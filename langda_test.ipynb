{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7843c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import langda_solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70ed28bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"\"\"\n",
    "# Try langda solve:\n",
    "operation(X,Y,Z) :-\n",
    "    langda(LLM:\"X plus Y equals Z\",FUP:\"false\").\n",
    "\"\"\"\n",
    "additional_input = { \"config\": { \"configurable\": { \"thread_id\": \"42\" } },\"prefix\": \"\",\"langda_ext\": \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5136bfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### =========== processing init_node =========== ###\n",
      "{'C5731F2D': 'operation(X, Y, Z) :- Z is X + Y.'}\n",
      "[{'C5731F2D': 'operation(X, Y, Z) :- Z is X + Y.'}]\n",
      "processing _decide_next_init ...\n",
      "No langda needs to be updated, process end now...\n",
      "### =========== processing summary_node =========== ###\n",
      "*** test_result: ***\n",
      "\n",
      "Running problog_test_tool...\n",
      "Error evaluating Problog model:\n",
      "    toks = self.label_tokens(string, root_tokens)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/zhenzhili/miniforge3/envs/langda/lib/python3.11/site-packages/problog/parser.py\", line 1186, in label_tokens\n",
      "    raise ParseError(string, \"Expected binary operator\", t.location)\n",
      "problog.parser.ParseError: Expected binary operator at 1:2.\n",
      "{'C5731F2D': 'operation(X, Y, Z) :- Z is X + Y.'}\n",
      "*** Running_time: 0s, 0 rounds in total.\n",
      "# Try langda solve:\n",
      "operation(X,Y,Z) :-\n",
      " \n",
      " Z is X + Y.\n"
     ]
    }
   ],
   "source": [
    "result = langda_solve('simple',model,'deepseek-chat',additional_input=additional_input)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5888cee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MIXMNIST_test = MIXMNIST(prefix=\"Arabic\", subset=\"test\")\n",
    "def engine(input:Iterable[int | bool]):\n",
    "    return 1 if (input[0] >= 80 and input[1] <= 20) else 0\n",
    "test_set = operation(2, \"test\", \"Arabic\", engine, seed=42)\n",
    "query = test_set.to_query(0)\n",
    "\n",
    "prompt_from_expert1 = \"(24.7136° N, 46.6753° E)\"\n",
    "thismodel = different_languange_test(load_dataset=\"Arabic\", logic_type=\"Engine\",\n",
    "                             train=False, load_pretrained=True, load_rule=True, prompt_from_expert=prompt_from_expert1)\n",
    "test_set._get_label\n",
    "\n",
    "def get_fake_queries(test_set, dataset):\n",
    "    query = test_set.to_query(0)\n",
    "    sub = {}\n",
    "    for placeholder, tensor_term in query.substitution.items():\n",
    "        print(placeholder,tensor_term)\n",
    "        inner_term = tensor_term.args[0]\n",
    "        if hasattr(inner_term, 'functor') and len(inner_term.args) > 0:\n",
    "            source_name = inner_term.functor\n",
    "            index = inner_term.args[0]\n",
    "            \n",
    "            # 处理index，可能是Constant类型\n",
    "            if hasattr(index, 'value'):\n",
    "                index = index.value\n",
    "            else:\n",
    "                index = int(index)\n",
    "            sub[placeholder] = f\"image_{dataset[index][1]}\"\n",
    "            print(source_name , index, dataset[index][1])\n",
    "    query.substitute(sub).query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07677deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Try langda solve:\n",
      "operation(X,Y,Z) :-\n",
      " \n",
      " Z is X + Y.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d12c074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DeepProbLog逻辑代码end-to-end验证框架\n",
    "通过多种策略验证逻辑规则的正确性和一致性\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple, Any, Optional\n",
    "from collections import defaultdict\n",
    "from deepproblog.model import Model\n",
    "from deepproblog.query import Query\n",
    "from deepproblog.dataset import Dataset\n",
    "from problog.logic import Term, Constant, Var\n",
    "import itertools\n",
    "\n",
    "class LogicVerificationFramework:\n",
    "    \"\"\"DeepProbLog逻辑代码验证框架\"\"\"\n",
    "    \n",
    "    def __init__(self, model: Model):\n",
    "        self.model = model\n",
    "        self.verification_results = {}\n",
    "        \n",
    "    def verify_logic_completeness(self, test_cases: List[Dict]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        验证逻辑规则的完整性\n",
    "        检查是否存在遗漏的逻辑分支或规则\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            'coverage_rate': 0.0,\n",
    "            'missing_cases': [],\n",
    "            'covered_cases': [],\n",
    "            'logic_gaps': []\n",
    "        }\n",
    "        \n",
    "        covered_cases = 0\n",
    "        total_cases = len(test_cases)\n",
    "        \n",
    "        for case in test_cases:\n",
    "            query = case['query']\n",
    "            expected = case.get('expected_logic_path', None)\n",
    "            \n",
    "            # 执行查询并分析逻辑路径\n",
    "            result = self.model.solve([query])[0]\n",
    "            \n",
    "            if len(result.result) > 0:\n",
    "                covered_cases += 1\n",
    "                results['covered_cases'].append(case)\n",
    "                \n",
    "                # 验证逻辑推理路径是否符合预期\n",
    "                if expected and not self._verify_logic_path(result, expected):\n",
    "                    results['logic_gaps'].append({\n",
    "                        'case': case,\n",
    "                        'expected_path': expected,\n",
    "                        'actual_result': result.result\n",
    "                    })\n",
    "            else:\n",
    "                results['missing_cases'].append(case)\n",
    "        \n",
    "        results['coverage_rate'] = covered_cases / total_cases if total_cases > 0 else 0\n",
    "        return results\n",
    "    \n",
    "    def verify_logic_consistency(self, rule_groups: List[List[str]]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        验证逻辑规则之间的一致性\n",
    "        检查相互冲突或重复的规则\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            'consistency_score': 1.0,\n",
    "            'conflicts': [],\n",
    "            'redundancies': [],\n",
    "            'circular_dependencies': []\n",
    "        }\n",
    "        \n",
    "        # 检查规则冲突\n",
    "        conflicts = self._detect_rule_conflicts(rule_groups)\n",
    "        results['conflicts'] = conflicts\n",
    "        \n",
    "        # 检查规则冗余\n",
    "        redundancies = self._detect_rule_redundancies(rule_groups)\n",
    "        results['redundancies'] = redundancies\n",
    "        \n",
    "        # 检查循环依赖\n",
    "        circular_deps = self._detect_circular_dependencies(rule_groups)\n",
    "        results['circular_dependencies'] = circular_deps\n",
    "        \n",
    "        # 计算一致性分数\n",
    "        total_issues = len(conflicts) + len(redundancies) + len(circular_deps)\n",
    "        total_rules = sum(len(group) for group in rule_groups)\n",
    "        results['consistency_score'] = max(0, 1 - (total_issues / total_rules))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def verify_counterfactual_reasoning(self, base_cases: List[Dict]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        通过反事实推理验证逻辑正确性\n",
    "        修改输入条件，验证输出变化是否符合逻辑预期\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            'counterfactual_accuracy': 0.0,\n",
    "            'failed_cases': [],\n",
    "            'unexpected_behaviors': []\n",
    "        }\n",
    "        \n",
    "        correct_predictions = 0\n",
    "        total_tests = 0\n",
    "        \n",
    "        for base_case in base_cases:\n",
    "            # 生成反事实变体\n",
    "            counterfactuals = self._generate_counterfactuals(base_case)\n",
    "            \n",
    "            for cf_case in counterfactuals:\n",
    "                total_tests += 1\n",
    "                \n",
    "                # 执行原始查询和反事实查询\n",
    "                base_result = self.model.solve([base_case['query']])[0]\n",
    "                cf_result = self.model.solve([cf_case['query']])[0]\n",
    "                \n",
    "                # 验证变化是否符合预期\n",
    "                expected_change = cf_case.get('expected_change', None)\n",
    "                if expected_change:\n",
    "                    actual_change = self._analyze_result_change(base_result, cf_result)\n",
    "                    \n",
    "                    if self._matches_expected_change(actual_change, expected_change):\n",
    "                        correct_predictions += 1\n",
    "                    else:\n",
    "                        results['failed_cases'].append({\n",
    "                            'base_case': base_case,\n",
    "                            'counterfactual': cf_case,\n",
    "                            'expected_change': expected_change,\n",
    "                            'actual_change': actual_change\n",
    "                        })\n",
    "        \n",
    "        results['counterfactual_accuracy'] = correct_predictions / total_tests if total_tests > 0 else 0\n",
    "        return results\n",
    "    \n",
    "    def verify_boundary_conditions(self, predicates: List[str]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        验证逻辑规则在边界条件下的行为\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            'boundary_robustness': 0.0,\n",
    "            'edge_case_failures': [],\n",
    "            'undefined_behaviors': []\n",
    "        }\n",
    "        \n",
    "        total_boundary_tests = 0\n",
    "        successful_tests = 0\n",
    "        \n",
    "        for predicate in predicates:\n",
    "            # 生成边界条件测试用例\n",
    "            boundary_cases = self._generate_boundary_cases(predicate)\n",
    "            \n",
    "            for case in boundary_cases:\n",
    "                total_boundary_tests += 1\n",
    "                \n",
    "                try:\n",
    "                    result = self.model.solve([case['query']])[0]\n",
    "                    \n",
    "                    if case.get('should_succeed', True):\n",
    "                        if len(result.result) > 0:\n",
    "                            successful_tests += 1\n",
    "                        else:\n",
    "                            results['edge_case_failures'].append({\n",
    "                                'case': case,\n",
    "                                'expected': 'success',\n",
    "                                'actual': 'failure'\n",
    "                            })\n",
    "                    else:\n",
    "                        if len(result.result) == 0:\n",
    "                            successful_tests += 1\n",
    "                        else:\n",
    "                            results['edge_case_failures'].append({\n",
    "                                'case': case,\n",
    "                                'expected': 'failure',\n",
    "                                'actual': 'success'\n",
    "                            })\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    results['undefined_behaviors'].append({\n",
    "                        'case': case,\n",
    "                        'error': str(e)\n",
    "                    })\n",
    "        \n",
    "        results['boundary_robustness'] = successful_tests / total_boundary_tests if total_boundary_tests > 0 else 0\n",
    "        return results\n",
    "    \n",
    "    def verify_logical_equivalence(self, equivalent_formulations: List[Tuple[str, str]]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        验证逻辑上等价的不同表述是否产生相同结果\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            'equivalence_accuracy': 0.0,\n",
    "            'non_equivalent_pairs': [],\n",
    "            'semantic_drifts': []\n",
    "        }\n",
    "        \n",
    "        equivalent_count = 0\n",
    "        total_pairs = len(equivalent_formulations)\n",
    "        \n",
    "        for form1, form2 in equivalent_formulations:\n",
    "            # 生成测试查询\n",
    "            test_queries = self._generate_equivalence_test_queries(form1, form2)\n",
    "            \n",
    "            pair_equivalent = True\n",
    "            for query1, query2 in test_queries:\n",
    "                result1 = self.model.solve([query1])[0]\n",
    "                result2 = self.model.solve([query2])[0]\n",
    "                \n",
    "                if not self._results_equivalent(result1, result2):\n",
    "                    pair_equivalent = False\n",
    "                    results['semantic_drifts'].append({\n",
    "                        'formulation1': form1,\n",
    "                        'formulation2': form2,\n",
    "                        'query1': query1,\n",
    "                        'query2': query2,\n",
    "                        'result1': result1.result,\n",
    "                        'result2': result2.result\n",
    "                    })\n",
    "            \n",
    "            if pair_equivalent:\n",
    "                equivalent_count += 1\n",
    "            else:\n",
    "                results['non_equivalent_pairs'].append((form1, form2))\n",
    "        \n",
    "        results['equivalence_accuracy'] = equivalent_count / total_pairs if total_pairs > 0 else 0\n",
    "        return results\n",
    "    \n",
    "    def generate_comprehensive_report(self, test_suite: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        生成综合验证报告\n",
    "        \"\"\"\n",
    "        report = {\n",
    "            'overall_logic_quality': 0.0,\n",
    "            'verification_summary': {},\n",
    "            'recommendations': [],\n",
    "            'critical_issues': []\n",
    "        }\n",
    "        \n",
    "        # 执行所有验证\n",
    "        completeness_result = self.verify_logic_completeness(test_suite.get('completeness_cases', []))\n",
    "        consistency_result = self.verify_logic_consistency(test_suite.get('rule_groups', []))\n",
    "        counterfactual_result = self.verify_counterfactual_reasoning(test_suite.get('counterfactual_cases', []))\n",
    "        boundary_result = self.verify_boundary_conditions(test_suite.get('predicates', []))\n",
    "        equivalence_result = self.verify_logical_equivalence(test_suite.get('equivalent_formulations', []))\n",
    "        \n",
    "        # 汇总结果\n",
    "        report['verification_summary'] = {\n",
    "            'completeness': completeness_result,\n",
    "            'consistency': consistency_result,\n",
    "            'counterfactual_reasoning': counterfactual_result,\n",
    "            'boundary_conditions': boundary_result,\n",
    "            'logical_equivalence': equivalence_result\n",
    "        }\n",
    "        \n",
    "        # 计算总体质量分数\n",
    "        scores = [\n",
    "            completeness_result['coverage_rate'],\n",
    "            consistency_result['consistency_score'],\n",
    "            counterfactual_result['counterfactual_accuracy'],\n",
    "            boundary_result['boundary_robustness'],\n",
    "            equivalence_result['equivalence_accuracy']\n",
    "        ]\n",
    "        report['overall_logic_quality'] = np.mean(scores)\n",
    "        \n",
    "        # 生成建议\n",
    "        report['recommendations'] = self._generate_recommendations(report['verification_summary'])\n",
    "        \n",
    "        # 识别关键问题\n",
    "        report['critical_issues'] = self._identify_critical_issues(report['verification_summary'])\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def _verify_logic_path(self, result, expected_path):\n",
    "        \"\"\"验证逻辑推理路径\"\"\"\n",
    "        # 这里需要根据具体的逻辑表示来实现\n",
    "        # 可能需要访问proof对象来分析推理路径\n",
    "        return True  # 简化实现\n",
    "    \n",
    "    def _detect_rule_conflicts(self, rule_groups):\n",
    "        \"\"\"检测规则冲突\"\"\"\n",
    "        conflicts = []\n",
    "        # 实现规则冲突检测逻辑\n",
    "        return conflicts\n",
    "    \n",
    "    def _detect_rule_redundancies(self, rule_groups):\n",
    "        \"\"\"检测规则冗余\"\"\"\n",
    "        redundancies = []\n",
    "        # 实现规则冗余检测逻辑\n",
    "        return redundancies\n",
    "    \n",
    "    def _detect_circular_dependencies(self, rule_groups):\n",
    "        \"\"\"检测循环依赖\"\"\"\n",
    "        circular_deps = []\n",
    "        # 实现循环依赖检测逻辑\n",
    "        return circular_deps\n",
    "    \n",
    "    def _generate_counterfactuals(self, base_case):\n",
    "        \"\"\"生成反事实测试用例\"\"\"\n",
    "        counterfactuals = []\n",
    "        # 实现反事实生成逻辑\n",
    "        return counterfactuals\n",
    "    \n",
    "    def _analyze_result_change(self, base_result, cf_result):\n",
    "        \"\"\"分析结果变化\"\"\"\n",
    "        change = {}\n",
    "        # 实现结果变化分析逻辑\n",
    "        return change\n",
    "    \n",
    "    def _matches_expected_change(self, actual_change, expected_change):\n",
    "        \"\"\"检查变化是否符合预期\"\"\"\n",
    "        return True  # 简化实现\n",
    "    \n",
    "    def _generate_boundary_cases(self, predicate):\n",
    "        \"\"\"生成边界条件测试用例\"\"\"\n",
    "        boundary_cases = []\n",
    "        # 实现边界用例生成逻辑\n",
    "        return boundary_cases\n",
    "    \n",
    "    def _generate_equivalence_test_queries(self, form1, form2):\n",
    "        \"\"\"生成等价性测试查询\"\"\"\n",
    "        test_queries = []\n",
    "        # 实现等价性测试查询生成逻辑\n",
    "        return test_queries\n",
    "    \n",
    "    def _results_equivalent(self, result1, result2):\n",
    "        \"\"\"检查两个结果是否等价\"\"\"\n",
    "        # 比较结果的概率分布\n",
    "        if len(result1.result) != len(result2.result):\n",
    "            return False\n",
    "        \n",
    "        for key in result1.result:\n",
    "            if key not in result2.result:\n",
    "                return False\n",
    "            if abs(float(result1.result[key]) - float(result2.result[key])) > 1e-6:\n",
    "                return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def _generate_recommendations(self, verification_summary):\n",
    "        \"\"\"生成改进建议\"\"\"\n",
    "        recommendations = []\n",
    "        \n",
    "        # 基于验证结果生成具体建议\n",
    "        completeness = verification_summary['completeness']\n",
    "        if completeness['coverage_rate'] < 0.8:\n",
    "            recommendations.append(\"逻辑规则覆盖率较低，建议添加更多规则处理边缘情况\")\n",
    "        \n",
    "        consistency = verification_summary['consistency']\n",
    "        if consistency['consistency_score'] < 0.9:\n",
    "            recommendations.append(\"发现逻辑规则一致性问题，建议检查并解决规则冲突\")\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def _identify_critical_issues(self, verification_summary):\n",
    "        \"\"\"识别关键问题\"\"\"\n",
    "        critical_issues = []\n",
    "        \n",
    "        # 识别可能导致系统故障的关键问题\n",
    "        for verification_type, results in verification_summary.items():\n",
    "            if verification_type == 'consistency' and results['consistency_score'] < 0.7:\n",
    "                critical_issues.append({\n",
    "                    'type': 'consistency',\n",
    "                    'severity': 'high',\n",
    "                    'description': '逻辑规则存在严重一致性问题',\n",
    "                    'conflicts': results['conflicts']\n",
    "                })\n",
    "        \n",
    "        return critical_issues\n",
    "\n",
    "\n",
    "# 使用示例\n",
    "def create_verification_test_suite():\n",
    "    \"\"\"创建测试套件示例\"\"\"\n",
    "    test_suite = {\n",
    "        'completeness_cases': [\n",
    "            {\n",
    "                'query': Query(Term('addition', Constant(1), Constant(2), Var('X'))),\n",
    "                'expected_logic_path': ['digit_recognition', 'arithmetic_operation']\n",
    "            }\n",
    "        ],\n",
    "        'rule_groups': [\n",
    "            ['addition_rule_1', 'addition_rule_2'],\n",
    "            ['digit_rule_1', 'digit_rule_2']\n",
    "        ],\n",
    "        'counterfactual_cases': [\n",
    "            {\n",
    "                'query': Query(Term('game', Term('cards'), Term('win'))),\n",
    "                'expected_change': {'probability_increase': True}\n",
    "            }\n",
    "        ],\n",
    "        'predicates': ['addition', 'digit', 'game'],\n",
    "        'equivalent_formulations': [\n",
    "            ('addition(X,Y,Z) :- digit(X,X2), digit(Y,Y2), Z is X2+Y2.',\n",
    "             'addition(A,B,C) :- digit(A,A1), digit(B,B1), C is A1+B1.')\n",
    "        ]\n",
    "    }\n",
    "    return test_suite\n",
    "\n",
    "# 主验证流程\n",
    "def run_logic_verification(model: Model):\n",
    "    \"\"\"运行逻辑验证的主流程\"\"\"\n",
    "    verifier = LogicVerificationFramework(model)\n",
    "    test_suite = create_verification_test_suite()\n",
    "    \n",
    "    # 生成综合报告\n",
    "    report = verifier.generate_comprehensive_report(test_suite)\n",
    "    \n",
    "    print(f\"逻辑质量总分: {report['overall_logic_quality']:.2f}\")\n",
    "    print(f\"发现 {len(report['critical_issues'])} 个关键问题\")\n",
    "    print(f\"建议: {len(report['recommendations'])} 条改进建议\")\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4522097",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'solve'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrun_logic_verification\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\"\"\u001b[39;49m\u001b[33;43mnn(mnist_net,[X],Y,[0,1,2,3,4,5,6,7,8,9]) :: digit(X,Y).\u001b[39;49m\n\u001b[32m      2\u001b[39m \u001b[33;43maddition(X,Y,Z) :- digit(X,X2), digit(Y,Y2), Z is X2+Y2.\u001b[39;49m\u001b[33;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 406\u001b[39m, in \u001b[36mrun_logic_verification\u001b[39m\u001b[34m(model)\u001b[39m\n\u001b[32m    403\u001b[39m test_suite = create_verification_test_suite()\n\u001b[32m    405\u001b[39m \u001b[38;5;66;03m# 生成综合报告\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m report = \u001b[43mverifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_comprehensive_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_suite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m逻辑质量总分: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreport[\u001b[33m'\u001b[39m\u001b[33moverall_logic_quality\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    409\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m发现 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(report[\u001b[33m'\u001b[39m\u001b[33mcritical_issues\u001b[39m\u001b[33m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m 个关键问题\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 240\u001b[39m, in \u001b[36mLogicVerificationFramework.generate_comprehensive_report\u001b[39m\u001b[34m(self, test_suite)\u001b[39m\n\u001b[32m    232\u001b[39m report = {\n\u001b[32m    233\u001b[39m     \u001b[33m'\u001b[39m\u001b[33moverall_logic_quality\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.0\u001b[39m,\n\u001b[32m    234\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mverification_summary\u001b[39m\u001b[33m'\u001b[39m: {},\n\u001b[32m    235\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mrecommendations\u001b[39m\u001b[33m'\u001b[39m: [],\n\u001b[32m    236\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcritical_issues\u001b[39m\u001b[33m'\u001b[39m: []\n\u001b[32m    237\u001b[39m }\n\u001b[32m    239\u001b[39m \u001b[38;5;66;03m# 执行所有验证\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m completeness_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverify_logic_completeness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_suite\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcompleteness_cases\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m consistency_result = \u001b[38;5;28mself\u001b[39m.verify_logic_consistency(test_suite.get(\u001b[33m'\u001b[39m\u001b[33mrule_groups\u001b[39m\u001b[33m'\u001b[39m, []))\n\u001b[32m    242\u001b[39m counterfactual_result = \u001b[38;5;28mself\u001b[39m.verify_counterfactual_reasoning(test_suite.get(\u001b[33m'\u001b[39m\u001b[33mcounterfactual_cases\u001b[39m\u001b[33m'\u001b[39m, []))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mLogicVerificationFramework.verify_logic_completeness\u001b[39m\u001b[34m(self, test_cases)\u001b[39m\n\u001b[32m     40\u001b[39m expected = case.get(\u001b[33m'\u001b[39m\u001b[33mexpected_logic_path\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# 执行查询并分析逻辑路径\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43msolve\u001b[49m([query])[\u001b[32m0\u001b[39m]\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result.result) > \u001b[32m0\u001b[39m:\n\u001b[32m     46\u001b[39m     covered_cases += \u001b[32m1\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'solve'"
     ]
    }
   ],
   "source": [
    "run_logic_verification(\"\"\"nn(mnist_net,[X],Y,[0,1,2,3,4,5,6,7,8,9]) :: digit(X,Y).\n",
    "addition(X,Y,Z) :- digit(X,X2), digit(Y,Y2), Z is X2+Y2.\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

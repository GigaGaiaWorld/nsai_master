Your task is to analyze the provided code and its test results, strictly following the instructions below.

<Code>
{input}
</Code>

<Evaluation_Instructions>
 
1. **Test Results Verification**
- List all queries and their return values ​​(including probability results).
- If all tests pass, please clearly output "All tests passed (no failures)" and briefly explain why there are no failures.
- If there are failures, point out the failed queries one by one and give the corresponding actual vs. expected results.

2. **Failure Localization**
- For each failed test, point out the specific predicate or rule with the error and the corresponding code line number interval.
- If there is no failure, also verify that all expansion predicates (e.g., `implies/2`, `opposite/1`, `expand/2`, `includes/2`, `extend/3`, `refute/1`) are correctly defined in both classical and probabilistic contexts.

3. **Root Cause Analysis**
- In classical Problog scenarios, analyze logical correctness and recursive termination.
- In ProbLog probabilistic scenarios, check whether the computation of probabilistic facts and negations/implications complies with probabilistic rules such as `P(¬A)=1−P(A)`, `P(A⇒B)=P(¬A)+P(A∧B)`.
- If there are DeepProbLog related calls (e.g., `nn/3`, `tensor/…`), verify whether the fusion of neural network output and probabilistic reasoning is correct; if it is not used at all, report "DeepProbLog feature not used".

4. **Overall Analysis**
- For the functional requirements (classical reasoning, probabilistic reasoning, neural network integration), indicate whether they are met and briefly explain.
- Comment on the easily overlooked edge cases (undefined `expand/2`, non-list input, deep recursive performance, etc.).

5. **Report Format**
- Use Markdown and include the following parts:
1. **Document Title**
2. **Background and Purpose**
3. **Test Results Summary**
4. **Failure Localization**
5. **Root Cause Analysis**
6. **Overall Analysis**
7. **Error Summary** (tabular form: number | problem | impact | suggestion)
- Must include code blocks and tables, and the word count should be between 300–500 words.
- The tone should be formal and the logic should be clear.
</Evaluation_Instructions>

<Final_Answer>
Please output the complete report according to the above structure.
</Final_Answer>

*** split ***
In this phase, you'll receive the output from the first chain along with the original code blocks. Your task is to evaluate each <langda> code block individually and determine if it needs regeneration.
<original_code>

{template_code}

</original_code>

{first_chain_output}

<Evaluation_Instructions>
For each <langda> code module (identified by its HASH):
1.Summarize the errors in that module in a brief *ErrorSummary*. If no errors, state "No issues found."
2.Propose a *SuggestedFix* that specifically addresses the error(s) (e.g. add a missing predicate, correct a probability rule). Include line numbers or module names if helpful.
3.List any *Dependencies* (by HASH) on other modules that must be modified together with this one (if none, use an empty list).
4.Set *NeedRegenerate* to true if the module requires changes (errors present), or false if it’s correct.
</Evaluation_Instructions>
<Final_Answer> 
Provide a JSON object for each code module with the keys "HASH", "ErrorSummary", "SuggestedFix", "Dependencies", "NeedRegenerate". Format the output as a JSON array or separate JSON blocks. For example:
// Inside the ```report ... ``` blocks, make sure not to use the ``` symbol to prevent parsing errors
```report
{{"HASH": "XXXX1234","ErrorSummary": "Missing base case in factorial predicate causing infinite recursion","SuggestedFix": "Add a base case predicate for factorial(0) = 1 to handle termination","Dependencies": [],"NeedRegenerate": true}}
```
```report
{{"HASH": "XXXX5678","ErrorSummary": "No issues found","SuggestedFix": "None needed","Dependencies": [],"NeedRegenerate": false}}
```
</Final_Answer>

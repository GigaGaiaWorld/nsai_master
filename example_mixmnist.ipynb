{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "247e5f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "# datasets = {\n",
    "#     \"train\": torchvision.datasets.MNIST(\n",
    "#         root=str(\"./data\"), train=True, download=True, transform=None\n",
    "#     ),\n",
    "#     \"test\": torchvision.datasets.MNIST(\n",
    "#         root=str(\"./data\"), train=False, download=True, transform=None\n",
    "#     ),\n",
    "# }\n",
    "# class MNIST_Images(object):\n",
    "#     def __init__(self, subset):\n",
    "#         self.subset = subset\n",
    "\n",
    "#     def __getitem__(self, item):\n",
    "#         return datasets[self.subset][int(item[0])][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1980c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets[\"train\"][21][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7bcd47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(datasets[\"train\"][21][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06ef0df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision\n",
    "# from torch import Tensor\n",
    "# import torch.nn as nn\n",
    "# import torchvision.transforms as transforms\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# class BasicDataset(Dataset):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.data = None\n",
    "#         self.targets = None\n",
    "#         self.transform = transforms.Compose([\n",
    "#             transforms.ToTensor(), # normalize\n",
    "#             # transforms.Normalize(mean=(0.1307,), std=(0.3081,))  # Zero center and unit variance treatment\n",
    "#         ])\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         if self.data is None or self.targets is None:\n",
    "#             raise RuntimeError(\"Dataset not initialized properly\")\n",
    "#         item = self.data[idx]\n",
    "#         target = self.targets[idx]\n",
    "#         if self.transform:\n",
    "#             item = self.transform(item)\n",
    "#         return item, target\n",
    "\n",
    "\n",
    "# class MNIST(BasicDataset):\n",
    "#     def __init__(self, root='./data', train=True):\n",
    "#         super().__init__()\n",
    "#         loaded = torchvision.datasets.MNIST(train=train, root='./data', transform=None, download=True)\n",
    "#         self.data = loaded.data\n",
    "#         self.targets = loaded.targets\n",
    "\n",
    "# # 定义数据转换\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(), # normalize\n",
    "#     # transforms.Normalize(mean=(0.1307,), std=(0.3081,))  # Zero center and unit variance treatment\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d458bbd",
   "metadata": {},
   "source": [
    "## MIX MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eb5e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "all_languages = [\"Arabic\",\"ARDIS\",\"Bangla\",\"BanglaLekha\",\"Devanagari\",\"EMNIST\",\n",
    " \"Farsi\",\"ISI_Bangla\",\"Kannada\",\"MADBase\",\"Telugu\",\"Tibetan\",\"Urdu\"]\n",
    "_main_ = [\"MNIST_MIX\"]\n",
    "# we use:\n",
    "used_languages = [\"EMNIST\",\"Farsi\",\"Urdu\",\"Kannada\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9f4d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Created for MIX MNIST: Bangla-train\n",
      "Dataset Created for MIX MNIST: Bangla-test\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from typing import Dict, Tuple, Iterable\n",
    "import torchvision.transforms as transforms\n",
    "from numpy.typing import NDArray\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MIXMNIST_BASE:\n",
    "    def __init__(self, root:str='./data', prefix:str=\"\"):\n",
    "        self.root = root\n",
    "        self.prefix = prefix\n",
    "        self.transform = transforms.Compose(\n",
    "            [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    "        )\n",
    "        self.datasets = self._get_dataset()\n",
    "\n",
    "    def _get_dataset(self) -> Dict[str,Tuple[NDArray,NDArray]]:\n",
    "        # NpzFile '{...}_train_test.npz' with keys: X_train, X_test, y_train, y_test\n",
    "        loaded:Dict[str,NDArray] = np.load(f'{self.root}/MNIST-MIX-all/{self.prefix}_train_test.npz')\n",
    "        raw_dataset = {\n",
    "            'train': (loaded['X_train'], loaded['y_train']),\n",
    "            'test': (loaded['X_test'], loaded['y_test'])\n",
    "        }\n",
    "        formatted_dataset = {}\n",
    "        for split_name, (imgs, targets) in raw_dataset.items():\n",
    "            formatted_items = []\n",
    "            for i, img in enumerate(imgs):\n",
    "\n",
    "                if self.transform:\n",
    "                    img = self.transform(img)\n",
    "                formatted_items.append((img, int(targets[i])))\n",
    "            formatted_dataset[split_name] = formatted_items\n",
    "        return formatted_dataset\n",
    "\n",
    "class MIXMNIST(Dataset):\n",
    "    def __init__(self, root: str = './data', prefix: str = \"\", subset: str = \"train\"):\n",
    "        self.base = MIXMNIST_BASE(root=root, prefix=prefix)\n",
    "        self.subset = subset\n",
    "        print(f\"Dataset Created for MIX MNIST: {prefix}-{subset}\")\n",
    "\n",
    "    def __getitem__(self, item: int) -> torch.Tensor:\n",
    "        return self.base.datasets[self.subset][int(item[0])][0]\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        length = len(self.base.datasets[self.subset])\n",
    "        return length\n",
    "\n",
    "# datasets = MIXMNIST_BASE(prefix=\"Bangla\").datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3b073ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Callable, List, Iterable, Tuple\n",
    "\n",
    "from problog.logic import Term, list2term, Constant\n",
    "from torch.utils.data import Dataset as TensorDataset\n",
    "from deepproblog.dataset import Dataset\n",
    "from deepproblog.query import Query\n",
    "\n",
    "class MNISTOperator(Dataset, TensorDataset):\n",
    "    def __getitem__(self, index: int) -> Tuple[list, list, int]:\n",
    "        l1, l2 = self.data[index]\n",
    "        print(\"L1L2\",l1,l2)\n",
    "        label = self._get_label(index)\n",
    "        l1 = [self.dataset[x][0] for x in l1]\n",
    "        l2 = [self.dataset[x][0] for x in l2]\n",
    "        return l1, l2, label\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_name: str,\n",
    "        function_name: str,\n",
    "        operator: Callable[[List[int]], int],\n",
    "        size=1,\n",
    "        arity=2,\n",
    "        seed=None,\n",
    "        prefix=\"None\"\n",
    "    ):\n",
    "        \"\"\"Generic dataset for operator(img, img) style datasets.\n",
    "\n",
    "        :param dataset_name: Dataset to use (train, val, test)\n",
    "        :param function_name: Name of Problog function to query.\n",
    "        :param operator: Operator to generate correct examples\n",
    "        :param size: Size of numbers (number of digits)\n",
    "        :param arity: Number of arguments for the operator\n",
    "        :param seed: Seed for RNG\n",
    "        \"\"\"\n",
    "        super(MNISTOperator, self).__init__()\n",
    "        assert size >= 1\n",
    "        assert arity >= 1\n",
    "        self.dataset_name = dataset_name\n",
    "        self.dataset = (MIXMNIST_BASE(prefix=prefix).datasets)[self.dataset_name]\n",
    "        self.function_name = function_name\n",
    "        self.operator = operator\n",
    "        self.size = size\n",
    "        self.arity = arity\n",
    "        self.seed = seed\n",
    "        mnist_indices = list(range(len(self.dataset)))\n",
    "        if seed is not None:\n",
    "            rng = random.Random(seed)\n",
    "            rng.shuffle(mnist_indices)\n",
    "        dataset_iter = iter(mnist_indices)\n",
    "        # Build list of examples (mnist indices): [[2,3],[5,7],...] a list of arities of each query\n",
    "        self.data = []\n",
    "        try:\n",
    "            while True:\n",
    "                self.data.append(\n",
    "                    [\n",
    "                        [next(dataset_iter) for _ in range(self.size)]\n",
    "                        for _ in range(self.arity)\n",
    "                    ]\n",
    "                )\n",
    "        except StopIteration:\n",
    "            pass\n",
    "\n",
    "    def _dig2num(self, digits:List[int]) -> int:\n",
    "        number = 0\n",
    "        for d in digits:\n",
    "            number *= 10\n",
    "            number += d\n",
    "        return number\n",
    "\n",
    "    def to_query(self, i: int) -> Query:\n",
    "        \"\"\"Generate queries\"\"\"\n",
    "        mnist_indices = self.data[i]\n",
    "        expected_result = self._get_label(i)\n",
    "\n",
    "        # Build substitution dictionary for the arguments\n",
    "        subs = dict()\n",
    "        var_names = []\n",
    "        for i in range(self.arity):\n",
    "            inner_vars = []\n",
    "            for j in range(self.size):\n",
    "                t = Term(f\"p{i}_{j}\")\n",
    "                subs[t] = Term(\n",
    "                    \"tensor\",\n",
    "                    Term(\n",
    "                        self.dataset_name,\n",
    "                        Constant(mnist_indices[i][j]),\n",
    "                    ),\n",
    "                )\n",
    "                inner_vars.append(t)\n",
    "            var_names.append(inner_vars)\n",
    "\n",
    "        # Build query\n",
    "        if self.size == 1:\n",
    "            args = [e[0] for e in var_names]\n",
    "        else:\n",
    "            args = [list2term(e) for e in var_names]\n",
    "\n",
    "        return Query(\n",
    "            Term(\n",
    "                self.function_name,\n",
    "                *args,\n",
    "                Constant(expected_result),\n",
    "            ),\n",
    "            subs,\n",
    "        )\n",
    "\n",
    "    def _get_label(self, i: int):\n",
    "        mnist_indices = self.data[i]\n",
    "        # Figure out what the ground truth is, first map each parameter to the value:\n",
    "        ground_truth = []\n",
    "        for idx_tuple in mnist_indices:\n",
    "            digits = [self.dataset[j][1] for j in idx_tuple]\n",
    "            number = self._dig2num(digits)\n",
    "            ground_truth.append(number)\n",
    "\n",
    "        # Then compute the expected value:\n",
    "        expected_result = self.operator(ground_truth)\n",
    "        return expected_result\n",
    "\n",
    "    def __len__(self):\n",
    "        print(\"call __len__ Operator:\",len(self.data))\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cee746f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Created for MIX MNIST: Arabic-train\n",
      "Dataset Created for MIX MNIST: Arabic-test\n",
      "Caching ACs\n",
      "call __len__ Operator: 1200\n",
      "Training  for 2 epoch(s)\n",
      "Epoch 1\n"
     ]
    },
    {
     "ename": "ArithmeticError",
     "evalue": "Error while evaluating 'is'(51,1/3*3.14*p0_0*p0_0*p1_0): Unknown function 'p0_0'/0.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mArithmeticError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/problog/eval_nodes.py:849\u001b[39m, in \u001b[36mEvalBuiltIn.__call__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    848\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m849\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparent\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    859\u001b[39m \u001b[43m        \u001b[49m\u001b[43midentifier\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43midentifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcall_origin\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_origin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcurrent_clause\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcurrent_clause\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mArithmeticError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/problog/engine_stack.py:1513\u001b[39m, in \u001b[36mSimpleBuiltIn.__call__\u001b[39m\u001b[34m(self, *args, **kwdargs)\u001b[39m\n\u001b[32m   1512\u001b[39m callback = kwdargs.get(\u001b[33m\"\u001b[39m\u001b[33mcallback\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1513\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwdargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1514\u001b[39m output = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/problog/engine_builtin.py:889\u001b[39m, in \u001b[36m_builtin_is\u001b[39m\u001b[34m(a, b, engine, **k)\u001b[39m\n\u001b[32m    888\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m889\u001b[39m     b_value = \u001b[43mb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    890\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m b_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/problog/logic.py:245\u001b[39m, in \u001b[36mTerm.compute_value\u001b[39m\u001b[34m(self, functions)\u001b[39m\n\u001b[32m    240\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute value of the Term by computing the function it represents.\u001b[39;00m\n\u001b[32m    241\u001b[39m \n\u001b[32m    242\u001b[39m \u001b[33;03m:param functions: dictionary of user-defined functions\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[33;03m:return: value of the Term\u001b[39;00m\n\u001b[32m    244\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompute_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunctor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/problog/logic.py:1314\u001b[39m, in \u001b[36mcompute_function\u001b[39m\u001b[34m(func, args, extra_functions)\u001b[39m\n\u001b[32m   1313\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m     values = \u001b[43m[\u001b[49m\u001b[43marg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextra_functions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   1315\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m values:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/problog/logic.py:1314\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   1313\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m     values = [\u001b[43marg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextra_functions\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[32m   1315\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m values:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/problog/logic.py:245\u001b[39m, in \u001b[36mTerm.compute_value\u001b[39m\u001b[34m(self, functions)\u001b[39m\n\u001b[32m    240\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute value of the Term by computing the function it represents.\u001b[39;00m\n\u001b[32m    241\u001b[39m \n\u001b[32m    242\u001b[39m \u001b[33;03m:param functions: dictionary of user-defined functions\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[33;03m:return: value of the Term\u001b[39;00m\n\u001b[32m    244\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompute_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunctor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/problog/logic.py:1314\u001b[39m, in \u001b[36mcompute_function\u001b[39m\u001b[34m(func, args, extra_functions)\u001b[39m\n\u001b[32m   1313\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m     values = \u001b[43m[\u001b[49m\u001b[43marg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextra_functions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   1315\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m values:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/problog/logic.py:1314\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   1313\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m     values = [\u001b[43marg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextra_functions\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[32m   1315\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m values:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/problog/logic.py:245\u001b[39m, in \u001b[36mTerm.compute_value\u001b[39m\u001b[34m(self, functions)\u001b[39m\n\u001b[32m    240\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute value of the Term by computing the function it represents.\u001b[39;00m\n\u001b[32m    241\u001b[39m \n\u001b[32m    242\u001b[39m \u001b[33;03m:param functions: dictionary of user-defined functions\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[33;03m:return: value of the Term\u001b[39;00m\n\u001b[32m    244\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompute_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunctor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/problog/logic.py:1314\u001b[39m, in \u001b[36mcompute_function\u001b[39m\u001b[34m(func, args, extra_functions)\u001b[39m\n\u001b[32m   1313\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m     values = \u001b[43m[\u001b[49m\u001b[43marg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextra_functions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   1315\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m values:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/problog/logic.py:1314\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   1313\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m     values = [\u001b[43marg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextra_functions\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[32m   1315\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m values:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/problog/logic.py:245\u001b[39m, in \u001b[36mTerm.compute_value\u001b[39m\u001b[34m(self, functions)\u001b[39m\n\u001b[32m    240\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute value of the Term by computing the function it represents.\u001b[39;00m\n\u001b[32m    241\u001b[39m \n\u001b[32m    242\u001b[39m \u001b[33;03m:param functions: dictionary of user-defined functions\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[33;03m:return: value of the Term\u001b[39;00m\n\u001b[32m    244\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompute_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunctor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/problog/logic.py:1312\u001b[39m, in \u001b[36mcompute_function\u001b[39m\u001b[34m(func, args, extra_functions)\u001b[39m\n\u001b[32m   1311\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1312\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mArithmeticError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUnknown function \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % (func, \u001b[38;5;28mlen\u001b[39m(args)))\n\u001b[32m   1313\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mArithmeticError\u001b[39m: Unknown function 'p0_0'/0.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mArithmeticError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 82\u001b[39m\n\u001b[32m     79\u001b[39m model.add_tensor_source(\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m, MIXMNIST_test)\n\u001b[32m     81\u001b[39m loader = DataLoader(train_set, \u001b[32m2\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m train = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m model.save_state(\u001b[33m\"\u001b[39m\u001b[33msnapshot/\u001b[39m\u001b[33m\"\u001b[39m + name + \u001b[33m\"\u001b[39m\u001b[33m.pth\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     84\u001b[39m train.logger.comment(dumps(model.get_hyperparameters()))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/deepproblog/train.py:200\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, loader, stop_condition, **kwargs)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_model\u001b[39m(\n\u001b[32m    194\u001b[39m     model: Model,\n\u001b[32m    195\u001b[39m     loader: DataLoader,\n\u001b[32m    196\u001b[39m     stop_condition: Union[\u001b[38;5;28mint\u001b[39m, StopCondition],\n\u001b[32m    197\u001b[39m     **kwargs\n\u001b[32m    198\u001b[39m ) -> TrainObject:\n\u001b[32m    199\u001b[39m     train_object = TrainObject(model)\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m     \u001b[43mtrain_object\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_condition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m train_object\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/deepproblog/train.py:128\u001b[39m, in \u001b[36mTrainObject.train\u001b[39m\u001b[34m(self, loader, stop_criterion, verbose, loss_function_name, with_negatives, log_iter, initial_test, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m     loss = \u001b[38;5;28mself\u001b[39m.get_loss_with_negatives(batch, loss_function)\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[38;5;28mself\u001b[39m.accumulated_loss += loss\n\u001b[32m    131\u001b[39m \u001b[38;5;28mself\u001b[39m.model.optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/deepproblog/train.py:39\u001b[39m, in \u001b[36mTrainObject.get_loss\u001b[39m\u001b[34m(self, batch, backpropagate_loss)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[33;03mCalculates and propagates the loss for a given batch of queries and loss function.\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[33;03m:param batch: The batch of queries.\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[33;03m:param backpropagate_loss:  The loss function. It should also perform the backpropagation.\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[33;03m:return: The average loss over the batch\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     38\u001b[39m total_loss = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[32m     41\u001b[39m     \u001b[38;5;28mself\u001b[39m.timing[\u001b[32m0\u001b[39m] += r.ground_time / \u001b[38;5;28mlen\u001b[39m(batch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/deepproblog/model.py:117\u001b[39m, in \u001b[36mModel.solve\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msolve\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch: Sequence[Query]) -> List[Result]:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m.\u001b[49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/deepproblog/solver.py:86\u001b[39m, in \u001b[36mSolver.solve\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28mself\u001b[39m.engine.tensor_store.clear()\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# Build ACs\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m acs: List[ArithmeticCircuit] = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# Evaluate ACs. Evaluate networks if necessary\u001b[39;00m\n\u001b[32m     88\u001b[39m result = [\n\u001b[32m     89\u001b[39m     ac.evaluate(\u001b[38;5;28mself\u001b[39m.model, batch[i].substitution) \u001b[38;5;28;01mfor\u001b[39;00m i, ac \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(acs)\n\u001b[32m     90\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/deepproblog/solver.py:86\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28mself\u001b[39m.engine.tensor_store.clear()\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# Build ACs\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m acs: List[ArithmeticCircuit] = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# Evaluate ACs. Evaluate networks if necessary\u001b[39;00m\n\u001b[32m     88\u001b[39m result = [\n\u001b[32m     89\u001b[39m     ac.evaluate(\u001b[38;5;28mself\u001b[39m.model, batch[i].substitution) \u001b[38;5;28;01mfor\u001b[39;00m i, ac \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(acs)\n\u001b[32m     90\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/deepproblog/utils/cache.py:52\u001b[39m, in \u001b[36mCache.get\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, item: K) -> T:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/deepproblog/utils/cache.py:62\u001b[39m, in \u001b[36mCache.get_from_dict\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m     60\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.get_from_file(item, cache_key)\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m     result.from_cache = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28mself\u001b[39m.cache_dict[cache_key] = result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/deepproblog/solver.py:71\u001b[39m, in \u001b[36mSolver.build_ac\u001b[39m\u001b[34m(self, q)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[33;03mBuilds the arithmetic circuit.\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[33;03m:param q: The query for which to build the arithmetic circuit.\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[33;03m:return: The arithmetic circuit for the given query.\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     69\u001b[39m start = time()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m ground = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mground\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLogicFormula\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLABEL_QUERY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m ground_time = time() - start\n\u001b[32m     73\u001b[39m ac = ArithmeticCircuit(\n\u001b[32m     74\u001b[39m     ground, \u001b[38;5;28mself\u001b[39m.semiring, ground_time=ground_time, sdd_auto_gc=\u001b[38;5;28mself\u001b[39m.sdd_auto_gc\n\u001b[32m     75\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/deepproblog/engines/exact_engine.py:147\u001b[39m, in \u001b[36mExactEngine.ground\u001b[39m\u001b[34m(self, query, label, repeat, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model.solver.cache.cache:\n\u001b[32m    146\u001b[39m     query = query.substitute()\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m ground = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mground\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ground\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/problog/engine.py:336\u001b[39m, in \u001b[36mClauseDBEngine.ground\u001b[39m\u001b[34m(self, db, term, target, label, **kwdargs)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    334\u001b[39m     negated = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m target, results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ground\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent_fail\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwdargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m args_node = defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m args, node_id \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/problog/engine.py:451\u001b[39m, in \u001b[36mClauseDBEngine._ground\u001b[39m\u001b[34m(self, db, term, gp, silent_fail, assume_prepared, **kwdargs)\u001b[39m\n\u001b[32m    447\u001b[39m         location = db.lineno(term.location)\n\u001b[32m    448\u001b[39m         \u001b[38;5;28mself\u001b[39m.debugger.call_create(\n\u001b[32m    449\u001b[39m             clause_node, term.functor, context, \u001b[38;5;28;01mNone\u001b[39;00m, location\n\u001b[32m    450\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m     results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclause_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwdargs\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m UnknownClauseInternal:\n\u001b[32m    455\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m silent_fail \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.unknown == \u001b[38;5;28mself\u001b[39m.UNKNOWN_FAIL:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/problog/engine_stack.py:441\u001b[39m, in \u001b[36mStackBasedEngine.execute\u001b[39m\u001b[34m(self, node_id, target, database, subcall, is_root, name, **kwdargs)\u001b[39m\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# We need to execute another node.\u001b[39;00m\n\u001b[32m    424\u001b[39m \u001b[38;5;66;03m# if self.cycle_root is not None and context['parent'] < self.cycle_root.pointer:\u001b[39;00m\n\u001b[32m    425\u001b[39m \u001b[38;5;66;03m#     print ('Cycle exhausted indeed:', len(actions) + 1)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    430\u001b[39m \u001b[38;5;66;03m#         (act, obj, args, context)]\u001b[39;00m\n\u001b[32m    431\u001b[39m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    433\u001b[39m     \u001b[38;5;66;03m# Evaluate the next node.\u001b[39;00m\n\u001b[32m    434\u001b[39m     \u001b[38;5;66;03m# if exclude is not None and obj in exclude:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    439\u001b[39m     \u001b[38;5;66;03m#     obj = self.pointer\u001b[39;00m\n\u001b[32m    440\u001b[39m     \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m441\u001b[39m     next_actions = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    442\u001b[39m     obj = \u001b[38;5;28mself\u001b[39m.pointer\n\u001b[32m    443\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m UnknownClauseInternal:\n\u001b[32m    444\u001b[39m     \u001b[38;5;66;03m# An unknown clause was encountered.\u001b[39;00m\n\u001b[32m    445\u001b[39m     \u001b[38;5;66;03m# TODO why is this handled here?\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/problog/engine_stack.py:126\u001b[39m, in \u001b[36mStackBasedEngine.eval\u001b[39m\u001b[34m(self, node_id, **kwdargs)\u001b[39m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    124\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m UnknownClauseInternal()\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexec_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwdargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/problog/engine_stack.py:891\u001b[39m, in \u001b[36mStackBasedEngine.eval_clause\u001b[39m\u001b[34m(self, context, node, node_id, parent, transform, identifier, current_clause, **kwdargs)\u001b[39m\n\u001b[32m    888\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.create_context(output, parent=result)\n\u001b[32m    890\u001b[39m     transform.addFunction(result_transform)\n\u001b[32m--> \u001b[39m\u001b[32m891\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcurrent_clause\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m        \u001b[49m\u001b[43midentifier\u001b[49m\u001b[43m=\u001b[49m\u001b[43midentifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwdargs\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m UnifyError:\n\u001b[32m    901\u001b[39m     \u001b[38;5;66;03m# Call and clause head are not unifiable, just fail (complete without results).\u001b[39;00m\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [complete(parent, identifier)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/problog/engine_stack.py:126\u001b[39m, in \u001b[36mStackBasedEngine.eval\u001b[39m\u001b[34m(self, node_id, **kwdargs)\u001b[39m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    124\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m UnknownClauseInternal()\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexec_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwdargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/problog/engine_stack.py:834\u001b[39m, in \u001b[36mStackBasedEngine.eval_call\u001b[39m\u001b[34m(self, node_id, node, context, parent, transform, identifier, **kwdargs)\u001b[39m\n\u001b[32m    831\u001b[39m kwdargs[\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m] = transform\n\u001b[32m    833\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m834\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    835\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midentifier\u001b[49m\u001b[43m=\u001b[49m\u001b[43midentifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwdargs\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m UnknownClauseInternal:\n\u001b[32m    838\u001b[39m     loc = kwdargs[\u001b[33m\"\u001b[39m\u001b[33mdatabase\u001b[39m\u001b[33m\"\u001b[39m].lineno(node.location)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/problog/engine_stack.py:126\u001b[39m, in \u001b[36mStackBasedEngine.eval\u001b[39m\u001b[34m(self, node_id, **kwdargs)\u001b[39m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    124\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m UnknownClauseInternal()\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexec_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwdargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/problog/engine_stack.py:954\u001b[39m, in \u001b[36mStackBasedEngine.eval_builtin\u001b[39m\u001b[34m(self, **kwdargs)\u001b[39m\n\u001b[32m    953\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34meval_builtin\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwdargs):\n\u001b[32m--> \u001b[39m\u001b[32m954\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meval_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEvalBuiltIn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwdargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/problog/engine_stack.py:958\u001b[39m, in \u001b[36mStackBasedEngine.eval_default\u001b[39m\u001b[34m(self, eval_type, **kwdargs)\u001b[39m\n\u001b[32m    956\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34meval_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, eval_type, **kwdargs):\n\u001b[32m    957\u001b[39m     node = eval_type(pointer=\u001b[38;5;28mself\u001b[39m.pointer, engine=\u001b[38;5;28mself\u001b[39m, **kwdargs)\n\u001b[32m--> \u001b[39m\u001b[32m958\u001b[39m     cleanup, actions = \u001b[43mnode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Evaluate the node\u001b[39;00m\n\u001b[32m    959\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cleanup:\n\u001b[32m    960\u001b[39m         \u001b[38;5;28mself\u001b[39m.add_record(node)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/problog/eval_nodes.py:872\u001b[39m, in \u001b[36mEvalBuiltIn.__call__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    867\u001b[39m     base_message = \u001b[33m\"\u001b[39m\u001b[33mError while evaluating \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % (\n\u001b[32m    868\u001b[39m         callterm,\n\u001b[32m    869\u001b[39m         err.base_message,\n\u001b[32m    870\u001b[39m     )\n\u001b[32m    871\u001b[39m     location = \u001b[38;5;28mself\u001b[39m.database.lineno(\u001b[38;5;28mself\u001b[39m.location)\n\u001b[32m--> \u001b[39m\u001b[32m872\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mArithmeticError\u001b[39;00m(base_message, location)\n\u001b[32m    873\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    874\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "\u001b[31mArithmeticError\u001b[39m: Error while evaluating 'is'(51,1/3*3.14*p0_0*p0_0*p1_0): Unknown function 'p0_0'/0."
     ]
    }
   ],
   "source": [
    "from json import dumps\n",
    "\n",
    "import torch\n",
    "\n",
    "from deepproblog.dataset import DataLoader\n",
    "from deepproblog.engines import ApproximateEngine, ExactEngine\n",
    "from deepproblog.evaluate import get_confusion_matrix\n",
    "from deepproblog.examples.MNIST.network import MNIST_Net\n",
    "from deepproblog.model import Model\n",
    "from deepproblog.network import Network\n",
    "from deepproblog.train import train_model\n",
    "\n",
    "# =============== define some (prompt, function) pairs\n",
    "def my_sum(input:Iterable[int | bool]):\n",
    "    return sum(input)\n",
    "\n",
    "def my_cone_volume(input:Iterable[int | bool]):\n",
    "    radius = input[0]\n",
    "    height = input[1]\n",
    "    return round((1/3) * 3.14 * radius**2 * height)\n",
    "def my_swap(input:Iterable[int | bool]):\n",
    "    \"\"\" [4,8] => 84\"\"\"\n",
    "    return input[1] * 10 + input[0]\n",
    "\n",
    "language = \"Arabic\"\n",
    "\n",
    "def operation(n: int, dataset: str, prefix:str, func:callable, seed=None):\n",
    "    \"\"\"Returns a dataset for binary addition\"\"\"\n",
    "    return MNISTOperator(\n",
    "        dataset_name=dataset,\n",
    "        function_name=\"operation\",\n",
    "        operator=func,\n",
    "        size=n,\n",
    "        arity=2,\n",
    "        seed=seed,\n",
    "        prefix=prefix\n",
    "    )\n",
    "\n",
    "method = \"exact\"\n",
    "N = 1\n",
    "\n",
    "name = \"operation_{}_{}\".format(method, N)\n",
    "\n",
    "train_set = operation(N, \"train\", language, my_cone_volume, seed=42)\n",
    "test_set = operation(N, \"test\", language, my_cone_volume, seed=42)\n",
    " \n",
    "MIXMNIST_train = MIXMNIST(prefix=language, subset=\"train\")\n",
    "MIXMNIST_test = MIXMNIST(prefix=language, subset=\"test\")\n",
    "\n",
    "network1 = MNIST_Net()\n",
    "network2 = MNIST_Net()\n",
    "network3 = MNIST_Net()\n",
    "\n",
    "problog_string = \"\"\"\n",
    "nn(arabic_net,[X],Y,[0,1,2,3,4,5,6,7,8,9]) :: arabic_digit(X,Y).\n",
    "operation(X,Y,Z) :- \n",
    "    langda(LLM:\"/* PROMPT */\").\n",
    "\"\"\"\n",
    "\n",
    "# pretrain = 0\n",
    "# if pretrain is not None and pretrain > 0:\n",
    "#     network.load_state_dict(torch.load(\"models/pretrained/all_{}.pth\".format(pretrain)))\n",
    "\n",
    "net1 = Network(network1, \"arabic_net\", batching=True)\n",
    "net1.optimizer = torch.optim.Adam(network1.parameters(), lr=1e-3)\n",
    "\n",
    "model = Model(problog_string, [net1], load=False)\n",
    "if method == \"exact\":\n",
    "    model.set_engine(ExactEngine(model), cache=True)\n",
    "\n",
    "# elif method == \"geometric_mean\":\n",
    "#     model.set_engine(\n",
    "#         ApproximateEngine(model, 1, ApproximateEngine.geometric_mean, exploration=False)\n",
    "#     )\n",
    "\n",
    "model.add_tensor_source(\"train\", MIXMNIST_train)\n",
    "model.add_tensor_source(\"test\", MIXMNIST_test)\n",
    "\n",
    "loader = DataLoader(train_set, 2, False)\n",
    "train = train_model(model, loader, 2, log_iter=100, profile=0)\n",
    "model.save_state(\"snapshot/\" + name + \".pth\")\n",
    "train.logger.comment(dumps(model.get_hyperparameters()))\n",
    "train.logger.comment(\n",
    "    \"Accuracy {}\".format(get_confusion_matrix(model, test_set, verbose=1).accuracy())\n",
    ")\n",
    "train.logger.write_to_file(\"log/\" + name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "aa218370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Created for MIX MNIST: Telugu-train\n",
      "Dataset Created for MIX MNIST: Telugu-test\n",
      "### =========== processing init_node =========== ###\n",
      "{'6FBBDE1D': 'operation(X,Y,Z) :- \\n    telugu_digit(X, X1),\\n    telugu_digit(Y, Y1),\\n    Z is X1 + Y1.'}\n",
      "ext_match PROMPT\n",
      "raw_langda_dict[LLM] This is for Telugu net. Please calculate the sum of X and Y elements\n",
      "langda_ext_dict[ext_match] This is for Telugu net. Please calculate the sum of X and Y elements\n",
      "[{'6FBBDE1D': None}]\n",
      "processing _decide_next_init ...\n",
      "### =========== ### current round: 0 ### =========== ###\n",
      "### =========== processing generate_node =========== ###\n",
      "Executing first chain: Code generation with tools...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe provided code snippet is incomplete, and the `<Langda>` block specifies that the task is to calculate the sum of `X` and `Y` elements for the `telugu_net`. Here's the completed code based on the requirements:\n",
      "\n",
      "```problog\n",
      "nn(arabic_net,[X],Y,[0,1,2,3,4,5,6,7,8,9]) :: arabic_digit(X,Y).\n",
      "nn(telugu_net,[X],Y,[0,1,2,3,4,5,6,7,8,9]) :: telugu_digit(X,Y).\n",
      "nn(urdu_net,[X],Y,[0,1,2,3,4,5,6,7,8,9]) :: urdu_digit(X,Y).\n",
      "\n",
      "operation(X, Y, Z) :-\n",
      "    telugu_digit(X, X_val),\n",
      "    telugu_digit(Y, Y_val),\n",
      "    Z is X_val + Y_val.\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "1. The `telugu_digit(X, Y)` predicate uses the neural network `telugu_net` to predict the digit `Y` from the input `X`.\n",
      "2. The `operation(X, Y, Z)` predicate calculates the sum of the predicted values of `X` and `Y` using `telugu_digit` and stores the result in `Z`.\n",
      "\n",
      "This code assumes that `X` and `Y` are inputs to the `telugu_net`, and their predicted digit values are summed up. Adjustments may be needed based on the exact requirements or data format.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Executing second chain: Code formatting...\n",
      "processing _decide_next_gnrt... #current round: 1\n",
      "### =========== ### current round: 1 ### =========== ###\n",
      "### =========== processing test_node =========== ###\n",
      "Executing first chain: Code generation with tools...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_report_tool` with `learn from history`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m<Syntax_Notes>\n",
      "ProbLog supports a subset of Prolog's control constructs (logical connectives and meta-predicates) that do not break the logical (declarative) semantics. \n",
      "It excludes features like cuts and imperative control that have no meaning in a probabilistic setting.\n",
      "\n",
      "Supported control predicates:\n",
      "- Conjunction: P, Q (both P and Q must succeed).\n",
      "- Disjunction: P; Q (either P or Q succeeds).\n",
      "- true/0 (always succeeds).\n",
      "- fail/0 (always fails) and synonym false/0.\n",
      "- Negation-as-failure: \\+/1 (or its alias not/1).\n",
      "- Meta-call: call/1 (invoke a goal at runtime) and call/N for N up to 9 (for calling predicates with N-1 additional arguments).\n",
      "- You can also write a goal directly as a term (which is equivalent to call/1).\n",
      "\n",
      "Supported arithmetic evaluation and comparison: \n",
      "- X is Y (evaluate expression Y and unify with X).\n",
      "- Comparison Operators X < Y, X =< Y (or <=), X > Y, X >= Y, as well as numeric equality X =:= Y and inequality X =\\\\= Y (which compare numerical values after evaluation).\n",
      "\n",
      "Not supported control constructs:\n",
      "- The cut !/0 is not supported (no hard cut in ProbLog; see the Cut library for an alternative soft cut mechanism).\n",
      "- The if-then (->) and if-then-else (*->) constructs are not supported. (You can achieve a similar effect using (Condition, Action) ; (\\+ Condition, Alternative).)\n",
      "\n",
      "** Other situations can be obtained by calling the tool\n",
      "</Syntax_Notes>\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `retriever_tool` with `{'query': 'ProbLog operation predicate syntax'}`\n",
      "\n",
      "\n",
      "\u001b[0m Running retriever tool...\n",
      "Loading existing vector store...\n",
      "\u001b[33;1m\u001b[1;3m[(Document(id='54ca7e47-e6ae-4e48-b196-ed166181924e', metadata={'id': 'builtin_message_handling', 'title': 'Message Handling', 'tags': ['predicate', 'exception', 'builtin'], 'keywords': ['catch', 'throw', 'error']}, page_content=\"Prolog's message handling predicates (for catching and throwing exceptions or printing system messages) are not available in ProbLog's modeling language. Constructs like catch/3, throw/1, and other built-in message or exception handling predicates are not supported in ProbLog.\"), 248.63766), (Document(id='a74afbba-0c6e-4381-b7dd-3cfba38d3850', metadata={'id': 'builtin_handling_undefined', 'title': 'Handling Undefined Procedures', 'tags': ['predicate', 'undefined', 'builtin'], 'keywords': ['unknown', 'undefined predicate', 'fail']}, page_content='In ProbLog, undefined predicates (calls to predicates that have no definition) can be handled by setting the Prolog flag unknown to fail. By default, any call to an undefined predicate fails.\\n\\nOne can use unknown(fail) directive to ensure that undefined procedure calls fail silently rather than causing an error. Aside from this, other traditional Prolog behaviors for undefined predicates are not supported.'), 249.54259), (Document(id='5254b66a-6155-472c-a543-4ec663fd2692', metadata={'id': 'builtin_predicates_on_characters', 'title': 'Predicates on Characters', 'tags': ['predicate', 'character', 'builtin'], 'keywords': ['char_code', 'character']}, page_content=\"Predicates dealing with character codes or character classification (for example, checking if a character is a digit or converting between characters and character codes) are not supported in ProbLog. Essentially, no built-in predicates for character manipulation (like those in Prolog's char_code/2 or character classification routines) are available at this time.\"), 268.38513)]\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_tool` with `{'query': 'DeepProbLog neural network integration verification'}`\n",
      "\n",
      "\n",
      "\u001b[0m Running search tool...\n",
      "\u001b[38;5;200m\u001b[1;3m[{'title': '[PDF] DEEP GENERATIVE MODELS WITH PROBABILISTIC LOGIC PRIORS', 'url': 'https://amslaurea.unibo.it/id/eprint/24058/1/Deep_Generative_Models_with_Probabilistic_Logic_Priors.pdf', 'content': '(1.13) To get a seamless integration between ProbLog and neural network training, DeepProbLog relies gradient\\xadbased learning, since the same AC that ProbLog uses for inference can be used for gradient computations as well. In fact, an AC is a differentiable structure, as it is composed of addition and multiplication operations. [...] the addition of two natural numbers. By combining probabilistic\\xadlogical programming and neural network, DeepProbLog is able to encode back\\xad ground knowledge in rules, like the one of our example: add(img1, img2, N):- digit(img1,N1), digit(img2,N2), N is N1 + N2. [...] Figure 1.8: The SDD and the corresponding AC for query add(img1,img2,1).\\n1.5. PROBLOG 18 1.5.1 DeepProbLog DeepProbLog [36] is a neural probabilistic logic programming language that incorporates deep learning by means of neural predicates.', 'score': 0.77179235}, {'title': '[PDF] Approximate Inference for Neural Probabilistic Logic Programming', 'url': 'https://proceedings.kr.org/2021/45/kr2021-0045-manhaeve-et-al.pdf', 'content': 'Approximate Inference for Neural Probabilistic Logic Programming Robin Manhaeve1 , Giuseppe Marra1 , Luc De Raedt1,2 1KU Leuven, Dept. of Computer Science; Leuven.AI 2Örebro University {robin.manhaeve, giuseppe.marra,luc.deraedt}@cs.kuleuven.be Abstract DeepProbLog is a neural-symbolic framework that integrates probabilistic logic programming and neural networks. It is realized by providing an interface between the probabilistic logic and the neural networks. Inference in probabilistic neural [...] interface layer between the neural and the symbolic side (Manhaeve et al., 2018). One such interface is built between the probabilistic logic programming language ProbLog and neural networks in DeepProbLog. ProbLog (Fierens et al., 2015) belongs to the statistical relational artiﬁcial intelligence paradigm and combines theorem proving with knowledge compilation to perform inference and learning. It is well known that probabilistic logic inference is computationally hard. While the statistical [...] DeepProbLog extends ProbLog by the addition of the neu-ral predicate. The neural predicate is deﬁned by means of a neural AD, i.e., an expression of the form nn(mr, I, O, D) :: r(I, O), where mr is a neural network taking I as input and computing O as output. Furthermore, the range of possible outputs is speciﬁed in the (discrete) domain D = {d1, ..., dk}.', 'score': 0.7498395}, {'title': '[PDF] arXiv:1907.08194v2 [cs.AI] 23 Sep 2019', 'url': 'https://arxiv.org/pdf/1907.08194', 'content': 'We introduced DeepProbLog, a framework where neural networks and prob-abilistic logic programming are integrated in a way that exploits the full ex-pressiveness and strengths of both worlds and can be trained end-to-end based on examples. This was accomplished by extending an existing probabilistic logic programming language, ProbLog, with neural predicates. Learning is per-formed by using aProbLog to calculate the gradient of the loss which is then used in standard gradient-descent based [...] Most of the work on combining neural networks and logical reasoning comes from the neuro-symbolic reasoning literature [7, 31]. These approaches typically focus on approximating logical reasoning with neural networks by encoding log-ical terms in Euclidean space. However, they neither support probabilistic rea-soning nor perception, and are often limited to non-recursive and acyclic logic programs [32]. DeepProbLog takes a different approach and integrates neural networks into a probabilistic [...] methods should have the pure neural, logical and probabilistic methods as special cases. With DeepProbLog, we tackle the neuro-symbolic challenge from this per-spective. Furthermore, instead of integrating reasoning capabilities into a com-plex neural network architecture, we proceed the other way round. We start from an existing probabilistic logic programming language, ProbLog [12], and introduce the smallest extension that allows us to integrate neural networks: the neural predicate. The', 'score': 0.7323053}]\u001b[0m\u001b[32;1m\u001b[1;3m### **Code Evaluation Report: ProbLog and DeepProbLog Analysis**\n",
      "\n",
      "---\n",
      "\n",
      "#### **1. Document Title**  \n",
      "**Evaluation of ProbLog Code for Telugu Digit Summation**\n",
      "\n",
      "---\n",
      "\n",
      "#### **2. Background and Purpose**  \n",
      "The provided ProbLog code defines a neural network-based predicate (`telugu_digit`) to recognize Telugu digits and a rule (`operation`) to compute their sum. The purpose is to verify the correctness of the code, including its logical structure, probabilistic reasoning, and neural network integration (if applicable).\n",
      "\n",
      "---\n",
      "\n",
      "#### **3. Test Results Summary**  \n",
      "- **Queries and Results**:  \n",
      "  - Example query: `operation(X, Y, Z).`  \n",
      "    - Expected: `Z` is the sum of the recognized values of `X` and `Y`.  \n",
      "    - Actual: The code correctly computes the sum if `X` and `Y` are valid inputs for `telugu_digit`.  \n",
      "  - Probability results: Not applicable here, as the code does not involve probabilistic facts or queries.  \n",
      "\n",
      "- **Conclusion**:  \n",
      "  - **All tests passed (no failures)**. The code adheres to the requirements and correctly computes the sum of recognized Telugu digits.\n",
      "\n",
      "---\n",
      "\n",
      "#### **4. Failure Localization**  \n",
      "- No failures were detected. The predicates and rules are correctly defined.  \n",
      "- **Expansion Predicates**:  \n",
      "  - The code does not use any expansion predicates (`implies/2`, `opposite/1`, etc.), so no verification is needed.\n",
      "\n",
      "---\n",
      "\n",
      "#### **5. Root Cause Analysis**  \n",
      "- **Classical Prolog**:  \n",
      "  - The rule `operation(X, Y, Z)` is logically correct. It terminates as it does not involve recursion.  \n",
      "- **ProbLog Probabilistic Scenarios**:  \n",
      "  - The code does not use probabilistic facts or implications, so no probabilistic rules (e.g., `P(¬A)=1−P(A)`) are violated.  \n",
      "- **DeepProbLog Integration**:  \n",
      "  - The `nn/4` predicate (`telugu_net`) is correctly defined for neural network integration. However, the code does not utilize DeepProbLog features like gradient-based learning or probabilistic neural predicates.  \n",
      "  - **Report**: \"DeepProbLog feature not used.\"\n",
      "\n",
      "---\n",
      "\n",
      "#### **6. Overall Analysis**  \n",
      "- **Functional Requirements**:  \n",
      "  - **Classical Reasoning**: Met. The code correctly implements the sum operation.  \n",
      "  - **Probabilistic Reasoning**: Not applicable.  \n",
      "  - **Neural Network Integration**: Partially met. The `nn/4` predicate is defined, but no DeepProbLog-specific features are used.  \n",
      "\n",
      "- **Edge Cases**:  \n",
      "  - **Undefined Inputs**: If `X` or `Y` are not recognized by `telugu_digit`, the query fails silently (default ProbLog behavior).  \n",
      "  - **Non-list Input**: The code does not handle non-list inputs explicitly, but this is not required here.  \n",
      "  - **Performance**: No deep recursion or performance issues are present.\n",
      "\n",
      "---\n",
      "\n",
      "#### **7. Error Summary**  \n",
      "\n",
      "| No. | Problem                  | Impact               | Suggestion                          |\n",
      "|-----|--------------------------|----------------------|-------------------------------------|\n",
      "| 1   | DeepProbLog unused       | Limited functionality| Integrate gradient-based learning.  |\n",
      "| 2   | Silent failure on invalid inputs | User confusion | Add validation rules for inputs. |\n",
      "\n",
      "---\n",
      "\n",
      "**Word Count**: 450 words.  \n",
      "\n",
      "**Final Remarks**: The code is functionally correct for the given requirements but could benefit from deeper integration with DeepProbLog features for enhanced capabilities.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Executing second chain: Code formatting...\n",
      "processing _decide_next_eval... #current round: 1\n",
      "### =========== processing summary_node =========== ###\n",
      "*** test_result: ***\n",
      "\n",
      "Running problog_test_tool...\n",
      " ------------- result_lines ------------- \n",
      "\n",
      "{'6FBBDE1D': 'operation(X, Y, Z) :- \\n    telugu_digit(X, X_val),\\n    telugu_digit(Y, Y_val),\\n    Z is X_val + Y_val.'}\n",
      "*** Running_time: 86s, 1 rounds in total.\n",
      "nn(arabic_net,[X],Y,[0,1,2,3,4,5,6,7,8,9]) :: arabic_digit(X,Y).\n",
      "nn(telugu_net,[X],Y,[0,1,2,3,4,5,6,7,8,9]) :: telugu_digit(X,Y).\n",
      "nn(urdu_net,[X],Y,[0,1,2,3,4,5,6,7,8,9]) :: urdu_digit(X,Y).\n",
      "operation(X,Y,Z) :- \n",
      " \n",
      " \n",
      "    telugu_digit(X, X_val),\n",
      "    telugu_digit(Y, Y_val),\n",
      "    Z is X_val + Y_val.\n",
      "Caching ACs\n",
      "call __len__ Operator: 1200\n",
      "Training  for 2 epoch(s)\n",
      "Epoch 1\n",
      "Iteration:  100 \ts:1.8529 \tAverage Loss:  2.6835637247562407\n",
      "Iteration:  200 \ts:1.3396 \tAverage Loss:  2.3708843004703524\n",
      "Iteration:  300 \ts:1.2744 \tAverage Loss:  1.9893792556226253\n",
      "Iteration:  400 \ts:1.2675 \tAverage Loss:  1.7149719964712857\n",
      "Iteration:  500 \ts:1.2632 \tAverage Loss:  1.314457463407889\n",
      "Iteration:  600 \ts:1.1880 \tAverage Loss:  0.9350347975431942\n",
      "Epoch time:  8.197162866592407\n",
      "Epoch 2\n",
      "Iteration:  700 \ts:1.1683 \tAverage Loss:  0.8377103571104817\n",
      "Iteration:  800 \ts:1.2288 \tAverage Loss:  0.7941535115172155\n",
      "Iteration:  900 \ts:1.2530 \tAverage Loss:  0.6638302124547772\n",
      "Iteration:  1000 \ts:1.2265 \tAverage Loss:  0.5124526245740708\n",
      "Iteration:  1100 \ts:1.0935 \tAverage Loss:  0.4250217213778524\n",
      "Iteration:  1200 \ts:1.1472 \tAverage Loss:  0.35366825235963917\n",
      "Epoch time:  7.117389917373657\n",
      "call __len__ Operator: 300\n",
      "         \t  \t  \t  \t  \t  \t  \t  \t  \t  \t  \tActual\t \t  \t  \t  \t  \t  \t  \t \t \n",
      "         \t  \t11\t 5\t12\t 8\t 9\t15\t10\t17\t13\t     6\t1\t 4\t 7\t 3\t18\t16\t14\t2\t0\n",
      "         \t11\t33\t 0\t 2\t 0\t 1\t 0\t 0\t 0\t 0\t     0\t0\t 0\t 0\t 0\t 0\t 0\t 0\t0\t0\n",
      "         \t 5\t 0\t12\t 0\t 1\t 0\t 0\t 0\t 0\t 0\t     1\t0\t 0\t 0\t 0\t 0\t 0\t 0\t0\t0\n",
      "         \t12\t 1\t 0\t18\t 0\t 0\t 0\t 1\t 0\t 2\t     0\t0\t 0\t 0\t 0\t 0\t 0\t 0\t0\t0\n",
      "         \t 8\t 1\t 0\t 0\t21\t 2\t 0\t 0\t 0\t 0\t     1\t0\t 0\t 0\t 1\t 0\t 0\t 0\t0\t0\n",
      "         \t 9\t 0\t 0\t 1\t 1\t24\t 0\t 2\t 0\t 0\t     0\t0\t 0\t 1\t 0\t 0\t 0\t 0\t0\t0\n",
      "         \t15\t 0\t 0\t 0\t 0\t 0\t 9\t 0\t 0\t 0\t     0\t0\t 0\t 0\t 0\t 0\t 1\t 0\t0\t0\n",
      "         \t10\t 2\t 0\t 0\t 0\t 0\t 0\t23\t 0\t 0\t     3\t0\t 0\t 0\t 0\t 0\t 0\t 0\t0\t0\n",
      "         \t17\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t 4\t 0\t     0\t0\t 0\t 0\t 0\t 0\t 0\t 0\t0\t0\n",
      "Predicted\t13\t 0\t 1\t 1\t 0\t 0\t 0\t 0\t 0\t20\t     0\t0\t 0\t 0\t 0\t 0\t 0\t 1\t0\t0\n",
      "         \t 6\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t    11\t0\t 0\t 0\t 0\t 0\t 0\t 0\t0\t0\n",
      "         \t 1\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t     0\t9\t 0\t 0\t 0\t 0\t 0\t 0\t0\t0\n",
      "         \t 4\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t     0\t0\t12\t 0\t 1\t 0\t 0\t 0\t0\t0\n",
      "         \t 7\t 0\t 0\t 0\t 3\t 0\t 0\t 0\t 0\t 0\t     1\t0\t 0\t26\t 0\t 0\t 0\t 0\t0\t1\n",
      "         \t 3\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t     0\t0\t 0\t 0\t13\t 0\t 0\t 0\t0\t0\n",
      "         \t18\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t 1\t     0\t0\t 0\t 0\t 0\t 2\t 0\t 0\t0\t0\n",
      "         \t16\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t     0\t0\t 0\t 0\t 0\t 0\t 8\t 0\t0\t0\n",
      "         \t14\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t 1\t 0\t     0\t0\t 0\t 0\t 0\t 0\t 0\t 9\t0\t0\n",
      "         \t 2\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t     0\t0\t 0\t 0\t 3\t 0\t 0\t 0\t6\t0\n",
      "         \t 0\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t 0\t     0\t0\t 0\t 0\t 0\t 0\t 0\t 0\t0\t1\n",
      "Accuracy:  0.87\n",
      "Accuracy 0.87\n",
      "Accuracy:  0.87\n"
     ]
    }
   ],
   "source": [
    "from json import dumps\n",
    "\n",
    "import torch\n",
    "from typing import Dict, Tuple, Iterable\n",
    "\n",
    "from deepproblog.dataset import DataLoader\n",
    "from deepproblog.engines import ApproximateEngine, ExactEngine\n",
    "from deepproblog.evaluate import get_confusion_matrix\n",
    "from deepproblog.model import Model\n",
    "from deepproblog.network import Network\n",
    "from deepproblog.train import train_model\n",
    "from deepproblog.examples.MNIST.network import MNIST_Net\n",
    "\n",
    "from core import langda_solve\n",
    "\n",
    "from typing import Iterable\n",
    "\n",
    "def my_sum(input: Iterable[int | bool]) -> int:\n",
    "    \"\"\"求和: [1,2,3] => 6\"\"\"\n",
    "    return sum(input)\n",
    "\n",
    "def my_swap(input: Iterable[int | bool]) -> int:\n",
    "    \"\"\"交换位置并拼接: [4,8] => 84\"\"\"\n",
    "    return input[1] * 10 + input[0]\n",
    "\n",
    "def my_product(input: Iterable[int | bool]) -> int:\n",
    "    \"\"\"求积: [2,3,4] => 24\"\"\"\n",
    "    result = 1\n",
    "    for x in input:\n",
    "        result *= x\n",
    "    return result\n",
    "\n",
    "def my_max_min_diff(input: Iterable[int | bool]) -> int:\n",
    "    \"\"\"最大值减最小值: [1,5,3] => 4\"\"\"\n",
    "    return max(input) - min(input)\n",
    "\n",
    "def my_reverse_concat(input: Iterable[int | bool]) -> int:\n",
    "    \"\"\"逆序拼接: [1,2,3] => 321\"\"\"\n",
    "    return int(''.join(str(x) for x in reversed(input)))\n",
    "\n",
    "def my_alternating_sum(input: Iterable[int | bool]) -> int:\n",
    "    \"\"\"交替求和: [1,2,3,4] => 1-2+3-4 = -2\"\"\"\n",
    "    result = 0\n",
    "    for i, x in enumerate(input):\n",
    "        result += x if i % 2 == 0 else -x\n",
    "    return result\n",
    "\n",
    "def my_count_even(input: Iterable[int | bool]) -> int:\n",
    "    \"\"\"计算偶数个数: [1,2,3,4] => 2\"\"\"\n",
    "    return sum(1 for x in input if x % 2 == 0)\n",
    "\n",
    "def my_weighted_sum(input: Iterable[int | bool]) -> int:\n",
    "    \"\"\"按位置加权求和: [1,2,3] => 1*1 + 2*2 + 3*3 = 14\"\"\"\n",
    "    return sum(x * (i + 1) for i, x in enumerate(input))\n",
    "\n",
    "def my_binary_to_decimal(input: Iterable[int | bool]) -> int:\n",
    "    \"\"\"二进制转十进制: [1,0,1] => 5\"\"\"\n",
    "    result = 0\n",
    "    for bit in input:\n",
    "        result = result * 2 + bit\n",
    "    return result\n",
    "\n",
    "def my_sum_of_squares(input: Iterable[int | bool]) -> int:\n",
    "    \"\"\"平方和: [1,2,3] => 1+4+9 = 14\"\"\"\n",
    "    return sum(x * x for x in input)\n",
    "\n",
    "def my_ascending_check(input: Iterable[int | bool]) -> int:\n",
    "    \"\"\"检查是否递增(是返回1，否返回0): [1,2,3] => 1\"\"\"\n",
    "    lst = list(input)\n",
    "    return 1 if all(lst[i] <= lst[i+1] for i in range(len(lst)-1)) else 0\n",
    "\n",
    "# FUNCMAP = {\n",
    "#     \"Arabic\":(\"This is for arabic net. Please calculate the sum of X and Y elements\",my_sum),\n",
    "#     \"Telugu\":(\"This is for telugu net. Please calculate the volume of the cone with telugu_digit. X is the base radius, Y is the height, π is approximated to 3.14, keep only the integer part\",my_cone_volume),\n",
    "#     \"Urdu\":(\"This is for urdu net.  Please calculate with the digit predicate. Please swap the positions of X and Y and combine them into a new number. Example: input [4,8] → 8*10 + 4 = 84\",my_swap),\n",
    "# }\n",
    "FUNCMAP = {\n",
    "    \"Arabic\":(\"This is for arabic net. Please calculate the sum of X and Y elements\",my_sum),\n",
    "    \"Telugu\":(\"This is for Telugu net. Please calculate the sum of X and Y elements\",my_sum),\n",
    "    \"Urdu\":(\"This is for Urdu net. Please calculate the sum of X and Y elements\",my_sum),\n",
    "}\n",
    "rule_string = \"\"\"\n",
    "nn(arabic_net,[X],Y,[0,1,2,3,4,5,6,7,8,9]) :: arabic_digit(X,Y).\n",
    "nn(telugu_net,[X],Y,[0,1,2,3,4,5,6,7,8,9]) :: telugu_digit(X,Y).\n",
    "nn(urdu_net,[X],Y,[0,1,2,3,4,5,6,7,8,9]) :: urdu_digit(X,Y).\n",
    "\n",
    "operation(X,Y,Z) :- \n",
    "    langda(LLM:\"/* PROMPT */\").\n",
    "\"\"\"\n",
    "def operation(n: int, dataset: str, prefix:str, func:callable, seed=None):\n",
    "    \"\"\"Returns a dataset for binary addition\"\"\"\n",
    "    return MNISTOperator(\n",
    "        dataset_name=dataset,\n",
    "        function_name=\"operation\",\n",
    "        operator=func,\n",
    "        size=n,\n",
    "        arity=2,\n",
    "        seed=seed,\n",
    "        prefix=prefix\n",
    "    )\n",
    "\n",
    "# language = \"Arabic\"\n",
    "method = \"exact\"\n",
    "N = 1\n",
    "\n",
    "\n",
    "# for language in [\"Arabic\",\"Telugu\",\"Urdu\"]:\n",
    "for language in [\"Telugu\"]:\n",
    "    name = \"{}_{}_{}\".format(language,method, N)\n",
    "    train_set = operation(N, \"train\", language, FUNCMAP[language][1], seed=42)\n",
    "    test_set = operation(N, \"test\", language, FUNCMAP[language][1], seed=42)\n",
    "    \n",
    "    MIXMNIST_train = MIXMNIST(prefix=language, subset=\"train\")\n",
    "    MIXMNIST_test = MIXMNIST(prefix=language, subset=\"test\")\n",
    "\n",
    "    network1 = MNIST_Net()\n",
    "    network2 = MNIST_Net()\n",
    "    network3 = MNIST_Net()\n",
    "\n",
    "    # pretrain = 0\n",
    "    # if pretrain is not None and pretrain > 0:\n",
    "    #     network.load_state_dict(torch.load(\"models/pretrained/all_{}.pth\".format(pretrain)))\n",
    "\n",
    "    net1 = Network(network1, \"arabic_net\", batching=True)\n",
    "    net1.optimizer = torch.optim.Adam(network1.parameters(), lr=1e-3)\n",
    "    net2 = Network(network2, \"telugu_net\", batching=True)\n",
    "    net2.optimizer = torch.optim.Adam(network2.parameters(), lr=1e-3)\n",
    "    net3 = Network(network3, \"urdu_net\", batching=True)\n",
    "    net3.optimizer = torch.optim.Adam(network3.parameters(), lr=1e-3)\n",
    "\n",
    "    result_string = langda_solve(\"double_dc\", rule_string,\n",
    "                            additional_input={\n",
    "                                \"langda_ext\": {\"PROMPT\":FUNCMAP[language][0]}})\n",
    "\n",
    "    print(result_string)\n",
    "    model = Model(result_string, [net1,net2,net3],load=False)\n",
    "    if method == \"exact\":\n",
    "        model.set_engine(ExactEngine(model), cache=True)\n",
    "\n",
    "    model.add_tensor_source(\"train\", MIXMNIST_train)\n",
    "    model.add_tensor_source(\"test\", MIXMNIST_test)\n",
    "\n",
    "    loader = DataLoader(train_set, 2, False)\n",
    "    train = train_model(model, loader, 2, log_iter=100, profile=0)\n",
    "    model.save_state(\"snapshot/\" + name + \".pth\")\n",
    "    train.logger.comment(dumps(model.get_hyperparameters()))\n",
    "    train.logger.comment(\n",
    "        \"Accuracy {}\".format(get_confusion_matrix(model, test_set, verbose=1).accuracy())\n",
    "    )\n",
    "    train.logger.write_to_file(\"log/\" + name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a11a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Created for MIX MNIST: Arabic-test\n",
      "Caching ACs\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'snapshot/Arabic_exact_1.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[96]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m model.set_engine(ExactEngine(model), cache=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     16\u001b[39m model.add_tensor_source(\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m, MIXMNIST_test)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msnapshot/\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[33;43m_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[33;43m_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[33;43m.pth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m model.eval()\n\u001b[32m     21\u001b[39m test_set = operation(N, \u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m, language, FUNCMAP[language][\u001b[32m1\u001b[39m], seed=\u001b[32m42\u001b[39m).subset(\u001b[32m0\u001b[39m,\u001b[32m100\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/site-packages/deepproblog/model.py:159\u001b[39m, in \u001b[36mModel.load_state\u001b[39m\u001b[34m(self, filename)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_state\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename: Union[\u001b[38;5;28mstr\u001b[39m, PathLike, IO[\u001b[38;5;28mbytes\u001b[39m]]):\n\u001b[32m    153\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[33;03m    Restore the state of this model from the given filename. This only includes the probabilistic parameters\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[33;03m        and all parameters of the neural networks, but not the model architecture or neural architectures.\u001b[39;00m\n\u001b[32m    156\u001b[39m \u001b[33;03m    :param filename: The filename to restore the model from.\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[33;03m    :return:\u001b[39;00m\n\u001b[32m    158\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m zipf:\n\u001b[32m    160\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m zipf.open(\u001b[33m\"\u001b[39m\u001b[33mparameters\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    161\u001b[39m             \u001b[38;5;28mself\u001b[39m.parameters = pickle.load(f)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/langda/lib/python3.11/zipfile.py:1295\u001b[39m, in \u001b[36mZipFile.__init__\u001b[39m\u001b[34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[39m\n\u001b[32m   1293\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m   1294\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1295\u001b[39m         \u001b[38;5;28mself\u001b[39m.fp = io.open(file, filemode)\n\u001b[32m   1296\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m   1297\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'snapshot/Arabic_exact_1.pth'"
     ]
    }
   ],
   "source": [
    "language_model = \"Telugu\"\n",
    "language_call = \"Arabic\"\n",
    "\n",
    "network = MNIST_Net()\n",
    "\n",
    "net1 = Network(network1, \"arabic_net\", batching=True)\n",
    "net1.optimizer = torch.optim.Adam(network1.parameters(), lr=1e-3)\n",
    "net2 = Network(network2, \"telugu_net\", batching=True)\n",
    "net2.optimizer = torch.optim.Adam(network2.parameters(), lr=1e-3)\n",
    "net3 = Network(network3, \"urdu_net\", batching=True)\n",
    "net3.optimizer = torch.optim.Adam(network3.parameters(), lr=1e-3)\n",
    "\n",
    "MIXMNIST_test = MIXMNIST(prefix=language_call, subset=\"test\")\n",
    "\n",
    "model = Model(result_string, [net1,net2,net3],load=False)\n",
    "model.set_engine(ExactEngine(model), cache=True)\n",
    "model.add_tensor_source(\"test\", MIXMNIST_test)\n",
    "\n",
    "model.load_state(\"snapshot/{}_{}_{}.pth\".format(language_model,method, N))\n",
    "model.eval()\n",
    "\n",
    "test_set = operation(N, \"test\", language_call, FUNCMAP[language_call][1], seed=42).subset(0,100)\n",
    "\n",
    "confusion_matrix = get_confusion_matrix(model, test_set, verbose=1)\n",
    "accuracy = confusion_matrix.accuracy()\n",
    "\n",
    "print(f\"\\n✓ 测试完成!\")\n",
    "print(f\"准确率: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5b92e4",
   "metadata": {},
   "source": [
    "### Anomaly Detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d53608",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

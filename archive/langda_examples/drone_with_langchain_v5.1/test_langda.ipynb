{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def recursive_extract(term, results=None):\n",
    "#     \"\"\"Recursively extract all terms from a complex Prolog structure.\"\"\"\n",
    "#     if results is None:\n",
    "#         results = []\n",
    "    \n",
    "#     # If this isn't a Term, we can't process it\n",
    "#     if not isinstance(term, Term):\n",
    "#         return results\n",
    "    \n",
    "#     # Check if this is a conjunction (,) or disjunction (;)\n",
    "#     if term.functor == ',' or term.functor == ';':\n",
    "#         # Recursively process each argument\n",
    "#         for arg in term.args:\n",
    "#             recursive_extract(arg, results)\n",
    "#     # If this is a rule (:-), process both head and body\n",
    "#     elif term.functor == ':-' and term.arity == 2:\n",
    "#         # Add the head to results (usually not a langda, but might be useful)\n",
    "#         recursive_extract(term.args[0], results)\n",
    "#         # Process the body recursively\n",
    "#         recursive_extract(term.args[1], results)\n",
    "#     else:\n",
    "#         # This is a regular predicate term\n",
    "#         results.append(term)\n",
    "    \n",
    "#     return results\n",
    "\n",
    "# import problog\n",
    "# import re\n",
    "# from typing import List\n",
    "# from problog.logic import Term\n",
    "\n",
    "# class Langda(object):\n",
    "#     def __init__(self, model_string, caching=False, saving=False):\n",
    "#         self.model_string = self.parse(model_string)\n",
    "\n",
    "#     def parse(self, model_string):\n",
    "#         langda_string, out_model_string = list(), list()\n",
    "#         parser = problog.parser.PrologParser(problog.program.ExtendedPrologFactory())\n",
    "#         langda_pattern = r'langda\\(\"([^\"\\\\]*(\\\\.[^\"\\\\]*)*?)\"\\)'\n",
    "        \n",
    "#         for line in model_string.split('\\n'):\n",
    "#             if 'langda' in line:\n",
    "#                 # matches = list(re.finditer(langda_pattern, line))\n",
    "#                 modified_line = re.sub(langda_pattern, \"\\n{LANGDA}\\n\", line)\n",
    "#                 out_model_string.append(modified_line)\n",
    "#                 # print(matches)\n",
    "#                 # print(re.finditer(langda_pattern, line))\n",
    "#                 # if matches:\n",
    "#                 #     modified_line = line\n",
    "#                 #     for match in matches:\n",
    "#                 #         modified_line = modified_line.replace(match.group(0), \"\\n{LANGDA}\\n\")\n",
    "\n",
    "#                 #         # print(\"match:\",match.group(1))\n",
    "#                 #         out_model_string.append(modified_line)\n",
    "\n",
    "#             else:\n",
    "#                 out_model_string.append(line)\n",
    "    \n",
    "#         return '\\n'.join(out_model_string)\n",
    "\n",
    "# l = Langda(model_string)\n",
    "# print(l.model_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_string = \"\"\"\n",
    "# langda(\"hello; there\").\n",
    "# vols(X) :-\n",
    "#     (langda(\"nothing\"), langda(\"Is this, this, as ggod?! oh no- have fun\"), where(X,Y));house(X).\n",
    "# valid_drone_flight(X) :-\n",
    "#     what(X);langda(\"there's a high building at 0.11\"), vlos(X),\n",
    "#     here(X).\n",
    "# % Definition of a valid mission\n",
    "# landscape(X) :- \n",
    "#     (langda(\"stop from there\"), vlos(X)), addtion(X), langda(\"danger, stop!\"), langda(\"what the hell?\").\n",
    "# final(X) :- langda(\"23 is a good number; stop here\").\n",
    "# \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Here's the code to replace the `{LANGDA}` placeholder, which adds the construction site avoidance rule:\n",
    "\n",
    "```\n",
    "    distance(X, (500,500)) >= 20,\n",
    "    vlos(X), weight < 25, can_return(X);\n",
    "    distance(X, (500,500)) >= 20,\n",
    "    permits(X), can_return(X)\n",
    "```\n",
    "```\n",
    "    distance(X, (500,500)) >= 20,\n",
    "    vlos(X), weight < 25, can_return(X);\n",
    "    distance(X, (500,500)) >= 20,\n",
    "    permits(X), can_return(X)\n",
    "```\n",
    "```\n",
    "    distance(X, (500,500)) >= 20,\n",
    "    vlos(X), weight < 25, can_return(X);\n",
    "    distance(X, (500,500)) >= 20,\n",
    "    permits(X), can_return(X)\n",
    "```\n",
    "This code:\n",
    "1. Ensures the drone maintains at least 20 units distance from the construction site at (500,500)\n",
    "2. Combines with both possible valid flight conditions (VLOS with weight check or permits)\n",
    "3. Maintains all other existing safety requirements\n",
    "4. Uses the same structure as the rest of the rules with semicolon-separated alternatives\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "import re\n",
    "\n",
    "generated_codes = []\n",
    "pattern = r\"```(?:prolog|[a-z]*)?\\n(.*?)```\"\n",
    "matches = re.findall(pattern, text, re.DOTALL)\n",
    "for match in matches:\n",
    "    generated_codes.append(match)\n",
    "print(len(generated_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"\\{\\{LANGDA\\}\\}\"\n",
    "model_string = \"\"\"\n",
    "{{LANGDA}}\n",
    "vols(X) :-\n",
    "    {{LANGDA}}\n",
    "    , langda(\"Is this, this, as ggod?! oh no- have fun\"), where(X,Y));house(X).\n",
    "valid_drone_flight(X) :-\n",
    "    what(X);langda(\"there's a high building at 0.11\"), vlos(X),\n",
    "    here(X).\n",
    "% Definition of a valid mission\n",
    "landscape(X) :- \n",
    "    (langda(\"stop from there\"), vlos(X)), addtion(X), langda(\"danger, stop!\"), langda(\"what the hell?\").\n",
    "final(X) :- langda(\"23 is a good number; stop here\").\n",
    "\"\"\"\n",
    "\n",
    "repl_iter = iter(generated_codes)\n",
    "res = re.sub(r\"\\{\\{LANGDA\\}\\}\", lambda _: next(repl_iter, \"{{LANGDA}}\"), model_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape length: 2\n",
      "Shape indices: [0]\n",
      "Shape networks: [('test_net', [5])]\n",
      "Shape parameters: []\n",
      "\n",
      "Semiring zero: (0.0, array([0., 0.]))\n",
      "Semiring one: (1.0, array([0., 0.]))\n",
      "\n",
      "Probability value for test_term: (0.30000001192092896, array([1., 0.]))\n",
      "\n",
      "Plus result: (1.0, array([0., 0.]))\n",
      "\n",
      "Times result: (0.0, array([0., 0.]))\n",
      "\n",
      "SDD structure:\n",
      "1: atom(identifier=(12, (5,) {{}}, 0), probability=nn(test_net,[5],a), group=(12, (5,) {{}}), name=query(5), source=None, is_extra=False)\n",
      "Queries : \n",
      "* query(5) : 1 [query]\n",
      "\n",
      "\n",
      "Query result: {query(5): (0.30000001192092896, {('test_net', [5]): array([1., 0.])})}\n",
      "\n",
      "Gradients: {('test_net', [5]): array([1., 0.])}\n"
     ]
    }
   ],
   "source": [
    "import problog\n",
    "from problog.logic import Term, Constant, Var\n",
    "from problog.evaluator import Semiring\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(\"/Users/zhenzhili/MASTERTHESIS/#Expert_System_Design\")\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "from src.deepprobcep.model import Model\n",
    "from src.deepprobcep.network import Network\n",
    "from src.deepprobcep.standard_networks import FC\n",
    "\n",
    "from src.deepprobcep.gradient_semiring import SemiringGradient\n",
    "from src.deepprobcep.vector_shape import VectorShape\n",
    "\n",
    "# Define a simple test function for the network\n",
    "def test_nn(network, *inputs):\n",
    "    return torch.FloatTensor([0.3, 0.7])  # Example probabilities for binary classification\n",
    "\n",
    "# Create a simple model\n",
    "model_string = \"nn(test_net,[X],Y,[a,b]) :: test_pred(X,Y).\\nquery(X) :- test_pred(X,a).\"\n",
    "fc = FC(1, 2)  # Simple fully connected network with 1 input and 2 outputs\n",
    "net = Network(fc, 'test_net', test_nn)\n",
    "model = Model(model_string, [net])\n",
    "# Create a query\n",
    "query = Term('query', Constant(5))\n",
    "\n",
    "# Get the compiled SDD and shape\n",
    "sdd, shape = model.get_sdd(query)\n",
    "\n",
    "# Examine the shape\n",
    "print(\"Shape length:\", shape.length)\n",
    "print(\"Shape indices:\", shape.indices)\n",
    "print(\"Shape networks:\", shape.networks)\n",
    "print(\"Shape parameters:\", shape.parameters)\n",
    "\n",
    "# Create the semiring\n",
    "semiring = SemiringGradient(model, shape)\n",
    "\n",
    "# Print semiring methods\n",
    "print(\"\\nSemiring zero:\", semiring.zero())\n",
    "print(\"Semiring one:\", semiring.one())\n",
    "\n",
    "# Create a valid list term for testing\n",
    "# This is how ProbLog represents lists internally: .(head, tail)\n",
    "empty_list = Term('[]')\n",
    "list_term = Term('.', Constant(5), empty_list)  # A list with just one element: [5]\n",
    "\n",
    "# Now create a valid nn term with the proper list format\n",
    "test_term = Term('nn', Constant('test_net'), list_term, Constant('a'))\n",
    "\n",
    "try:\n",
    "    prob_value = semiring.value(test_term)\n",
    "    print(\"\\nProbability value for test_term:\", prob_value)\n",
    "except Exception as e:\n",
    "    print(\"\\nError evaluating test_term:\", e)\n",
    "    \n",
    "    # Let's try to debug what's happening\n",
    "    from logic import term2list2\n",
    "    try:\n",
    "        print(\"Converting list term to Python list:\", term2list2(list_term))\n",
    "    except Exception as e:\n",
    "        print(\"Error converting list term:\", e)\n",
    "\n",
    "# Test plus method with valid values\n",
    "a = semiring.zero()\n",
    "b = semiring.one()\n",
    "plus_result = semiring.plus(a, b)\n",
    "print(\"\\nPlus result:\", plus_result)\n",
    "\n",
    "# Test times method\n",
    "times_result = semiring.times(a, b)\n",
    "print(\"\\nTimes result:\", times_result)\n",
    "\n",
    "# Let's also try examining the SDD structure\n",
    "print(\"\\nSDD structure:\")\n",
    "print(sdd)\n",
    "\n",
    "# Execute the query to see what happens\n",
    "try:\n",
    "    result = model.solve(query)\n",
    "    print(\"\\nQuery result:\", result)\n",
    "    if query in result:\n",
    "        print(\"\\nGradients:\", result[query][1])\n",
    "except Exception as e:\n",
    "    print(\"\\nError solving query:\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'Here is the completed code segment with all population data filled in:\\n\\n```problog\\n{\\n  \"HASH\": \"23C2CC6E\",\\n  \"Code\": \"pop(china, 8250).\\npop(india, 5863).\\npop(ussr, 2521).\\npop(usa, 2119).\\npop(indonesia, 1276).\\npop(japan, 1097).\\npop(brazil, 1042).\\npop(bangladesh, 750).\\npop(pakistan, 682).\\npop(w_germany, 613).\\npop(nigeria, 613).\\npop(mexico, 581).\\npop(uk, 559).\\npop(italy, 554).\\npop(france, 525).\\npop(philippines, 415).\\npop(thailand, 410).\\npop(turkey, 383).\\npop(egypt, 364).\\npop(spain, 352).\\npop(poland, 337).\\npop(s_korea, 335).\\npop(iran, 320).\\npop(ethiopia, 272).\\npop(argentina, 251).\"\\n}\\n```'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import uuid\n",
    "import hashlib\n",
    "from problog.program import PrologString, Clause, AnnotatedDisjunction, Term\n",
    "from typing import Literal, List, Union, Tuple, Dict, Any\n",
    "from langgraph.graph import END, StateGraph\n",
    "from state import BasicState, Mode\n",
    "from config import paths\n",
    "def _find_all_blocks(type:Literal[\"report\",\"code\",\"other\"], text:str, ext_mark:str=\"\") -> List[dict]:\n",
    "    \"\"\"\n",
    "    find block with certain patterns in json form.\n",
    "    \"\"\"\n",
    "    blocks:List[dict] = []\n",
    "    \n",
    "    if type == \"other\" or type == \"report\":\n",
    "        pattern = r\"```(?:report|[a-z]*)?\\n(.*?)```\"\n",
    "    elif type == \"code\":\n",
    "        pattern = r\"```(?:problog|[a-z]*)?\\n(.*?)```\"\n",
    "    else:\n",
    "        raise ValueError(\"you must choose from ['report','code','other']\")\n",
    "    \n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    if not matches:\n",
    "        pattern = r\"```(?:json|[a-z]*)?\\n(.*?)```\"\n",
    "        matches = re.findall(pattern, text, re.DOTALL)\n",
    "\n",
    "    if matches:\n",
    "        for match in matches:\n",
    "            try:\n",
    "                # 直接尝试解析 JSON\n",
    "                match_json = json.loads(match)\n",
    "            except json.JSONDecodeError:\n",
    "                # 对于 ProbLog 代码，需要特殊处理转义\n",
    "                # 保护 ProbLog 特殊操作符\n",
    "                protected_match = match\n",
    "                \n",
    "                # 创建特殊操作符的映射\n",
    "                special_patterns = {\n",
    "                    r'\\\\\\\\=': '<<<BACKSLASH_BACKSLASH_EQUALS>>>',\n",
    "                    r'\\\\\\\\\\\\\\\\=': '<<<QUAD_BACKSLASH_EQUALS>>>',  # 处理已经有四个反斜杠的情况\n",
    "                    r'\\\\n'        : '<<<ESCAPED_NEWLINE>>>',      # 新增这一行\n",
    "                }\n",
    "                # 临时替换特殊操作符\n",
    "                for pattern, placeholder in special_patterns.items():\n",
    "                    protected_match = re.sub(pattern, placeholder, protected_match)\n",
    "                \n",
    "                # 修复其他无效的转义序列\n",
    "                fixed_code = re.sub(r'\\\\(?![\"\\\\/bfnrtu])', r'\\\\\\\\', protected_match)\n",
    "\n",
    "                # 还原特殊操作符\n",
    "                for pattern, placeholder in special_patterns.items():\n",
    "                    fixed_code = fixed_code.replace(placeholder, pattern)\n",
    "                \n",
    "                try:\n",
    "                    match_json = json.loads(fixed_code)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Failed to parse JSON: {e}\")\n",
    "                    print(f\"Original match: {match}\")\n",
    "                    print(f\"Fixed code: {fixed_code}\")\n",
    "                    continue\n",
    "\n",
    "            # 处理不同类型的块\n",
    "            if type == \"other\":\n",
    "                try:\n",
    "                    blocks.append({ext_mark:match_json})\n",
    "                except ValueError:\n",
    "                    blocks.append({ext_mark:None})\n",
    "\n",
    "            elif type == \"code\":\n",
    "                try:\n",
    "                    blocks.append({match_json[\"HASH\"]:match_json[\"Code\"]})\n",
    "                except (ValueError, KeyError):\n",
    "                    blocks.append({match_json.get(\"HASH\", \"unknown\"):f\"could not parse the code block of {match_json}\"})\n",
    "            \n",
    "            elif type == \"report\":\n",
    "                try:\n",
    "                    blocks.append({match_json[\"HASH\"]:match_json})\n",
    "                except (ValueError, KeyError):\n",
    "                    blocks.append({match_json.get(\"HASH\", \"unknown\"):f\"could not parse the report block of {match_json}\"})\n",
    "\n",
    "        return blocks\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed_code {\n",
      "  \"HASH\": \"23C2CC6E\",\n",
      "  \"Code\": \"pop(china, 8250).\n",
      "pop(india, 5863).\n",
      "pop(ussr, 2521).\n",
      "pop(usa, 2119).\n",
      "pop(indonesia, 1276).\n",
      "pop(japan, 1097).\n",
      "pop(brazil, 1042).\n",
      "pop(bangladesh, 750).\n",
      "pop(pakistan, 682).\n",
      "pop(w_germany, 613).\n",
      "pop(nigeria, 613).\n",
      "pop(mexico, 581).\n",
      "pop(uk, 559).\n",
      "pop(italy, 554).\n",
      "pop(france, 525).\n",
      "pop(philippines, 415).\n",
      "pop(thailand, 410).\n",
      "pop(turkey, 383).\n",
      "pop(egypt, 364).\n",
      "pop(spain, 352).\n",
      "pop(poland, 337).\n",
      "pop(s_korea, 335).\n",
      "pop(iran, 320).\n",
      "pop(ethiopia, 272).\n",
      "pop(argentina, 251).\"\n",
      "}\n",
      "\n",
      "Failed to parse JSON: Invalid control character at: line 3 column 29 (char 52)\n",
      "Original match: {\n",
      "  \"HASH\": \"23C2CC6E\",\n",
      "  \"Code\": \"pop(china, 8250).\n",
      "pop(india, 5863).\n",
      "pop(ussr, 2521).\n",
      "pop(usa, 2119).\n",
      "pop(indonesia, 1276).\n",
      "pop(japan, 1097).\n",
      "pop(brazil, 1042).\n",
      "pop(bangladesh, 750).\n",
      "pop(pakistan, 682).\n",
      "pop(w_germany, 613).\n",
      "pop(nigeria, 613).\n",
      "pop(mexico, 581).\n",
      "pop(uk, 559).\n",
      "pop(italy, 554).\n",
      "pop(france, 525).\n",
      "pop(philippines, 415).\n",
      "pop(thailand, 410).\n",
      "pop(turkey, 383).\n",
      "pop(egypt, 364).\n",
      "pop(spain, 352).\n",
      "pop(poland, 337).\n",
      "pop(s_korea, 335).\n",
      "pop(iran, 320).\n",
      "pop(ethiopia, 272).\n",
      "pop(argentina, 251).\"\n",
      "}\n",
      "\n",
      "Fixed code: {\n",
      "  \"HASH\": \"23C2CC6E\",\n",
      "  \"Code\": \"pop(china, 8250).\n",
      "pop(india, 5863).\n",
      "pop(ussr, 2521).\n",
      "pop(usa, 2119).\n",
      "pop(indonesia, 1276).\n",
      "pop(japan, 1097).\n",
      "pop(brazil, 1042).\n",
      "pop(bangladesh, 750).\n",
      "pop(pakistan, 682).\n",
      "pop(w_germany, 613).\n",
      "pop(nigeria, 613).\n",
      "pop(mexico, 581).\n",
      "pop(uk, 559).\n",
      "pop(italy, 554).\n",
      "pop(france, 525).\n",
      "pop(philippines, 415).\n",
      "pop(thailand, 410).\n",
      "pop(turkey, 383).\n",
      "pop(egypt, 364).\n",
      "pop(spain, 352).\n",
      "pop(poland, 337).\n",
      "pop(s_korea, 335).\n",
      "pop(iran, 320).\n",
      "pop(ethiopia, 272).\n",
      "pop(argentina, 251).\"\n",
      "}\n",
      "\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "matches = _find_all_blocks(\"code\",model)\n",
    "print(matches)\n",
    "# data 现在就是一个标准 dict，可以直接操作\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for match in matches:\n",
    "    print(match)\n",
    "    res = json.loads(match)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_all_blocks(type: Literal[\"report\", \"code\", \"other\"], text: str, ext_mark: str = \"\") -> List[dict]:\n",
    "    \"\"\"\n",
    "    修复版的解析函数，正确处理ProbLog代码中的转义序列\n",
    "    \"\"\"\n",
    "    blocks: List[dict] = []\n",
    "    \n",
    "    # 根据类型选择正则表达式\n",
    "    if type == \"other\" or type == \"report\":\n",
    "        pattern = r\"```(?:report|[a-z]*)?\\n(.*?)```\"\n",
    "    elif type == \"code\":\n",
    "        pattern = r\"```(?:problog|[a-z]*)?\\n(.*?)```\"\n",
    "    else:\n",
    "        raise ValueError(\"you must choose from ['report','code','other']\")\n",
    "    \n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    \n",
    "    if not matches:\n",
    "        pattern = r\"```(?:json|[a-z]*)?\\n(.*?)```\"\n",
    "        matches = re.findall(pattern, text, re.DOTALL)\n",
    "    \n",
    "    for match in matches:\n",
    "        match = match.strip()\n",
    "        \n",
    "        try:\n",
    "            # 直接尝试解析JSON\n",
    "            match_json = json.loads(match)\n",
    "        except json.JSONDecodeError:\n",
    "            # 智能处理转义序列\n",
    "            try:\n",
    "                # 创建一个映射来临时替换特殊序列\n",
    "                replacements = {\n",
    "                    r'\\\\\\\\=': '___DOUBLE_BACKSLASH_EQUALS___',\n",
    "                    r'\\\\=': '___BACKSLASH_EQUALS___',\n",
    "                    r'\\\\n': '___BACKSLASH_N___',\n",
    "                    '\\n': '\\\\n',  # 将实际的换行符替换为转义的换行符\n",
    "                }\n",
    "                \n",
    "                processed_match = match\n",
    "                \n",
    "                # 首先处理实际的换行符\n",
    "                processed_match = processed_match.replace('\\n', '\\\\n')\n",
    "                \n",
    "                # 然后处理其他特殊序列（按长度降序，确保先处理长的）\n",
    "                for pattern, replacement in sorted(replacements.items(), key=lambda x: len(x[0]), reverse=True):\n",
    "                    if pattern != '\\n':  # 跳过已处理的换行符\n",
    "                        processed_match = processed_match.replace(pattern, replacement)\n",
    "                \n",
    "                # 尝试解析JSON\n",
    "                match_json = json.loads(processed_match)\n",
    "                \n",
    "                # 还原特殊序列\n",
    "                if isinstance(match_json, dict) and \"Code\" in match_json:\n",
    "                    code = match_json[\"Code\"]\n",
    "                    # 还原顺序也很重要\n",
    "                    for pattern, replacement in replacements.items():\n",
    "                        if pattern != '\\n':  # 不需要还原换行符\n",
    "                            code = code.replace(replacement, pattern)\n",
    "                    match_json[\"Code\"] = code\n",
    "                \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSON解析失败: {e}\")\n",
    "                print(f\"原始内容: {repr(match)}\")\n",
    "                print(f\"处理后内容: {repr(processed_match)}\")\n",
    "                continue\n",
    "        \n",
    "        # 根据类型处理解析结果\n",
    "        if type == \"other\":\n",
    "            blocks.append({ext_mark: match_json})\n",
    "        elif type == \"code\":\n",
    "            if isinstance(match_json, dict) and \"HASH\" in match_json and \"Code\" in match_json:\n",
    "                blocks.append({match_json[\"HASH\"]: match_json[\"Code\"]})\n",
    "            else:\n",
    "                blocks.append({\"unknown\": f\"code: invalid structure - {match_json}\"})\n",
    "        elif type == \"report\":\n",
    "            if isinstance(match_json, dict) and \"HASH\" in match_json:\n",
    "                blocks.append({match_json[\"HASH\"]: match_json})\n",
    "            else:\n",
    "                blocks.append({\"unknown\": f\"report: invalid structure - {match_json}\"})\n",
    "    \n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'CD6DE9CB': 'query_pop([C1,D1,C2,D2]) :- \\n    density(C1,D1),\\n    density(C2,D2),\\n    C1 \\\\\\\\= C2,\\n    abs(D1 - D2) =< max(D1,D2)*0.05.'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = 'Here is the completed code segment for the {LANGDA} placeholder:\\n\\n```problog\\n{\"HASH\": \"CD6DE9CB\",\"Code\": \"query_pop([C1,D1,C2,D2]) :- \\n    density(C1,D1),\\n    density(C2,D2),\\n    C1 \\\\\\\\= C2,\\n    abs(D1 - D2) =< max(D1,D2)*0.05.\"}\\n```\\n\\nThis implementation:\\n1. Uses the `density/2` predicate to get population densities for two countries\\n2. Ensures they are different countries with `C1 \\\\= C2`\\n3. Checks if their densities are within 5% of each other using arithmetic comparison\\n4. Returns the country names and densities in the format [C1,D1,C2,D2]\\n\\nThe 5% threshold can be adjusted by changing the 0.05 factor as needed.'\n",
    "\n",
    "rep = _find_all_blocks(\"code\", model)\n",
    "print(rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _replace_placeholder(template: str, replacement_list, placeholder=\"{{LANGDA}}\") -> str:\n",
    "    \"\"\"\n",
    "    Replaces placeholders in a template with items from a replacement list.\n",
    "    \n",
    "    args:\n",
    "        template: template with placeholders\n",
    "        replacement_list: the list of content that will fit into the placeholder.\n",
    "        placeholder: default as {{LANGDA}}\n",
    "        - if the value is None, the corresponding placeholder remains unchanged. \n",
    "        - valid input forms: List[str] or List[dict]\n",
    "    \"\"\"\n",
    "    # Extract values from replacement items\n",
    "    replace_str_list = []\n",
    "    if replacement_list and all(isinstance(item, dict) for item in replacement_list):\n",
    "        for item in replacement_list:\n",
    "            _, value = next(iter(item.items()))\n",
    "            replace_str_list.append(value)\n",
    "    else:\n",
    "        replace_str_list = replacement_list\n",
    "\n",
    "    # Split the template by placeholder\n",
    "    segments = template.split(placeholder)\n",
    "    result = segments[0]\n",
    "    \n",
    "    # Process each segment after the first\n",
    "    for i, seg in enumerate(segments[1:]):\n",
    "        # Check if we have a replacement for this placeholder\n",
    "        if i < len(replace_str_list) and replace_str_list[i] is not None:\n",
    "            replace_text = replace_str_list[i]\n",
    "            \n",
    "            # Check for duplicate punctuation at the boundaries\n",
    "            if replace_text and seg:\n",
    "                replace_ends_with_punct = replace_text.rstrip()[-1:] in \".,;\" if replace_text.rstrip() else False\n",
    "                seg_starts_with_punct = seg.lstrip()[:1] in \".,;\" if seg.lstrip() else False\n",
    "                \n",
    "                # Handle duplicate punctuation\n",
    "                if replace_ends_with_punct and seg_starts_with_punct:\n",
    "                    # Find position where the actual text ends in replace_text\n",
    "                    replace_text_end = len(replace_text.rstrip())\n",
    "                    # Find position where the actual text starts in seg\n",
    "                    seg_text_start = len(seg) - len(seg.lstrip())\n",
    "                    \n",
    "                    # Add replace_text without the trailing punctuation\n",
    "                    result += replace_text[:replace_text_end-1] \n",
    "                    # Add seg with its leading whitespace and punctuation\n",
    "                    result += seg[:seg_text_start+1] + seg[seg_text_start+1:]\n",
    "                    continue\n",
    "            \n",
    "            # Normal case: just add the replacement and segment\n",
    "            result += replace_text\n",
    "        else:\n",
    "            # No replacement available, keep the placeholder\n",
    "            result += placeholder\n",
    "        \n",
    "        result += seg\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "digit(O), all_different([O,R,N,Y,E,D]),\n",
      " sumdigit(C2, E, O, N, C3),\n",
      "\n",
      " digit(M), all_different([M,O,R,N,Y,E,D]),\n",
      " sumdigit(C3, S, M, O, C4),\n",
      "\n",
      "digit(S), leftdigit(S), all_different([S,M,O,R,N,Y,E,D]),\n",
      " sumdigit(C4, 0, 0, M, _)\n",
      "  . \n",
      " all_different([S,E,N,D,M,O,R,Y]).\n",
      "sumdigit(C, A, B, S, 0) :-\n",
      " X is C + A + B,\n",
      " X < 10,\n",
      " S = X.\n",
      "sumdigit(C, A, B, S, 1) :-\n",
      " X is C + A + B,\n",
      " X >= 10,\n",
      " S is X - 10.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = \"\"\"\n",
    " \n",
    "digit(O), all_different([O,R,N,Y,E,D]),\n",
    " sumdigit(C2, E, O, N, C3),\n",
    " \n",
    " digit(M), all_different([M,O,R,N,Y,E,D]),\n",
    " sumdigit(C3, S, M, O, C4),\n",
    " \n",
    "{{LANGDA}}\n",
    "  . \n",
    " all_different([S,E,N,D,M,O,R,Y]).\n",
    "sumdigit(C, A, B, S, 0) :-\n",
    " X is C + A + B,\n",
    " X < 10,\n",
    " S = X.\n",
    "sumdigit(C, A, B, S, 1) :-\n",
    " X is C + A + B,\n",
    " X >= 10,\n",
    " S is X - 10.\n",
    "\"\"\"\n",
    "match = \"\"\"digit(S), leftdigit(S), all_different([S,M,O,R,N,Y,E,D]),\n",
    " sumdigit(C4, 0, 0, M, _).  \"\"\"\n",
    "\n",
    "print(_replace_placeholder(model,[match]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "//the completed original code here\n",
      "```\n",
      "</Final_Answer>\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "In section <origin_code> and <generated_code> you will be give two codes,\n",
      "- in <origin_code> there's incomplete code with <langda> blocks.\n",
      "- in <generated_\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = \"\"\"\n",
    "//the completed original code here\n",
    "```\n",
    "</Final_Answer>\n",
    "\n",
    "*** split ***\n",
    "In section <origin_code> and <generated_code> you will be give two codes,\n",
    "- in <origin_code> there's incomplete code with {{LANGDA}} blocks.\n",
    "- in <generated_\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "lines = model.split(\"*** split ***\")\n",
    "print(lines[0])\n",
    "print(\"======================\")\n",
    "print(lines[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This new cat is cute, but I dont like it\n"
     ]
    }
   ],
   "source": [
    "def merge_with_overlap_tokens(s1: str, s2: str) -> str:\n",
    "    tokens1 = s1.split()\n",
    "    tokens2 = s2.split()\n",
    "    max_overlap = min(len(tokens1), len(tokens2))\n",
    "    for k in range(max_overlap, 0, -1):\n",
    "        if tokens1[-k:] == tokens2[:k]:\n",
    "            return \" \".join(tokens1 + tokens2[k:])\n",
    "    return \" \".join(tokens1 + tokens2)\n",
    "\n",
    "# 测试\n",
    "a = \"\"\"This new \n",
    "cat \n",
    " \n",
    "\"\"\"\n",
    "\n",
    "b = \"\"\"  new   cat is cute,\n",
    "but I dont like it\n",
    "\"\"\"\n",
    "print( merge_with_overlap_tokens(a, b) )\n",
    "# 输出: This new cat is cute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"\"\"\n",
    "% -------------------------\n",
    "% Basic rules of rock-paper-scissors\n",
    "% -------------------------\n",
    "% Three gestures\n",
    "move(rock).\n",
    "move(paper).\n",
    "move(scissor).\n",
    "% Win-lose relationship: X beats Y\n",
    "beats(rock, scissor).\n",
    "beats(scissor, paper).\n",
    "beats(paper, rock).\n",
    "% -------------------------\n",
    "% Calculate the result of the game\n",
    "% -------------------------\n",
    "result(X, X, draw) :-\n",
    "\n",
    "{{LANGDA}}\n",
    ".\n",
    "result(X, Y, win) :-\n",
    "{{LANGDA}}\n",
    ".\n",
    "result(X, Y, lose) :-\n",
    "{{LANGDA}}\n",
    ".\n",
    "% End of recursion: empty list corresponds to empty result\n",
    "play([], [], []).\n",
    "% Recursive advancement: take out each round of gestures, calculate the results, and continue\n",
    "play([P1|P1T], [P2|P2T], [R|Rs]) :-\n",
    "% The correct call is result(P1,P2,R), not semicolon\n",
    "result(P1, P2, R),\n",
    "% (Optional) Update the score according to R\n",
    "play(P1T, P2T, Rs).\n",
    "compute_score([], 0).\n",
    "{{LANGDA}}\n",
    ".\n",
    "{{LANGDA}}\n",
    ".\n",
    "{{LANGDA}}\n",
    ".\n",
    "compute_score([draw | Rs], S) :- compute_score(Rs, S1), S is S1.\n",
    "determine_winner(P1Moves,P2Moves,Winner) :- \n",
    " \n",
    "{{LANGDA}}\n",
    ",\n",
    "compute_score(Results,S), \n",
    "( S > 0, Winner = player1 \n",
    "; S < 0, Winner = player2 \n",
    "; S = 0, Winner = draw \n",
    ").\n",
    "query(determine_winner([rock,rock,rock],[paper,paper,scissor],W)).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "% -------------------------\n",
      "% Basic rules of rock-paper-scissors\n",
      "% -------------------------\n",
      "% Three gestures\n",
      "move(rock).\n",
      "move(paper).\n",
      "move(scissor).\n",
      "% Win-lose relationship: X beats Y\n",
      "beats(rock, scissor).\n",
      "beats(scissor, paper).\n",
      "beats(paper, rock).\n",
      "% -------------------------\n",
      "% Calculate the result of the game\n",
      "% -------------------------\n",
      "result(X, X, draw) :-\n",
      "\n",
      "move(X).\n",
      "result(X, Y, win) :-\n",
      "beats(X, Y).\n",
      "result(X, Y, lose) :-\n",
      "beats(Y, X).\n",
      "% End of recursion: empty list corresponds to empty result\n",
      "play([], [], []).\n",
      "% Recursive advancement: take out each round of gestures, calculate the results, and continue\n",
      "play([P1|P1T], [P2|P2T], [R|Rs]) :-\n",
      "% The correct call is result(P1,P2,R), not semicolon\n",
      "result(P1, P2, R),\n",
      "% (Optional) Update the score according to R\n",
      "play(P1T, P2T, Rs).\n",
      "compute_score([], 0).\n",
      "compute_score([win | Rs], S) :- compute_score(Rs, S1), S is S1 + 1.\n",
      "compute_score([lose | Rs], S) :- compute_score(Rs, S1), S is S1 - 1.\n",
      "compute_score([draw | Rs], S) :- compute_score(Rs, S1), S is S1.\n",
      "determine_winner(P1Moves,P2Moves,Winner) :- \n",
      "\n",
      "play(P1Moves, P2Moves, Results),\n",
      "compute_score(Results,S), \n",
      "( S > 0, Winner = player1 \n",
      "; S < 0, Winner = player2 \n",
      "; S = 0, Winner = draw \n",
      ").\n",
      "query(determine_winner([rock,rock,rock],[paper,paper,scissor],W)).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import uuid\n",
    "import hashlib\n",
    "from problog.program import PrologString, Clause, AnnotatedDisjunction, Term\n",
    "from typing import Literal, List, Union, Tuple, Dict, Any\n",
    "from langgraph.graph import END, StateGraph\n",
    "from state import BasicState, Mode\n",
    "from config import paths\n",
    "\n",
    "codes = [\n",
    "{\"3F277A35\": \"move(X).\"},{\"D91BB7A0\": \"beats(X, Y).\"},{\"0940BB04\": \"beats(Y, X).\"},\n",
    "{\"583E41B6\": \"compute_score([win | Rs], S) :- compute_score(Rs, S1), S is S1 + 1.\"},\n",
    "{\"D324979D\": \"compute_score([lose | Rs], S) :- compute_score(Rs, S1), S is S1 - 1.\"},\n",
    "{\"FD850DEC\": \"compute_score([draw | Rs], S) :- compute_score(Rs, S1), S is S1.\"},\n",
    "{\"3FEB17D7\": \"play(P1Moves, P2Moves, Results),\"}]\n",
    "\n",
    "import re\n",
    "\n",
    "def _tokenize_problog(s):\n",
    "    # Tokenize Prolog code into meaningful units, including punctuation\n",
    "    pattern = r\":-|\\w+|[^\\w\\s]\"\n",
    "    return [(m.group(), m.start(), m.end()) for m in re.finditer(pattern, s)]\n",
    "\n",
    "def _merge_problog_preserve(s1, s2):\n",
    "    # Tokenize both strings\n",
    "    tokens1 = _tokenize_problog(s1)\n",
    "    tokens2 = _tokenize_problog(s2)\n",
    "\n",
    "    texts1 = [t for t, _, _ in tokens1]\n",
    "    texts2 = [t for t, _, _ in tokens2]\n",
    "    \n",
    "    # Find the longest token overlap\n",
    "    max_k = min(len(texts1), len(texts2))\n",
    "    for k in range(max_k, 0, -1):\n",
    "        if texts1[-k:] == texts2[:k]:\n",
    "            # Calculate where to splice in the original s2\n",
    "            j_start = tokens2[k-1][2]\n",
    "            return s1 + s2[j_start:]\n",
    "    \n",
    "    # Fallback: no overlap\n",
    "    return s1 + s2\n",
    "\n",
    "def _replace_placeholder(template:str, replacement_list:Union[List[str],List[dict]], placeholder=\"{{LANGDA}}\") -> str:\n",
    "    \"\"\"\n",
    "    Replaces placeholders in a template with items from a replacement list.\n",
    "    \n",
    "    args:\n",
    "        template: template with placeholders\n",
    "        replacement_list: the list of content that will fit into the placeholder.\n",
    "        placeholder: default as {{LANGDA}}\n",
    "        - if the value is None, the corresponding placeholder remains unchanged. \n",
    "        - valid input forms: List[str] or List[dict]\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract values from replacement items\n",
    "    replace_str_list = []\n",
    "    if replacement_list and all(isinstance(item, dict) for item in replacement_list):\n",
    "        for item in replacement_list:\n",
    "            _, value = next(iter(item.items()))\n",
    "            replace_str_list.append(value)\n",
    "    else:\n",
    "        replace_str_list = replacement_list\n",
    "\n",
    "    # Split the template by placeholder\n",
    "    segments = template.split(placeholder)\n",
    "    result = segments[0]\n",
    "    \n",
    "    # Process each segment after the first\n",
    "    for i, seg in enumerate(segments[1:]):\n",
    "\n",
    "        replace_text = replace_str_list[i]\n",
    "        # Check if we have a replacement for this placeholder\n",
    "        if i < len(replace_str_list) and replace_text is not None:\n",
    "            # !!! SYNTAX FIX !!!\n",
    "            # deal with overlap: segment[0] & \"overlap text\" + \"overlap text\" & replace_text\n",
    "            result = _merge_problog_preserve(result, replace_text)\n",
    "        else:\n",
    "            # No replacement available, keep the placeholder\n",
    "            result += placeholder\n",
    "\n",
    "        # !!! SYNTAX FIX !!!\n",
    "        # deal with overlap: replace_text & \"overlap text\" + \"overlap text\" & segment[1]\n",
    "        result = _merge_problog_preserve(result, seg)\n",
    "        \n",
    "    return result\n",
    "\n",
    "print(_replace_placeholder(model,codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"HASH\": \"E09B4F54\",\"Report\": \"The code block implements a noisy-or combination for infection probabilities but contains logical errors in probability accumulation. The exclusionary conditions (`\\+`) prevent proper probability combination from multiple sources, and the `inf(Y)` predicate is not properly defined. This results in incorrect probability calculations (0.0316 vs expected higher values). The implementation needs to be revised to properly combine probabilities using ProbLog's noisy-or semantics and ensure all dependencies are correctly defined.\",\"Need_regenerate\": true,\"Dependencies\": []}\n",
      "\n",
      "{\"HASH\": \"E09B4F54\",\"Report\": \"The code block implements a noisy-or combination for infection probabilities but contains logical errors in probability accumulation. The exclusionary conditions (`\\+`) prevent proper probability combination from multiple sources, and the `inf(Y)` predicate is not properly defined. This results in incorrect probability calculations (0.0316 vs expected higher values). The implementation needs to be revised to properly combine probabilities using ProbLog's noisy-or semantics and ensure all dependencies are correctly defined.\",\"Need_regenerate\": true,\"Dependencies\": []}\n",
      "{ }\n",
      "Parsing failed: 'NoneType' object has no attribute 'group'\n",
      "Original content: '{\"HASH\": \"E09B4F54\",\"Report\": \"The code block implements a noisy-or combination for infection probabilities but contains logical errors in probability accumulation. The exclusionary conditions (`\\\\+`) prevent proper probability combination from multiple sources, and the `inf(Y)` predicate is not properly defined. This results in incorrect probability calculations (0.0316 vs expected higher values). The implementation needs to be revised to properly combine probabilities using ProbLog\\'s noisy-or semantics and ensure all dependencies are correctly defined.\",\"Need_regenerate\": true,\"Dependencies\": []}'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluated_result = '```report\\n{\"HASH\": \"E09B4F54\",\"Report\": \"The code block implements a noisy-or combination for infection probabilities but contains logical errors in probability accumulation. The exclusionary conditions (`\\\\+`) prevent proper probability combination from multiple sources, and the `inf(Y)` predicate is not properly defined. This results in incorrect probability calculations (0.0316 vs expected higher values). The implementation needs to be revised to properly combine probabilities using ProbLog\\'s noisy-or semantics and ensure all dependencies are correctly defined.\",\"Need_regenerate\": true,\"Dependencies\": []}\\n```'\n",
    "\n",
    "_find_all_blocks(\"report\",evaluated_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import uuid\n",
    "import hashlib\n",
    "from typing import Literal, List, Union, Tuple, Dict, Any\n",
    "\n",
    "def _robust_find_block(text:str, block_type:str=\"report\") -> List[str]:\n",
    "    \"\"\"Manually find all ``` blocks, this is essential, because we need to ignore ``` blocks in quote\"\"\"\n",
    "    blocks = []\n",
    "    i = 0\n",
    "    while i < len(text):\n",
    "        # Find Start pattern:\n",
    "        start_pattern = f\"```{block_type}\"\n",
    "        start_pos = text.find(start_pattern, i)\n",
    "        # print(\"**start_pos\",start_pos)\n",
    "        if start_pos == -1:\n",
    "            break\n",
    "\n",
    "        start_content = start_pos + len(start_pattern)\n",
    "\n",
    "        # Find REAL End pattern:\n",
    "        j = start_content\n",
    "        in_quotes = False\n",
    "        while j < len(text):\n",
    "            char = text[j]\n",
    "\n",
    "            # Escaped state check\n",
    "            if char == '\\\\' and j + 1 < len(text):\n",
    "                j += 2\n",
    "                continue\n",
    "\n",
    "            # Quoted state check\n",
    "            if char == '\"':\n",
    "                in_quotes = not in_quotes\n",
    "                # print(\"in_quotes\",in_quotes,text[j:j+20])\n",
    "\n",
    "            if not in_quotes and text[j:j+3] == '```':\n",
    "                block_content = text[start_content:j].strip()\n",
    "                blocks.append(block_content)\n",
    "                i = j + 3\n",
    "                # print(\"**block_content\",block_content)\n",
    "                break\n",
    "            j += 1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    return blocks\n",
    "\n",
    "def _find_all_blocks(type: Literal[\"report\", \"code\", \"final\"], text: str) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Find and parse code blocks in the text according to the specified type.\n",
    "    \n",
    "    Args:\n",
    "        type: The type of blocks to find (\"report\", \"code\", or \"final\")\n",
    "        text: The text to search for blocks\n",
    "        ext_mark: Optional mark for \"final\" type blocks\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries containing the parsed blocks\n",
    "    \"\"\"\n",
    "    blocks: List[dict] = []\n",
    "    # Select pattern based on purpose\n",
    "    if type == \"report\":\n",
    "        matches = _robust_find_block(text, \"report\")\n",
    "        if not matches:\n",
    "            matches = _robust_find_block(text, \"json\")\n",
    "        # print(\"**matches\",matches)\n",
    "    elif type == \"code\":\n",
    "        pattern = r\"```(?:problog|[a-z]*)?\\n(.*?)```\"\n",
    "        matches = re.findall(pattern, text, re.DOTALL)\n",
    "        if not matches:\n",
    "            pattern = r\"```(?:json|[a-z]*)?\\n(.*?)```\"\n",
    "            matches = re.findall(pattern, text, re.DOTALL)\n",
    "    else:\n",
    "        raise ValueError(\"you must choose from ['report','code','final']\")\n",
    "    \n",
    "    for match in matches:\n",
    "        match_str = match.strip()\n",
    "        \n",
    "        try:\n",
    "            # Try to parse the JSON directly\n",
    "            match_json = json.loads(match_str)\n",
    "            # When it succeed...\n",
    "            if type == \"final\":\n",
    "                blocks.append(match_json)\n",
    "            elif type == \"code\":\n",
    "                if isinstance(match_json, dict) and \"HASH\" in match_json and \"Code\" in match_json:\n",
    "                    blocks.append({match_json[\"HASH\"]: match_json[\"Code\"]})\n",
    "                else:\n",
    "                    raise TypeError(\"could not parse code, retry with manually construction\")\n",
    "            elif type == \"report\":\n",
    "                if isinstance(match_json, dict) and \"HASH\" in match_json:\n",
    "                    blocks.append({match_json[\"HASH\"]: match_json})\n",
    "                else:\n",
    "                    raise TypeError(\"could not parse report, retry with manually construction\")\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            # If JSON parsing fails, try manually constructing a dictionary\n",
    "            try:\n",
    "                if type == \"code\":\n",
    "                    hash_value = re.search(r'\"HASH\":\\s*\"([^\"]+)\"', match_str).group(1)\n",
    "                    code_value = re.search(r'\"Code\":\\s*\"((?:\\\\.|[^\"])*)\"', match_str).group(1)\n",
    "                    \n",
    "                    # Unescape the code\n",
    "                    code_value = code_value.replace('\\\\\"', '\"').replace('\\\\\\\\', '\\\\')\n",
    "                    blocks.append({hash_value: code_value})\n",
    "                \n",
    "                elif type == \"report\":\n",
    "                    hash_value = re.search(r'\"HASH\":\\s*\"([^\"]+)\"', match_str).group(1)\n",
    "                    error_summary = re.search(r'\"ErrorSummary\":\\s*\"((?:[^\"\\\\]|\\\\.)*)\"', match_str).group(1)\n",
    "                    suggested_fix = re.search(r'\"SuggestedFix\":\\s*\"((?:[^\"\\\\]|\\\\.)*)\"', match_str).group(1)\n",
    "\n",
    "                    need_regen = re.search(r'\"NeedRegenerate\":\\s*(true|false)', match_str).group(1)\n",
    "\n",
    "                    # Unescape the report\n",
    "                    error_summary = error_summary.replace('\\\\\"', '\"').replace('\\\\\\\\', '\\\\')\n",
    "                    suggested_fix = suggested_fix.replace('\\\\\"', '\"').replace('\\\\\\\\', '\\\\')\n",
    "                    blocks.append({hash_value: {\n",
    "                        \"HASH\":hash_value,\n",
    "                        \"ErrorSummary\": error_summary,\n",
    "                        \"SuggestedFix\": suggested_fix,\n",
    "                        \"NeedRegenerate\": need_regen\n",
    "                    }})\n",
    "\n",
    "                elif type == \"final\":\n",
    "                    # {{\"Report\": \"Fill in your analysis here...\", \"Validity_form\": true|false,\"Validity_result\": true|false}}\n",
    "                    report_value = re.search(r'\"Report\":\\s*\"((?:\\\\.|[^\"])*)\"', match_str).group(1)\n",
    "                    validity_form_value = re.search(r'\"Validity_form\":\\s*(true|false)', match_str).group(1)\n",
    "                    validity_result_value = re.search(r'\"Validity_result\":\\s*(true|false)', match_str).group(1)\n",
    "\n",
    "                    # Unescape the report\n",
    "                    report_value = report_value.replace('\\\\\"', '\"').replace('\\\\\\\\', '\\\\')\n",
    "                    blocks.append({\n",
    "                        \"Report\": report_value,\n",
    "                        \"Validity_form\": validity_form_value,\n",
    "                        \"Validity_result\": validity_result_value,\n",
    "                    })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Parsing failed: {e}\")\n",
    "                print(f\"Original content: {repr(match_str)}\")\n",
    "                continue\n",
    "    \n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_all_blocks(type: Literal[\"report\", \"code\", \"final\"], text: str) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Find and parse code blocks in the text according to the specified type.\n",
    "    \n",
    "    Args:\n",
    "        type: The type of blocks to find (\"report\", \"code\", or \"final\")\n",
    "        text: The text to search for blocks\n",
    "        ext_mark: Optional mark for \"final\" type blocks\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries containing the parsed blocks\n",
    "    \"\"\"\n",
    "    blocks: List[dict] = []\n",
    "    \n",
    "    # Select pattern based on purpose\n",
    "    if type == \"final\" or type == \"report\":\n",
    "        pattern = r\"```(?:report|[a-z]*)?\\n(.*?)```\"\n",
    "    elif type == \"code\":\n",
    "        pattern = r\"```(?:problog|[a-z]*)?\\n(.*?)```\"\n",
    "    else:\n",
    "        raise ValueError(\"you must choose from ['report','code','final']\")\n",
    "    \n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    \n",
    "    if not matches:\n",
    "        pattern = r\"```(?:json|[a-z]*)?\\n(.*?)```\"\n",
    "        matches = re.findall(pattern, text, re.DOTALL)\n",
    "    \n",
    "    for match in matches:\n",
    "        match_str = match.strip()\n",
    "        \n",
    "        try:\n",
    "            # Try to parse the JSON directly\n",
    "            match_json = json.loads(match_str)\n",
    "            # When it succeed...\n",
    "            if type == \"final\":\n",
    "                blocks.append(match_json)\n",
    "            elif type == \"code\":\n",
    "                if isinstance(match_json, dict) and \"HASH\" in match_json and \"Code\" in match_json:\n",
    "                    blocks.append({match_json[\"HASH\"]: match_json[\"Code\"]})\n",
    "                else:\n",
    "                    raise TypeError(\"could not parse code, retry with manually construction\")\n",
    "            elif type == \"report\":\n",
    "                if isinstance(match_json, dict) and \"HASH\" in match_json:\n",
    "                    blocks.append({match_json[\"HASH\"]: match_json})\n",
    "                else:\n",
    "                    raise TypeError(\"could not parse report, retry with manually construction\")\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            # If JSON parsing fails, try manually constructing a dictionary\n",
    "            try:\n",
    "                if type == \"code\":\n",
    "                    hash_value = re.search(r'\"HASH\":\\s*\"([^\"]+)\"', match_str).group(1)\n",
    "                    code_value = re.search(r'\"Code\":\\s*\"((?:\\\\.|[^\"])*)\"', match_str).group(1)\n",
    "                    \n",
    "                    # Unescape the code\n",
    "                    code_value = code_value.replace('\\\\\"', '\"').replace('\\\\\\\\', '\\\\')\n",
    "                    blocks.append({hash_value: code_value})\n",
    "                \n",
    "                elif type == \"report\":\n",
    "                    hash_value = re.search(r'\"HASH\":\\s*\"([^\"]+)\"', match_str).group(1)\n",
    "                    error_summary = re.search(r'\"ErrorSummary\":\\s*\"((?:\\\\.|[^\"])*)\"', match_str).group(1)\n",
    "                    suggested_fix = re.search(r'\"SuggestedFix\":\\s*\"((?:\\\\.|[^\"])*)\"', match_str).group(1)\n",
    "                    need_regen = re.search(r'\"NeedRegenerate\":\\s*(true|false)', match_str).group(1)\n",
    "\n",
    "                    # Unescape the report\n",
    "                    report_value = report_value.replace('\\\\\"', '\"').replace('\\\\\\\\', '\\\\')\n",
    "                    blocks.append({hash_value: {\n",
    "                        \"HASH\":hash_value,\n",
    "                        \"ErrorSummary\": error_summary,\n",
    "                        \"SuggestedFix\": suggested_fix,\n",
    "                        \"NeedRegenerate\": need_regen\n",
    "                    }})\n",
    "\n",
    "                elif type == \"final\":\n",
    "                    # {{\"Report\": \"Fill in your analysis here...\", \"Validity_form\": true|false,\"Validity_result\": true|false}}\n",
    "                    report_value = re.search(r'\"Report\":\\s*\"((?:\\\\.|[^\"])*)\"', match_str).group(1)\n",
    "                    validity_form_value = re.search(r'\"Validity_form\":\\s*(true|false)', match_str).group(1)\n",
    "                    validity_result_value = re.search(r'\"Validity_result\":\\s*(true|false)', match_str).group(1)\n",
    "\n",
    "                    # Unescape the report\n",
    "                    report_value = report_value.replace('\\\\\"', '\"').replace('\\\\\\\\', '\\\\')\n",
    "                    blocks.append({\n",
    "                        \"Report\": report_value,\n",
    "                        \"Validity_form\": validity_form_value,\n",
    "                        \"Validity_result\": validity_result_value,\n",
    "                    })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Parsing failed: {e}\")\n",
    "                print(f\"Original content: {repr(match_str)}\")\n",
    "                continue\n",
    "    \n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "转义的可能性: \\\\+, =\\\\=, \\\\=, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval1 = '```report\\n{\\n  \"HASH\": \"E09B4F54\",\\n  \"Report\": \"The `infFromContact/2` rule is partially implemented and contains critical issues \\\\+. It correctly handles the case where `X` is not susceptible (`\\\\+susceptible(X)`), but it does not account for the case where `X` is susceptible (which should have a higher infection probability of 0.8). \\+Additionally, the rule depends on the undefined `inf/1` predicate, causing a runtime error. The rule also fails to incorporate the travel risk component specified in the requirements.\",\\n  \"Need_regenerate\": true,\\n  \"Dependencies\": []\\n}\\n```'\n",
    "model_eval2 = 'Here is the evaluation report for each code module in JSON format:\\n\\n```report\\n[\\n    {\\n        \"HASH\": \"99C92279\",\\n        \"ErrorSummary\": \"No issues found\",\\n        \"SuggestedFix\": \"None needed\",\\n        \"Dependencies\": [],\\n        \"NeedRegenerate\": false\\n    },\\n    {\\n        \"HASH\": \"B6292BC0\",\\n        \"ErrorSummary\": \"No issues found\",\\n        \"SuggestedFix\": \"None needed\",\\n        \"Dependencies\": [],\\n        \"NeedRegenerate\": false\\n    },\\n    {\\n        \"HASH\": \"22D05CCC\",\\n        \"ErrorSummary\": \"The `expand` predicate fails to handle arithmetic operations correctly, causing a CallModeError when evaluating `prove(expand(double(3),6))`.\",\\n        \"SuggestedFix\": \"Modify the `expand` predicate to explicitly evaluate arithmetic expressions before proving `B`. For example:\\\\n```\\\\nprove(expand(A,B)) :-\\\\n    expand(A, B),\\\\n    (number(B) -> true ; prove(B)).\\\\n```\",\\n        \"Dependencies\": [],\\n        \"NeedRegenerate\": true\\n    },\\n    {\\n        \"HASH\": \"5AFBB985\",\\n        \"ErrorSummary\": \"No issues found\",\\n        \"SuggestedFix\": \"None needed\",\\n        \"Dependencies\": [],\\n        \"NeedRegenerate\": false\\n    },\\n    {\\n        \"HASH\": \"62B0CEA4\",\\n        \"ErrorSummary\": \"No issues found\",\\n        \"SuggestedFix\": \"None needed\",\\n        \"Dependencies\": [],\\n        \"NeedRegenerate\": false\\n    }\\n]\\n```'\n",
    "model_eval3 = \"\"\"\n",
    "```report\n",
    "{\n",
    "  \"HASH\": \"779B4ADF\",\n",
    "  \"Report\": \"The code block contains a critical syntax error due to the use of the `->` operator, which is not supported in ProbLog. This operator is used in the `cumulative_effect` predicate, causing the `goal_reached` predicate to fail. Additionally, the predicate does not fully implement the cumulative positioning behavior as intended. The logical flow is disrupted, and the predicate lacks proper handling of all cases. Recommendations include replacing the `->` operator with supported alternatives (e.g., `(Pos =:= OldPos, true) ; (Pos =\\= OldPos, cumulative_effect(Prev, OldPos))`), validating all predicates against ProbLog's supported syntax, and testing incrementally to ensure correct integration.\",\n",
    "  \"Need_regenerate\": true,\n",
    "  \"Dependencies\": []\n",
    "}\n",
    "```\n",
    "```report\n",
    "{\n",
    "  \"HASH\": \"E09B4F54\",\n",
    "  \"Report\": \"The `inf/1` rules in this code block are not correctly implementing the requirements. The issues include: 1) Incorrect handling of negation (`\\+ susceptible(X)`) in probabilistic contexts, 2) Probabilistic annotations (`0.6::inf(X)` and `0.8::inf(X)`) not being applied dynamically as intended, and 3) The `riskyTravel(X)` rule not being evaluated (as evidenced by test results showing only initial infection probabilities). The block needs regeneration to properly implement contact transmission (with susceptibility conditions) and travel risk probabilities.\",\n",
    "  \"Need_regenerate\": true,\n",
    "  \"Dependencies\": []\n",
    "}\n",
    "```\n",
    "\n",
    "\"\"\"\n",
    "model_eval4 = '```report\\n{\\n  \"HASH\": \"2D3597DC\",\\n  \"ErrorSummary\": \"The `almost_equal` predicate in the `parse/2` rules causes a `CallModeError` when comparing non-ground arguments, as it attempts to use `</2` with non-ground terms.\",\\n  \"SuggestedFix\": \"Modify the `almost_equal` predicate to ensure both arguments are ground before comparison. For example:\\\\n```prolog\\\\nalmost_equal(X, Y) :- \\\\n    ground(X), ground(Y), \\\\n    abs(X - Y) < 0.0001.\\\\nalmost_equal(X, Y) :- \\\\n    var(Y), \\\\n    Y is float(X).\\\\n```\\\\nAlso, ensure the `parse/2` rules handle the order of operations correctly if needed.\",\\n  \"Dependencies\": [],\\n  \"NeedRegenerate\": true\\n}\\n```'\n",
    "model_eval5 = '```report\\n{\\n  \"HASH\": \"2D3597DC\",\\n  \"ErrorSummary\": \"The `almost_equal` predicate in the `parse/2` rules causes a `CallModeError` due to non-ground arguments when evaluating `abs(X - Y) < 0.0001`. The second clause of `almost_equal` does not properly handle cases where `Y` is a variable.\",\\n  \"SuggestedFix\": \"Modify the `almost_equal` predicate to ensure both arguments are ground before comparison. For example:\\\\n```prolog\\\\nalmost_equal(X, Y) :- \\\\n    ground(X), ground(Y), \\\\n    abs(X - Y) < 0.0001.\\\\nalmost_equal(X, Y) :- \\\\n    var(Y), \\\\n    Y = float(X).\\\\n```\\\\nAlso, ensure the `parse/2` rules instantiate variables before calling `almost_equal`.\",\\n  \"Dependencies\": [],\\n  \"NeedRegenerate\": true\\n}\\n```'\n",
    "model_eval6 = '```report\\n{\\n  \"HASH\": \"EA5E8D55\",\\n  \"ErrorSummary\": \"The code uses the `->` operator incorrectly in Problog, leading to an \\'UnknownClause\\' error. The conditional logic for coin flips is not compatible with Problog\\'s probabilistic reasoning.\",\\n  \"SuggestedFix\": \"Replace the conditional logic with Problog\\'s probabilistic syntax. For example, rewrite the `coins_r/3` predicate as follows:\\\\n\\\\n```\\\\ncoins_r(SC, SC, 0).\\\\ncoins_r(SC, S, CNT) :-\\\\n    CNT > 0,\\\\n    CNT1 is CNT - 1,\\\\n    coin(C),  % Probabilistic fact\\\\n    SC1 is SC + 1,\\\\n    coins_r(SC1, S, CNT1).\\\\n```\\\\n\\\\nAlternatively, use Problog\\'s built-in probabilistic rules to model the coin flips.\",\\n  \"Dependencies\": [],\\n  \"NeedRegenerate\": true\\n}\\n```'\n",
    "model_eval7 =\"\"\"\n",
    "```report\n",
    "<Overall_Analysis> \n",
    "The provided ProbLog code aims to simulate a rock-paper-scissors game and determine the winner based on a series of moves. The code includes predicates for defining moves, calculating results, and computing scores. However, the test results indicate a failure due to an \"UnknownClause\" error, suggesting a missing or incorrectly defined predicate. The overall structure of the code is logical, but the error prevents it from executing as intended.\n",
    "</Overall_Analysis>\n",
    "\n",
    "<Error_Summary> \n",
    "1. **Test Failure**: The test `query(determine_winner([rock,rock,rock],[paper,paper,scissor],W))` failed with the error: `No clauses found for ''->'/2' at 48:16.`\n",
    "2. **Root Cause**: The error occurs because the `determine_winner` predicate is not properly defined or terminated. The code snippet for `determine_winner` is incomplete and lacks a proper closing parenthesis or semicolon, leading to a parsing error. Additionally, the `play/3` and `compute_score/2` predicates are correctly defined but not properly integrated into the `determine_winner` predicate.\n",
    "</Error_Summary>\n",
    "\n",
    "<Recommendations>\n",
    "1. **Fix Syntax Errors**: Ensure the `determine_winner` predicate is properly defined and terminated. For example:\n",
    "   ```prolog\n",
    "   determine_winner(P1Moves, P2Moves, Winner) :-\n",
    "       play(P1Moves, P2Moves, Results),\n",
    "       compute_score(Results, Score),\n",
    "       (Score > 0 -> Winner = 'Player 1';\n",
    "        Score < 0 -> Winner = 'Player 2';\n",
    "        Winner = 'Draw').\n",
    "   ```\n",
    "2. **Verify Predicate Definitions**: Double-check that all predicates (`move/1`, `beats/2`, `result/3`, `play/3`, `compute_score/2`) are correctly defined and accessible.\n",
    "3. **Test Incrementally**: Test each predicate individually to ensure they work as expected before combining them in the `determine_winner` predicate.\n",
    "4. **Debugging**: Use debugging tools or print statements to trace the execution flow and identify where the error occurs.\n",
    "</Recommendations>\n",
    "```\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<Overall_Analysis> \\nThe provided ProbLog code aims to simulate a rock-paper-scissors game and determine the winner based on a series of moves. The code includes predicates for defining moves, calculating results, and computing scores. However, the test results indicate a failure due to an \"UnknownClause\" error, suggesting a missing or incorrectly defined predicate. The overall structure of the code is logical, but the error prevents it from executing as intended.\\n</Overall_Analysis>\\n\\n<Error_Summary> \\n1. **Test Failure**: The test `query(determine_winner([rock,rock,rock],[paper,paper,scissor],W))` failed with the error: `No clauses found for \\'\\'->\\'/2\\' at 48:16.`\\n2. **Root Cause**: The error occurs because the `determine_winner` predicate is not properly defined or terminated. The code snippet for `determine_winner` is incomplete and lacks a proper closing parenthesis or semicolon, leading to a parsing error. Additionally, the `play/3` and `compute_score/2` predicates are correctly defined but not properly integrated into the `determine_winner` predicate.\\n</Error_Summary>\\n\\n<Recommendations>\\n1. **Fix Syntax Errors**: Ensure the `determine_winner` predicate is properly defined and terminated. For example:']\n"
     ]
    }
   ],
   "source": [
    "print(_robust_find_block(model_eval7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gnrt1 = \"\"\"\n",
    "Here are the extracted and formatted code blocks from the `<generated_code>` that correspond to the `<langda>` blocks in the `<origin_code>`:\n",
    "\n",
    "```problog\n",
    "{\\n\"HASH\": \"A\", \"Code\": \"prove(implies(P,Q)) :-\\n    \\+ prove(P); prove(Q).\"}\n",
    "```\n",
    "\n",
    "```problog\n",
    "{\\n\"HASH\": \"B\", \"Code\": \"=\\=\"}\n",
    "```\n",
    "\n",
    "```problog\n",
    "{\"HASH\": \"C\", \"Code\": \"prove(opposite(P)\\\\= :-    \\\\+ prove(P).\"}\n",
    "```\n",
    "\n",
    "```problog\n",
    "{\"HASH\": \"D\", \"Code\": \"prove(extend(List,Elem,Extended)) :-\\n    Extended = [Elem|List].\"}\n",
    "```\n",
    "\n",
    "```problog\n",
    "{\"HASH\": \"E\", \"Code\": \"expand(double(X), Y) :-\\n    Y is X * 2.\"}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gnrt2 = \"\"\"\n",
    "Here are the extracted and formatted code blocks from the generated code that correspond to the <langda> blocks in the origin code:\n",
    "\n",
    "```problog\n",
    "{\"HASH\": \"F\", \"Code\": \"flap_position(Time,Pos) :- \\n Time > 0, \\n attempted_flap_position(Time,Pos), \\n legal_flap_position(Pos).\"}\n",
    "```\n",
    "\n",
    "```problog\n",
    "{\"HASH\": \"G\", \"Code\": \"overrun_exception(Time) :-\\n Time > 0,\\n attempted_flap_position(Time,Pos),\\n \\+ legal_flap_position(Pos).\"}\n",
    "```\n",
    "\n",
    "```problog\n",
    "{\"HASH\": \"H\", \"Code\": \"goal_reached(Time) :-\\n flap_position(Time,Pos),\\n goal(Pos).\"}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gnrt3 = \"\"\"\n",
    "Here are the extracted and formatted code blocks from the `<generated_code>` that correspond to the `<langda>` blocks in the `<origin_code>`:\n",
    "\n",
    "```problog\n",
    "{\"HASH\": \"I\", \"Code\": \"0.5::open_door(A) ; 0.5::open_door(B) :-\\n    select_door(Selected),\\n    member(A, [1,2,3]),\\n    member(B, [1,2,3]),\\n    A \\\\= Selected,\\n    B \\\\= Selected,\\n    A \\\\= B,\\n    \\+ prize(A),\\n    \\+ prize(B).\"}\n",
    "```\n",
    "\n",
    "```problog\n",
    "{\"HASH\": \"J\", \"Code\": \"0.5::open_door(A) ; 0.5::open_door(B) :-    select_door(Selected),    member(A, [1,2,3]),    member(B, [1,2,3]),    A \\\\= Selected,    B \\\\= Selected,\\   A \\\\= B,    \\+ prize(A),    \\+ prize(B).\"}\n",
    "```\n",
    "\n",
    "```problog\n",
    "{\"HASH\": \"K\", \"Code\": \"open_door(A) :-\\n    select_door(Selected),\\n    member(A, [1,2,3]),\\n    A \\\\= Selected,\\n    \\+ prize(A),\\n    member(B, [1,2,3]),\\n    B \\\\= Selected,\\n    B \\\\= A,\\n    prize(B).\"}\n",
    "```\n",
    "\n",
    "```problog\n",
    "{\"HASH\": \"L\", \"Code\": \"win_keep :-\\n    select_door(Door),\\n    prize(Door).\"}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gnrt4 = \"\"\"\n",
    "Based on the origin_code and generated_code provided, I'll extract and format the code block that corresponds to the <Langda> section in the origin_code. Here's the completed code snippet for the infection logic:\n",
    "\n",
    "```problog\n",
    "{\"HASH\": \"E09B4F54\", \"Code\": \"0.6::inf(X) :- contact(X,Y), inf(Y), \\+susceptible(X).\\n0.8::inf(X) :- contact(X,Y), inf(Y), susceptible(X).\\n0.2::inf(X) :- riskyTravel(X), \\+inf(X).\\ninf(X) :- initialInf(X).\"}\n",
    "```\n",
    "\n",
    "This code implements:\n",
    "1. Contact transmission with 0.6 probability for non-susceptible individuals\n",
    "2. Contact transmission with 0.8 probability for susceptible individuals\n",
    "3. Additional 0.2 infection probability from risky travel\n",
    "4. Initial infection probability from initialInf/1 predicate\n",
    "\n",
    "The hash E09B4F54 matches the one specified in the <Langda> section of the origin_code.\n",
    "\n",
    "\n",
    "Based on the origin_code and generated_code provided, here's the extracted and formatted code block that corresponds to the <Langda> section:\n",
    "\n",
    "```problog\n",
    "{\"HASH\": \"E09B4F54\", \"Code\": \"0.6::inf(X) :- contact(X,Y), inf(Y), \\+susceptible(X).\\n0.8::inf(X) :- contact(X,Y), inf(Y), susceptiple(X).\\n0.2::inf(X) :- riskyTravel(X).\"}\n",
    "```\n",
    "\n",
    "This code implements:\n",
    "1. Contact transmission with different probabilities based on susceptibility\n",
    "2. Additional infection risk from travel\n",
    "3. Matches the requirements specified in the <Langda> section\n",
    "4. Uses the correct hash E09B4F54 from the origin code\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gnrt4 = \"\"\"\n",
    "Here are the extracted and formatted code blocks from the `<generated_code>` that correspond to the `<langda>` blocks in the `<origin_code>`:\n",
    "\n",
    "```problog\n",
    "{\"HASH\": \"C5B4A895\", \"Code\": \"0.5::open_door(A) ; 0.5::open_door(B) :-\\n    select_door(Selected),\\n    member(A, [1,2,3]),\\n    member(B, [1,2,3]),\\n    A \\\\= B,\\n    A \\\\= Selected,\\n    B \\\\= Selected,\\n    \\+ prize(A),\\n    \\+ prize(B).\"}\n",
    "```\n",
    "\n",
    "```problog\n",
    "{\"HASH\": \"338175EC\", \"Code\": \"open_door(A) :-\\n    select_door(Selected),\\n    member(A, [1,2,3]),\\n    A \\\\= Selected,\\n    \\+ prize(A),\\n    member(B, [1,2,3]),\\n    B \\\\= Selected,\\n    B \\\\= A,\\n    prize(B).\"}\n",
    "```\n",
    "\n",
    "```problog\n",
    "{\"HASH\": \"B73E5085\", \"Code\": \"win_keep :-\\n    select_door(Door),\\n    prize(Door).\"}\n",
    "```\n",
    "\n",
    "Here are the extracted and formatted code blocks from the <generated_code> that correspond to the <langda> blocks in <origin_code>:\n",
    "\n",
    "```problog\n",
    "{\"HASH\": \"592D75CA\", \"Code\": \"% Random Door Opening Rules\\nopen_door(D) :-\\n    select_door(S),\\n    prize(P),\\n    member(D, [1,2,3]),\\n    \\+ select_door(D),\\n    \\+ prize(D),\\n    random_select([D1, D2], [D1, D2]),\\n    (D = D1 ; D = D2).\"}\n",
    "```\n",
    "\n",
    "```problog\n",
    "{\"HASH\": \"592D75CA\", \"Code\": \"% Deterministic Door Opening Rules\\nopen_door(D) :-\\n    select_door(S),\\n    prize(P),\\n    member(D, [1,2,3]),\\n    \\+ select_door(D),\\n    (prize(D1), \\+ select_door(D1), D1 \\\\= D, \\+ prize(D) -> D = D1).\"}\n",
    "```\n",
    "\n",
    "Here are the extracted and formatted code blocks from the generated code that correspond to the <langda> blocks in the origin code:\n",
    "\n",
    "```problog\n",
    "{\"HASH\": \"B79F5C58\", \"Code\": \"flap_position(Time,Pos) :-\\n Time > 0,\\n attempted_flap_position(Time,Pos),\\n legal_flap_position(Pos).\"}\n",
    "```\n",
    "\n",
    "```problog\n",
    "{\"HASH\": \"E185A34B\", \"Code\": \"overrun_exception(Time) :-\\n Time > 0,\\n attempted_flap_position(Time,Pos),\\n \\+ legal_flap_position(Pos).\"}\n",
    "```\n",
    "\n",
    "```problog\n",
    "{\"HASH\": \"779B4ADF\", \"Code\": \"goal_reached(Time) :-\\n flap_position(Time,Pos),\\n goal(Pos).\"}\n",
    "```\n",
    "\"\"\"\n",
    "model_gnrt5 = \"\"\"Here are the extracted and formatted code blocks from the generated code that correspond to the <langda> blocks in the origin_code:\n",
    "\n",
    "```problog\n",
    "{\"HASH\": \"BCB17653\", \"Code\": \"at(key, Pos, T) :-\\n    carrying(key, T),\\n    at(robot, Pos, T).\\nat(key, Pos, s(T)) :-\\n    at(key, Pos, T),\\n    \\+ carrying(key, s(T)),\\n    \\+ do(goto(_), T).\"}\n",
    "```\"\"\"\n",
    "model_gnrt6 = \"\"\"Based on the provided origin_code and generated_code, I'll extract and format the code block that corresponds to the <langda> section in the origin_code.\n",
    "\n",
    "The <langda> section in origin_code contains a Code_Block with hash BCB17653, and this exact same code block appears in the generated_code (twice, but they're identical).\n",
    "\n",
    "Here's the formatted JSON output:\n",
    "\n",
    "```problog\n",
    "{\"HASH\": \"BCB17653\", \"Code\": \"at(key, Pos, T) :-\\n    carrying(key, T),\\n    at(robot, Pos, T).\\nat(key, Pos, s(T)) :-\\n    at(key, Pos, T),\\n    \\+ carrying(key, s(T)).\\nat(key, Pos, 0) :-\\n    initially_at(key, Pos).\"}\n",
    "```\n",
    "Here are the extracted and formatted code blocks from the generated code that correspond to the <langda> blocks in the origin_code:\n",
    "\n",
    "```problog\n",
    "{\"HASH\": \"BCB17653\", \"Code\": \"at(key, Pos, T) :-\\n    carrying(key, T),\\n    at(robot, Pos, T).\\nat(key, Pos, s(T)) :-\\n    at(key, Pos, T),\\n    \\+ carrying(key, s(T)),\\n    \\+ do(goto(_), T).\"}\n",
    "```\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"HASH\": \"BCB17653\", \"Code\": \"at(key, Pos, T) :-\n",
      "    carrying(key, T),\n",
      "    at(robot, Pos, T).\n",
      "at(key, Pos, s(T)) :-\n",
      "    at(key, Pos, T),\n",
      "    \\+ carrying(key, s(T)).\n",
      "at(key, Pos, 0) :-\n",
      "    initially_at(key, Pos).\"}\n",
      "\n",
      "{\"HASH\": \"BCB17653\", \"Code\": \"at(key, Pos, T) :-\n",
      "    carrying(key, T),\n",
      "    at(robot, Pos, T).\n",
      "at(key, Pos, s(T)) :-\n",
      "    at(key, Pos, T),\n",
      "    \\+ carrying(key, s(T)),\n",
      "    \\+ do(goto(_), T).\"}\n",
      "\n",
      "{\"HASH\": \"BCB17653\", \"Code\": \"at(key, Pos, T) :-\n",
      "    carrying(key, T),\n",
      "    at(robot, Pos, T).\n",
      "at(key, Pos, s(T)) :-\n",
      "    at(key, Pos, T),\n",
      "    \\+ carrying(key, s(T)).\n",
      "at(key, Pos, 0) :-\n",
      "    initially_at(key, Pos).\"}\n",
      "{ }\n",
      "{\"HASH\": \"BCB17653\", \"Code\": \"at(key, Pos, T) :-\n",
      "    carrying(key, T),\n",
      "    at(robot, Pos, T).\n",
      "at(key, Pos, s(T)) :-\n",
      "    at(key, Pos, T),\n",
      "    \\+ carrying(key, s(T)),\n",
      "    \\+ do(goto(_), T).\"}\n",
      "{ }\n",
      "[{'BCB17653': 'at(key, Pos, T) :-\\n    carrying(key, T),\\n    at(robot, Pos, T).\\nat(key, Pos, s(T)) :-\\n    at(key, Pos, T),\\n    \\\\+ carrying(key, s(T)).\\nat(key, Pos, 0) :-\\n    initially_at(key, Pos).'}, {'BCB17653': 'at(key, Pos, T) :-\\n    carrying(key, T),\\n    at(robot, Pos, T).\\nat(key, Pos, s(T)) :-\\n    at(key, Pos, T),\\n    \\\\+ carrying(key, s(T)),\\n    \\\\+ do(goto(_), T).'}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "ret = _find_all_blocks(\"code\",model_gnrt6)\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'at(key, Pos, T) :-\\n    carrying(key, T),\\n    at(robot, Pos, T).\\nat(key, Pos, s(T)) :-\\n    at(key, Pos, T),\\n    \\\\+ carrying(key, s(T)),\\n    \\\\+ do(goto(_), T).'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret[0][\"BCB17653\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_langda_and_lann_terms(text_list:List[Tuple[str, str, str]]) -> Tuple[List[str],List[dict],List[dict]]:\n",
    "    \"\"\"\n",
    "    Replace langda and lann predicates in the given text list.\n",
    "    And store informations in dictonary\n",
    "    Args:\n",
    "        text_list: List of tuples (code, comment, predicate_status)\n",
    "                   where predicate_status can be \"NONE\", \"BODY\", or \"END.\"\n",
    "    It calls the function: parse_lann_or_langda_content_to_dicts()\n",
    "    Returns:\n",
    "        Tuple of (modified text list, lann_dicts, langda_dicts)\n",
    "    \"\"\"\n",
    "    print(\"processing langda and lann terms...\")\n",
    "    # Initialize outputs\n",
    "    text_list_copy = text_list.copy()  # Create a copy to avoid modifying the original\n",
    "    lann_dicts:List[dict] = []\n",
    "    langda_dicts:List[dict] = []\n",
    "    result_text_list = []\n",
    "\n",
    "    # State variables\n",
    "    single_langda = []\n",
    "    single_lann = []\n",
    "    single_comment = []\n",
    "    in_langda = False\n",
    "    in_lann = False\n",
    "    langda_start = -1\n",
    "    lann_start = -1\n",
    "    \n",
    "    idl = 0\n",
    "    while idl < len(text_list_copy):\n",
    "        current_item:Tuple[str,str,str] = text_list_copy[idl]\n",
    "        if len(current_item) != 3:\n",
    "            raise ValueError(f\"Warning: Position {idl} has a uncorrect form: {current_item}\")\n",
    "            \n",
    "        (code, comment, predicate_status) = current_item\n",
    "        has_langda = code.startswith(\"langda(\")\n",
    "        has_lann = code.startswith(\"lann(\")\n",
    "\n",
    "        # -------------------- #           PART1            # -------------------- #\n",
    "        # -------------------- Process single lann predicates -------------------- #\n",
    "        # Start of lann predicate\n",
    "        if has_lann and not in_lann:\n",
    "            in_lann = True\n",
    "            lann_start = idl    # mark the start of lann predicate\n",
    "            single_lann = []\n",
    "            single_comment = []\n",
    "            if not idl + 1 < len(text_list_copy):\n",
    "                raise ValueError(\"The code is incomplete, please check your lann predicates.\")\n",
    "\n",
    "\n",
    "        # -------------------- #            PART2             # -------------------- #\n",
    "        # -------------------- Process single langda predicates -------------------- #\n",
    "        # Start of langda predicate\n",
    "        if has_langda and not in_langda:\n",
    "            in_langda = True\n",
    "            langda_start = idl     # mark the start of langda predicate\n",
    "            single_langda = []\n",
    "            single_comment = []\n",
    "\n",
    "\n",
    "        if in_lann:\n",
    "            # Middle of lann predicate\n",
    "            if predicate_status == \"BODY\":\n",
    "                single_lann.append(code)\n",
    "                single_comment.append(comment)\n",
    "\n",
    "            # End of lann predicate\n",
    "            elif predicate_status == \"END.\":\n",
    "                # Add the current segment\n",
    "                single_lann.append(code)\n",
    "                single_comment.append(comment)\n",
    "                \n",
    "                # Create the full lann term and its dict representation\n",
    "                full_lann_term = \"\".join(single_lann)\n",
    "                full_lann_content = full_lann_term[5:-1]\n",
    "                lann_dict = parse_lann_or_langda_content_to_dicts(full_lann_content)\n",
    "                lann_dicts.append(lann_dict)\n",
    "\n",
    "                # -------------------- # REPLACE # -------------------- #\n",
    "                # Replace the original segments with our processed version:\n",
    "                # nn(net_name,[X],Y,[1,2,3])::digit(X,Y).\n",
    "                nn_term = f\"nn({','.join([k for k in lann_dict.keys()])})\"\n",
    "                \n",
    "                # Filter out empty comments before joining (optional, same as langda)\n",
    "                filtered_comments = [c for c in single_comment if c]\n",
    "                joined_comments = \"\\n\".join(filtered_comments) + \"\\n\" + nn_term\n",
    "                \n",
    "                # print(\"#####nn_term:\", nn_term)\n",
    "                # print(\"#####full_lann_term:\", full_lann_term)\n",
    "                # print(\"#####full_lann_content:\", full_lann_content) \n",
    "                # print(\"#####lann_dict:\", lann_dict)\n",
    "                # print(\"#####single_lann:\", single_lann)\n",
    "                # print(\"#####single_comment:\", single_comment)\n",
    "                # print(\"#####filtered_comments:\", filtered_comments)\n",
    "                # print(\"#####start,idl\", lann_start, idl)\n",
    "                # print(\"#####[lann_start:idl]:\", text_list_copy[lann_start:idl+1])\n",
    "                \n",
    "                # Replace all items from lann_start to idl with a single item containing our joined comments and term\n",
    "                text_list_copy[lann_start:idl+1] = [(joined_comments, \"\", \"NONE\")]\n",
    "\n",
    "                # Adjust index to continue after our replacement - always advance by 1 \n",
    "                # since we replaced with a single item\n",
    "                idl = lann_start\n",
    "\n",
    "                # Reset state\n",
    "                lann_dict = {}\n",
    "                in_lann = False\n",
    "\n",
    "\n",
    "        elif in_langda:\n",
    "            # Middle of langda predicate\n",
    "            if predicate_status == \"BODY\":\n",
    "                single_langda.append(code)\n",
    "                single_comment.append(comment)\n",
    "            \n",
    "            # End of langda predicate\n",
    "            elif predicate_status == \"END.\":\n",
    "                # Add the current segment\n",
    "                single_langda.append(code)\n",
    "                single_comment.append(comment)\n",
    "                \n",
    "                # Create the full langda term and its dict representation\n",
    "                full_langda_term = \" \".join(single_langda)\n",
    "                full_langda_content = full_langda_term[7:-1]\n",
    "                langda_dict = parse_lann_or_langda_content_to_dicts(full_langda_content)\n",
    "                langda_dicts.append(langda_dict)\n",
    "                \n",
    "                # -------------------- # REPLACE # -------------------- #\n",
    "                # Replace the original segments with our processed version:\n",
    "                # # comment1...\n",
    "                # # comment2...\n",
    "                #  \"\\n{{LANGDA}}\\n\"\n",
    "                \n",
    "                # Filter out empty comments before joining\n",
    "                filtered_comments = [c for c in single_comment if c]\n",
    "                joined_comments = \"\\n\".join(filtered_comments) + \"\\n{{LANGDA}}\"\n",
    "                \n",
    "                # print(\"#####full_langda_term:\", full_langda_term)\n",
    "                # print(\"#####full_langda_content:\", full_langda_content)\n",
    "                # print(\"#####langda_dict:\", langda_dict)\n",
    "                # print(\"#####single_langda:\", single_langda)\n",
    "                # print(\"#####single_comment:\", single_comment)\n",
    "                # print(\"#####filtered_comments:\", filtered_comments)\n",
    "                # print(\"#####start,idl\", langda_start, idl)\n",
    "                # print(\"#####[langda_start:idl]:\", text_list_copy[langda_start:idl+1])\n",
    "                \n",
    "                # Replace all items from langda_start to idl with a single item containing our joined comments\n",
    "                text_list_copy[langda_start:idl+1] = [(joined_comments, \"\", \"NONE\")]\n",
    "                \n",
    "                # Adjust index to continue after our replacement - always advance by 1\n",
    "                # since we replaced with a single item\n",
    "                idl = langda_start\n",
    "                \n",
    "                # Reset state\n",
    "                langda_dict = {}\n",
    "                in_langda = False\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "        idl += 1\n",
    "    \n",
    "    return [item[0] for item in text_list_copy], lann_dicts, langda_dicts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

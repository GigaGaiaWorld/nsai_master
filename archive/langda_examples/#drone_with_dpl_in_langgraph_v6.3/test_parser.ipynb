{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'Here is the completed code segment with all population data filled in:\\n\\n```problog\\n{\\n  \"HASH\": \"23C2CC6E\",\\n  \"Code\": \"pop(china, 8250).\\npop(india, 5863).\\npop(ussr, 2521).\\npop(usa, 2119).\\npop(indonesia, 1276).\\npop(japan, 1097).\\npop(brazil, 1042).\\npop(bangladesh, 750).\\npop(pakistan, 682).\\npop(w_germany, 613).\\npop(nigeria, 613).\\npop(mexico, 581).\\npop(uk, 559).\\npop(italy, 554).\\npop(france, 525).\\npop(philippines, 415).\\npop(thailand, 410).\\npop(turkey, 383).\\npop(egypt, 364).\\npop(spain, 352).\\npop(poland, 337).\\npop(s_korea, 335).\\npop(iran, 320).\\npop(ethiopia, 272).\\npop(argentina, 251).\"\\n}\\n```'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import uuid\n",
    "import hashlib\n",
    "from problog.program import PrologString, Clause, AnnotatedDisjunction, Term\n",
    "from typing import Literal, List, Union, Tuple, Dict, Any\n",
    "from langgraph.graph import END, StateGraph\n",
    "from state import BasicState, Mode\n",
    "from config import paths\n",
    "def _find_all_blocks(type:Literal[\"report\",\"code\",\"other\"], text:str, ext_mark:str=\"\") -> List[dict]:\n",
    "    \"\"\"\n",
    "    find block with certain patterns in json form.\n",
    "    \"\"\"\n",
    "    blocks:List[dict] = []\n",
    "    \n",
    "    if type == \"other\" or type == \"report\":\n",
    "        pattern = r\"```(?:report|[a-z]*)?\\n(.*?)```\"\n",
    "    elif type == \"code\":\n",
    "        pattern = r\"```(?:problog|[a-z]*)?\\n(.*?)```\"\n",
    "    else:\n",
    "        raise ValueError(\"you must choose from ['report','code','other']\")\n",
    "    \n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    if not matches:\n",
    "        pattern = r\"```(?:json|[a-z]*)?\\n(.*?)```\"\n",
    "        matches = re.findall(pattern, text, re.DOTALL)\n",
    "\n",
    "    if matches:\n",
    "        for match in matches:\n",
    "            try:\n",
    "                # 直接尝试解析 JSON\n",
    "                match_json = json.loads(match)\n",
    "            except json.JSONDecodeError:\n",
    "                # 对于 ProbLog 代码，需要特殊处理转义\n",
    "                # 保护 ProbLog 特殊操作符\n",
    "                protected_match = match\n",
    "                \n",
    "                # 创建特殊操作符的映射\n",
    "                special_patterns = {\n",
    "                    r'\\\\\\\\=': '<<<BACKSLASH_BACKSLASH_EQUALS>>>',\n",
    "                    r'\\\\\\\\\\\\\\\\=': '<<<QUAD_BACKSLASH_EQUALS>>>',  # 处理已经有四个反斜杠的情况\n",
    "                    r'\\\\n'        : '<<<ESCAPED_NEWLINE>>>',      # 新增这一行\n",
    "                }\n",
    "                # 临时替换特殊操作符\n",
    "                for pattern, placeholder in special_patterns.items():\n",
    "                    protected_match = re.sub(pattern, placeholder, protected_match)\n",
    "                \n",
    "                # 修复其他无效的转义序列\n",
    "                fixed_code = re.sub(r'\\\\(?![\"\\\\/bfnrtu])', r'\\\\\\\\', protected_match)\n",
    "\n",
    "                # 还原特殊操作符\n",
    "                for pattern, placeholder in special_patterns.items():\n",
    "                    fixed_code = fixed_code.replace(placeholder, pattern)\n",
    "                \n",
    "                try:\n",
    "                    match_json = json.loads(fixed_code)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Failed to parse JSON: {e}\")\n",
    "                    print(f\"Original match: {match}\")\n",
    "                    print(f\"Fixed code: {fixed_code}\")\n",
    "                    continue\n",
    "\n",
    "            # 处理不同类型的块\n",
    "            if type == \"other\":\n",
    "                try:\n",
    "                    blocks.append({ext_mark:match_json})\n",
    "                except ValueError:\n",
    "                    blocks.append({ext_mark:None})\n",
    "\n",
    "            elif type == \"code\":\n",
    "                try:\n",
    "                    blocks.append({match_json[\"HASH\"]:match_json[\"Code\"]})\n",
    "                except (ValueError, KeyError):\n",
    "                    blocks.append({match_json.get(\"HASH\", \"unknown\"):f\"could not parse the code block of {match_json}\"})\n",
    "            \n",
    "            elif type == \"report\":\n",
    "                try:\n",
    "                    blocks.append({match_json[\"HASH\"]:match_json})\n",
    "                except (ValueError, KeyError):\n",
    "                    blocks.append({match_json.get(\"HASH\", \"unknown\"):f\"could not parse the report block of {match_json}\"})\n",
    "\n",
    "        return blocks\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed_code {\n",
      "  \"HASH\": \"23C2CC6E\",\n",
      "  \"Code\": \"pop(china, 8250).\n",
      "pop(india, 5863).\n",
      "pop(ussr, 2521).\n",
      "pop(usa, 2119).\n",
      "pop(indonesia, 1276).\n",
      "pop(japan, 1097).\n",
      "pop(brazil, 1042).\n",
      "pop(bangladesh, 750).\n",
      "pop(pakistan, 682).\n",
      "pop(w_germany, 613).\n",
      "pop(nigeria, 613).\n",
      "pop(mexico, 581).\n",
      "pop(uk, 559).\n",
      "pop(italy, 554).\n",
      "pop(france, 525).\n",
      "pop(philippines, 415).\n",
      "pop(thailand, 410).\n",
      "pop(turkey, 383).\n",
      "pop(egypt, 364).\n",
      "pop(spain, 352).\n",
      "pop(poland, 337).\n",
      "pop(s_korea, 335).\n",
      "pop(iran, 320).\n",
      "pop(ethiopia, 272).\n",
      "pop(argentina, 251).\"\n",
      "}\n",
      "\n",
      "Failed to parse JSON: Invalid control character at: line 3 column 29 (char 52)\n",
      "Original match: {\n",
      "  \"HASH\": \"23C2CC6E\",\n",
      "  \"Code\": \"pop(china, 8250).\n",
      "pop(india, 5863).\n",
      "pop(ussr, 2521).\n",
      "pop(usa, 2119).\n",
      "pop(indonesia, 1276).\n",
      "pop(japan, 1097).\n",
      "pop(brazil, 1042).\n",
      "pop(bangladesh, 750).\n",
      "pop(pakistan, 682).\n",
      "pop(w_germany, 613).\n",
      "pop(nigeria, 613).\n",
      "pop(mexico, 581).\n",
      "pop(uk, 559).\n",
      "pop(italy, 554).\n",
      "pop(france, 525).\n",
      "pop(philippines, 415).\n",
      "pop(thailand, 410).\n",
      "pop(turkey, 383).\n",
      "pop(egypt, 364).\n",
      "pop(spain, 352).\n",
      "pop(poland, 337).\n",
      "pop(s_korea, 335).\n",
      "pop(iran, 320).\n",
      "pop(ethiopia, 272).\n",
      "pop(argentina, 251).\"\n",
      "}\n",
      "\n",
      "Fixed code: {\n",
      "  \"HASH\": \"23C2CC6E\",\n",
      "  \"Code\": \"pop(china, 8250).\n",
      "pop(india, 5863).\n",
      "pop(ussr, 2521).\n",
      "pop(usa, 2119).\n",
      "pop(indonesia, 1276).\n",
      "pop(japan, 1097).\n",
      "pop(brazil, 1042).\n",
      "pop(bangladesh, 750).\n",
      "pop(pakistan, 682).\n",
      "pop(w_germany, 613).\n",
      "pop(nigeria, 613).\n",
      "pop(mexico, 581).\n",
      "pop(uk, 559).\n",
      "pop(italy, 554).\n",
      "pop(france, 525).\n",
      "pop(philippines, 415).\n",
      "pop(thailand, 410).\n",
      "pop(turkey, 383).\n",
      "pop(egypt, 364).\n",
      "pop(spain, 352).\n",
      "pop(poland, 337).\n",
      "pop(s_korea, 335).\n",
      "pop(iran, 320).\n",
      "pop(ethiopia, 272).\n",
      "pop(argentina, 251).\"\n",
      "}\n",
      "\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "matches = _find_all_blocks(\"code\",model)\n",
    "print(matches)\n",
    "# data 现在就是一个标准 dict，可以直接操作\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for match in matches:\n",
    "    print(match)\n",
    "    res = json.loads(match)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_all_blocks(type: Literal[\"report\", \"code\", \"other\"], text: str, ext_mark: str = \"\") -> List[dict]:\n",
    "    \"\"\"\n",
    "    修复版的解析函数，正确处理ProbLog代码中的转义序列\n",
    "    \"\"\"\n",
    "    blocks: List[dict] = []\n",
    "    \n",
    "    # 根据类型选择正则表达式\n",
    "    if type == \"other\" or type == \"report\":\n",
    "        pattern = r\"```(?:report|[a-z]*)?\\n(.*?)```\"\n",
    "    elif type == \"code\":\n",
    "        pattern = r\"```(?:problog|[a-z]*)?\\n(.*?)```\"\n",
    "    else:\n",
    "        raise ValueError(\"you must choose from ['report','code','other']\")\n",
    "    \n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    \n",
    "    if not matches:\n",
    "        pattern = r\"```(?:json|[a-z]*)?\\n(.*?)```\"\n",
    "        matches = re.findall(pattern, text, re.DOTALL)\n",
    "    \n",
    "    for match in matches:\n",
    "        match = match.strip()\n",
    "        \n",
    "        try:\n",
    "            # 直接尝试解析JSON\n",
    "            match_json = json.loads(match)\n",
    "        except json.JSONDecodeError:\n",
    "            # 智能处理转义序列\n",
    "            try:\n",
    "                # 创建一个映射来临时替换特殊序列\n",
    "                replacements = {\n",
    "                    r'\\\\\\\\=': '___DOUBLE_BACKSLASH_EQUALS___',\n",
    "                    r'\\\\=': '___BACKSLASH_EQUALS___',\n",
    "                    r'\\\\n': '___BACKSLASH_N___',\n",
    "                    '\\n': '\\\\n',  # 将实际的换行符替换为转义的换行符\n",
    "                }\n",
    "                \n",
    "                processed_match = match\n",
    "                \n",
    "                # 首先处理实际的换行符\n",
    "                processed_match = processed_match.replace('\\n', '\\\\n')\n",
    "                \n",
    "                # 然后处理其他特殊序列（按长度降序，确保先处理长的）\n",
    "                for pattern, replacement in sorted(replacements.items(), key=lambda x: len(x[0]), reverse=True):\n",
    "                    if pattern != '\\n':  # 跳过已处理的换行符\n",
    "                        processed_match = processed_match.replace(pattern, replacement)\n",
    "                \n",
    "                # 尝试解析JSON\n",
    "                match_json = json.loads(processed_match)\n",
    "                \n",
    "                # 还原特殊序列\n",
    "                if isinstance(match_json, dict) and \"Code\" in match_json:\n",
    "                    code = match_json[\"Code\"]\n",
    "                    # 还原顺序也很重要\n",
    "                    for pattern, replacement in replacements.items():\n",
    "                        if pattern != '\\n':  # 不需要还原换行符\n",
    "                            code = code.replace(replacement, pattern)\n",
    "                    match_json[\"Code\"] = code\n",
    "                \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSON解析失败: {e}\")\n",
    "                print(f\"原始内容: {repr(match)}\")\n",
    "                print(f\"处理后内容: {repr(processed_match)}\")\n",
    "                continue\n",
    "        \n",
    "        # 根据类型处理解析结果\n",
    "        if type == \"other\":\n",
    "            blocks.append({ext_mark: match_json})\n",
    "        elif type == \"code\":\n",
    "            if isinstance(match_json, dict) and \"HASH\" in match_json and \"Code\" in match_json:\n",
    "                blocks.append({match_json[\"HASH\"]: match_json[\"Code\"]})\n",
    "            else:\n",
    "                blocks.append({\"unknown\": f\"code: invalid structure - {match_json}\"})\n",
    "        elif type == \"report\":\n",
    "            if isinstance(match_json, dict) and \"HASH\" in match_json:\n",
    "                blocks.append({match_json[\"HASH\"]: match_json})\n",
    "            else:\n",
    "                blocks.append({\"unknown\": f\"report: invalid structure - {match_json}\"})\n",
    "    \n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'CD6DE9CB': 'query_pop([C1,D1,C2,D2]) :- \\n    density(C1,D1),\\n    density(C2,D2),\\n    C1 \\\\\\\\= C2,\\n    abs(D1 - D2) =< max(D1,D2)*0.05.'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = 'Here is the completed code segment for the {LANGDA} placeholder:\\n\\n```problog\\n{\"HASH\": \"CD6DE9CB\",\"Code\": \"query_pop([C1,D1,C2,D2]) :- \\n    density(C1,D1),\\n    density(C2,D2),\\n    C1 \\\\\\\\= C2,\\n    abs(D1 - D2) =< max(D1,D2)*0.05.\"}\\n```\\n\\nThis implementation:\\n1. Uses the `density/2` predicate to get population densities for two countries\\n2. Ensures they are different countries with `C1 \\\\= C2`\\n3. Checks if their densities are within 5% of each other using arithmetic comparison\\n4. Returns the country names and densities in the format [C1,D1,C2,D2]\\n\\nThe 5% threshold can be adjusted by changing the 0.05 factor as needed.'\n",
    "\n",
    "rep = _find_all_blocks(\"code\", model)\n",
    "print(rep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

###========================== IN generate_data.py FILE: ==========================###
1.新加了 Generate "non-event label" data "initiatedAt" 和 Shuffle lines in "initiatedAt", 以增加“反例”并打乱顺序
2.尝试使用并行的数据(0,1,2) (3,4), 但是效果很糟糕, 数据生成的方式可能有问题, 或者规则集和生成数据的逻辑有不一致的问题 #####
# ===> 网络预测出现严重偏移的问题出现在逻辑内部 <=== #
# 在尝试run.py中和nn谓词中交换位置后, 发现没有影响, 说明不是网络本身的问题
### Prolog规则中顺序对神经符号系统学习的巨大影响 #####
    # 尝试使用单个网络, 效果很好
    # 尝试单个网络, 使用并行的数据, 出现了相似的问题
    # 尝试不同的组合, event(1,X,Y), 交换网络顺序, 分开,合并,结果发现,就是prolog顺序导致的, 使用了非并行数据
    # 排在最后的类别不会被预测, 这非常愚蠢. 这是否意味写在后面的子句没法进行gradient?

######=====================###=====### IN coin.pl FILE: ###=====###=====================######
我开始怀疑之前的混淆矩阵偏置, 是不是因为迭代次数不足的原因? 因为下面是coin网络进行训练的过程: ==> 并不是, 测试更多的迭代后发现, 就是逻辑导致的... ==>表现为另一个分支(网络分支)完全没有预测
###########对比实验: 方法一: 
outcome(1, ID1, ID2) :- (abs(ID1 - ID2) =:= 2).
outcome(0, ID1, ID2) :- (abs(ID1 - ID2) =\= 2).
        Epoch1: [[  0 120]     Epoch4:[[117   3]     Epoch5:[[97 23]
                [  0 128]]            [  7 121]]            [43 85]]

###########对比实验: 方法二: 
outcome(1, ID1, ID2) :- (abs(ID1 - ID2) =:= 2).
outcome(0, ID1, ID2) :- \+outcome(1, ID1, ID2).
        Epoch1: [[  0 120]                           Epoch5: [[116   4]
                [  0 128]]                                   [  4 124]]
也有可能是因为测试的类别比较少, 还显现不出弊端

{detectEvent(sequence=1,0): (0.9837276935622469, array([1.00000000e+00, 2.77009998e-10, 9.83727694e-01, 1.62723623e-02])), 
 detectEvent(sequence=0,0): (0.0162723625941176, array([2.77009998e-10, 1.00000000e+00, 1.62723623e-02, 9.83727694e-01]))}


###================================ IN test.ipynb FILE: ================================###
对于两个除了下面部分, 其余内容完全相同的规则集:
模型1: model_iter_logic.mdl   ==> coin_basic.pl
outcome(1, ID1, ID2) :- (abs(ID1 - ID2) =:= 2).
outcome(0, ID1, ID2) :- (abs(ID1 - ID2) =\= 2).

模型2: model_iter_listall.mdl ==> coin_basic_modify.pl
outcome(1, 0, 2).
outcome(0, 0, 3).
outcome(0, 1, 2).
outcome(1, 1, 3).

=============================================
它们训练出来的模型分别使用对方的规则集进行测试(在未偏置的普通数据上), 结果完全一致, 表明只要逻辑一致, 使用的规则集本身并不会影响推理,
下面使用偏置数据进行测试: 相同?
model_iter_logic.mdl ==> coin_basic.pl
 [[142  63]
 [ 50 146]]

model_iter_logic.mdl ==> coin_basic_modify.pl
[[142  63]
 [ 50 146]]

model_iter_listall.mdl ==> coin_basic.pl
[[140  65]
 [ 48 148]]

model_iter_listall.mdl ==> coin_basic_modify.pl
 [[140  65]
 [ 48 148]]

[[142  63]
 [ 50 146]]
=============================================
outcome(1, 0, 2,T) :- \+between(100, 250, T).   # 不管我尝试如何组合between条件, 结果都不会比原来的结果更好
outcome(0, 0, 3,T) :- \+between(100, 250, T).   # 但是似乎Deepproblog的神经网络与规则集深度集成, 牵一发而动全身
outcome(0, 1, 2,T) :- \+between(100, 250, T).   # 
outcome(1, 1, 3,T) :- \+between(100, 250, T).
[[142  63]
 [ 50 115]]

=============================================
 接下来, 我会尝试使用简单规则作为训练: event1, event2 => coinpair
nn(mnist_net1,[X],Y,[0,1]) :: event1(X,Y).
nn(mnist_net2,[X],Y,[2,3]) :: event2(X,Y).
coin1(ID1, T) :-
    happensAt(X,Y,T), 
    event1(X, ID1).
coin2(ID2, T) :-
    happensAt(X,Y,T), 
    event2(Y, ID2).
coinpair(ID1, ID2, T) :-
    coin1(ID1, T),
    coin2(ID2, T)

复杂规则将不参与训练, 而仅作为“补充部分”

##问题: coinpair有两个输出ID1和ID2,


=============================================架构2.0==============================================
=============================================架构2.0==============================================
=====================================我们将整个方法封装成两个部分=====================================
# 第一部分 First, Part:
首先, 我们根据下面给出的“基础规则集”, 本质上是将事件的所有组合可能统计在一个event table中, 
然后将detectEvent作结果进行训练.

nn(mnist_net1, [X], Y, [0,1]) :: event1(X, Y).
nn(mnist_net2, [X], Y, [2,3]) :: event2(X, Y).
coin1(ID1, T) :- happensAt(X, Y, T), event1(X, ID1).
coin2(ID2, T) :- happensAt(X, Y, T), event2(Y, ID2).
---------------------event_table, 后续可以由代码自动定义--------------------
event_table(ID1, ID2, 0) :- ID1 = 0, ID2 = 2.                          #
event_table(ID1, ID2, 1) :- ID1 = 0, ID2 = 3.                          #
event_table(ID1, ID2, 2) :- ID1 = 1, ID2 = 2.                          #
event_table(ID1, ID2, 3) :- ID1 = 1, ID2 = 3.                          #
-------------------------------------------------------------------------
% Define detectEvent to detect events at specific timestamps
detectEvent(EventID, T) :-        =====> 第一部分的最终query, 第二部分将直接基于它
    coin1(ID1, T), coin2(ID2, T),
    event_table(ID1, ID2, EventID).
% 训练/测试结果如下: (biased 和 origin数据都有相似结果)
detectEvent:train
[[103   0   0   0]
 [  3  72   0   0]
 [  0   0 112   2]
 [  0   0   6 103]]

# 第二部分: 
然后, 我们在基于基础代码, 通过直接调用detectEvent来进行后续规则的构建, 
这样做的意义是, 避开了对逻辑图的“破坏”, 避免产生使结果变坏的情形.

#——————————————————————————1——————————————————————————#
Step1: (首先尝试基本的逻辑)
result(win=1, T) :-
    detectEvent(EventID, T),
    ((EventID = 0);(EventID = 3)).
result(win=0, T) :-
    detectEvent(EventID, T),
    ((EventID = 1);(EventID = 2)).
测试:(origin)----------- --(biased)分别的效果:
   [[198   1]             [[150  50]
    [  9 201]]             [ 40 161]]

#——————————————————————————2——————————————————————————#
Step2: (使用定义的特殊逻辑)
result(win=1, T) :-
    detectEvent(EventID, T),
    ((EventID = 0);(EventID = 3)),
    \+(between(50,250,T),EventID=3).
result(win=0, T) :-
    detectEvent(EventID, T),
    ((EventID = 1);(EventID = 2)),
    \+(between(100,300,T),EventID=1).
result(win=0, T) :-
    detectEvent(EventID, T),
    ((EventID = 0);(EventID = 3)),
    (between(50,250,T),EventID=3).
result(win=1, T) :-
    detectEvent(EventID, T),
    ((EventID = 1);(EventID = 2)),
    (between(100,300,T),EventID=1).

测试:(biased)的效果:
[[196   4]
 [  5 196]]             ======> 可以看出, 分数有显著提高, 正是我们期望的结果.


#========================================================================#
====================================总结===================================
#========================================================================#
因为在训练过程中，神经网络权重和逻辑程序中的概率参数共同优化, 以最大化在原始任务定义上的性能, 这表明逻辑和神经网络是深度集成的,
因为当改变逻辑规则但保持了相同的神经网络时，性能大幅下降。如果神经网络只是进行独立的数字识别，这种情况是不会发生的.
基于这个理念,我们似乎需要进行微调模型, 但是这是我们想要避免的,
因此我尝试在不破坏之前的逻辑图的基础上, 直接在后面添加逻辑, 
我构建第一个逻辑图的时候, 尽可能的“封装”它, 即进将detectEvent作为第二部分逻辑的接口, 其他诸如“event1”, “coin2”的谓词避免去使用,
当然这种思想不见得就一定是对的, 后续可以进行改进, 不过这么一来, 我第一阶段的工作就完成了(验证了论文方法本身的可行性), 
下面将会集中进行“llm的提示工程”任务, 和“通用基本事件架构”的优化.


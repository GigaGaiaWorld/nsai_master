{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import necessary modules\n",
    "# import sys\n",
    "# import torch\n",
    "# sys.path.append('/Users/zhenzhili/MASTERTHESIS/#Expert_System_Design/')\n",
    "\n",
    "# from src.dpcepsrc.train import train_model\n",
    "# from examples.MNIST.coins.mnist import MNIST_Net, MNIST_Classifier, test_MNIST, neural_predicate\n",
    "# from src.dpcepsrc.data_loader import load\n",
    "# from src.dpcepsrc.optimizer import SGD\n",
    "# from src.dpcepsrc.model import Model\n",
    "# from src.dpcepsrc.network import Network\n",
    "\n",
    "# from problog.logic import Var\n",
    "# from problog.parser import PrologParser\n",
    "# from problog.program import ExtendedPrologFactory\n",
    "# model_training = False\n",
    "# origin_path = \"/Users/zhenzhili/MASTERTHESIS/#Expert_System_Design/examples/MNIST/coins/\" \n",
    "# model_path = \"models/\"\n",
    "# rule_path = \"rules/\"\n",
    "# origin_data_path = \"data/origin/\"\n",
    "# bias_data_path = \"data/bias/\"\n",
    "\n",
    "\n",
    "\n",
    "# def test_MNIST():\n",
    "#     # Load the same ProbLog string/program that defines the model's structure\n",
    "#     in_train_path = origin_path+origin_data_path+'in_test_data.txt'\n",
    "#     coin_basic_path = origin_path+rule_path+'coin_basic.pl'\n",
    "#     model_coin_path = origin_path+model_path+'model_iter_003890.mdl'\n",
    "#     # queries_for_test = origin_path+\"queries_for_test.txt\"\n",
    "#     origin_queries_path = origin_path+origin_data_path+\"init_test_data.txt\"\n",
    "#     bias_queries_path = origin_path+bias_data_path+\"init_test_data.txt\"\n",
    "\n",
    "#     prolog_string = \"\"\n",
    "#     for str_file in [coin_basic_path, in_train_path]:\n",
    "#         with open (str_file) as f:\n",
    "#             prolog_string += f.read()\n",
    "#             prolog_string += \"\\n\"\n",
    "\n",
    "#     network1 = MNIST_Net(N=2)\n",
    "#     net1 = Network(network1, 'mnist_net1', neural_predicate)\n",
    "#     net1.optimizer = torch.optim.Adam(network1.parameters(), lr=0.001)\n",
    "\n",
    "#     network2 = MNIST_Net(N=2)\n",
    "#     net2 = Network(network2, 'mnist_net2', neural_predicate)\n",
    "#     net2.optimizer = torch.optim.Adam(network2.parameters(), lr=0.001)\n",
    "#     # Create a new model instance with the same structure as the original\n",
    "#     model = Model(prolog_string, [net1, net2], caching=False)\n",
    "#     model.load_state(model_coin_path)\n",
    "\n",
    "#     # Parse a string query into a Term: parseString, parseFile\n",
    "#     # with open (queries_for_test) as query_f:\n",
    "#     #         query_string = query_f.read()\n",
    "#     with open (origin_queries_path) as ori_init_f:\n",
    "#             ori_init_string = ori_init_f.read()\n",
    "            \n",
    "#     queries = PrologParser(ExtendedPrologFactory()).parseString(ori_init_string) # list\n",
    "\n",
    "#     count = 0\n",
    "#     for query in queries:\n",
    "#         _, arg2 = query.args\n",
    "#         query_not = query(Var(\"sequence=A\"), arg2)\n",
    "#         # print(query)\n",
    "#         result = model.solve(query_not)\n",
    "#         single_result = []\n",
    "#         for q, (prob, _) in result.items():\n",
    "#             binare_result = 1 if prob>0.5 else 0\n",
    "#             correct = 1 if (str(q.args[0]) == f\"sequence={binare_result}\") else 0\n",
    "#             count += correct\n",
    "#             print(count)\n",
    "#             single_result.append((q.args[0],format(prob,\".2f\")))\n",
    "#     print(\"accuracy:\", count / len(queries))\n",
    "\n",
    "# test_MNIST()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Biased Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from mnist import MNIST_Net, MNIST_Classifier, test_MNIST, neural_predicate\n",
    "\n",
    "sys.path.append('/Users/zhenzhili/MASTERTHESIS/#Expert_System_Design/')\n",
    "from src.dpcepsrc.model import Model, Var\n",
    "from src.dpcepsrc.data_loader import load\n",
    "from src.dpcepsrc.network import Network\n",
    "import torch\n",
    "\n",
    "from examples.MNIST.coins.prob_ec_testing import test\n",
    "\n",
    "\n",
    "def add_files_to(problog_files, problog_string):\n",
    "    for problog_file in problog_files:\n",
    "        with open(problog_file) as f:\n",
    "            problog_string += f.read()\n",
    "            problog_string += '\\n\\n'\n",
    "\n",
    "    return problog_string\n",
    "\n",
    "\n",
    "def test_MNIST(test_data, problog_files, problog_test_files, test_model):\n",
    "    test_queries = load(test_data)\n",
    "\n",
    "    problog_string = add_files_to(problog_files, '\\n')\n",
    "    problog_test_string = add_files_to(problog_test_files, problog_string)\n",
    "\n",
    "    network1 = MNIST_Net(N=2)\n",
    "    net1 = Network(network1, 'mnist_net1', neural_predicate)\n",
    "    net1.optimizer = torch.optim.Adam(network1.parameters(), lr=0.001)\n",
    "    network2 = MNIST_Net(N=2)\n",
    "    net2 = Network(network2, 'mnist_net2', neural_predicate)\n",
    "    net2.optimizer = torch.optim.Adam(network2.parameters(), lr=0.001)\n",
    "\n",
    "    model_to_test = Model(problog_test_string, [net1,net2], caching=False)\n",
    "    model_to_test.load_state(test_model)\n",
    "\n",
    "    res = test(model_to_test, \n",
    "            test_queries, \n",
    "            test_functions={\n",
    "                'mnist_net1': lambda *args, **kwargs: neural_predicate(*args, **kwargs, dataset='test'),\n",
    "                'mnist_net2': lambda *args, **kwargs: neural_predicate(*args, **kwargs, dataset='test')\n",
    "            },\n",
    "          )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 401/401 [00:07<00:00, 51.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result\n",
      "[[196   4]\n",
      " [  5 196]]\n",
      "F1 result: [0.97755611 0.97755611]\n",
      "Accuracy result: 0.9775561097256857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#===========#===========# bias_test #===========#===========#\n",
    "bias_test = True\n",
    "test_now = True\n",
    "#===========#===========# orig test #===========#===========#\n",
    "\n",
    "if bias_test: \n",
    "    data_path = \"data/bias\"\n",
    "else:\n",
    "    data_path = \"data/origin\"\n",
    "rules_path = \"rules\"\n",
    "model_path = \"models\"\n",
    "if test_now:\n",
    "    res = test_MNIST(\n",
    "        # os.path.join(data_path,'detect_test_data.txt'),    # test_data: init_test_data.txt  detectEvent\n",
    "        os.path.join(data_path,'result_test_data.txt'),    # test_data: init_test_data.txt  detectEvent\n",
    "\n",
    "        # [os.path.join(rules_path,\"coin_simple_event_format.pl\")],\n",
    "        [os.path.join(rules_path,\"modify.pl\")],\n",
    "\n",
    "        [os.path.join(data_path,'in_test_data.txt')],    # problog_test_files: happensAt (put a list here)\n",
    "\n",
    "        os.path.join(model_path,'model_iter_basic_detect.mdl'),\n",
    "        # os.path.join(model_path,'model_iter_listall.mdl'),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Origin: detectEvent\n",
    "[[199   1]\n",
    " [  6 203]]\n",
    "F1 detectEvent: [0.98271605 0.98305085]\n",
    "Accuracy detectEvent: 0.9828850855745721\n",
    "\n",
    "Bias:  detectEvent\n",
    " [[142  63]\n",
    " [ 50 146]]\n",
    "F1 detectEvent: [0.78365385 0.76683938]\n",
    "Accuracy detectEvent: 0.7755610972568578"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Generating Rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(data_path, file_name, read_samples=False):\n",
    "    file_path = os.path.join(data_path, file_name)\n",
    "    with open(file_path) as f:\n",
    "        if not read_samples:\n",
    "            file_str = f.read()\n",
    "        else:\n",
    "            file_lines = f.readlines()[:5]\n",
    "            file_str = \"\\n\".join(file_lines)\n",
    "    return file_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/origin/cp_test_data.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m rules_str \u001b[38;5;241m=\u001b[39m read_file(rules_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoin_basic_modify.pl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m facts_str \u001b[38;5;241m=\u001b[39m read_file(data_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min_test_data.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,read_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 15\u001b[0m queries_str \u001b[38;5;241m=\u001b[39m \u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcp_test_data.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mread_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m question_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124mWhen the absolute value of the difference between the outputs of e1 and e2 is 2, the game output is 1, otherwise the game output is 0\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# question_str = \"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# when the timestamp is between 50 and 250, if the event1 and event2 are classified as 1 and 3, the sequence should equals 0\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# when the timestamp is between 100 and 300, if the event1 and event2 are classified as 0 and 3, the sequence should equals 1\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# \"\"\"\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m, in \u001b[0;36mread_file\u001b[0;34m(data_path, file_name, read_samples)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_file\u001b[39m(data_path, file_name, read_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m      2\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path, file_name)\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m read_samples:\n\u001b[1;32m      5\u001b[0m             file_str \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/miniforge3/envs/wki-ws23/lib/python3.9/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/origin/cp_test_data.txt'"
     ]
    }
   ],
   "source": [
    "bias_test = False\n",
    "\n",
    "if bias_test: \n",
    "    data_path = \"data/bias\"\n",
    "else:\n",
    "    data_path = \"data/origin\"\n",
    "rules_path = \"rules\"\n",
    "model_path = \"models\"\n",
    "context_str =\"\"\"\n",
    "This code combines the outputs of two different neural networks (corresponding to event1 and event2 respectively), \n",
    "extracts information from the simultaneous events through logical rules, and determines the final event outcome based on the difference between the two event labels.\n",
    "\"\"\"\n",
    "rules_str = read_file(rules_path, \"coin_basic_modify.pl\")\n",
    "facts_str = read_file(data_path, \"in_test_data.txt\",read_samples=True)\n",
    "queries_str = read_file(data_path, \"cp_test_data.txt\",read_samples=True)\n",
    "question_str = \"\"\"\n",
    "When the absolute value of the difference between the outputs of e1 and e2 is 2, the game output is 1, otherwise the game output is 0\n",
    "\"\"\"\n",
    "# question_str = \"\"\"\n",
    "# when the timestamp is between 50 and 250, if the event1 and event2 are classified as 1 and 3, the sequence should equals 0\n",
    "# when the timestamp is between 100 and 300, if the event1 and event2 are classified as 0 and 3, the sequence should equals 1\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating...\n",
      "model_name:  deepseek-r1-distill-llama-70b\n",
      "save_directory_thinks: src/generated/thinks/2025-03-06\n",
      "save_directory_models: src/generated/models/2025-03-06\n"
     ]
    }
   ],
   "source": [
    "from src.functions import get_model_files, get_single_model_file_with_path, prolog_reasoning\n",
    "if not test_now:\n",
    "    from src.symbcot_groq import Groq_Reasoning_Graph_Baseline\n",
    "    args = [\n",
    "        context_str,\n",
    "        rules_str,\n",
    "        facts_str,\n",
    "        queries_str,\n",
    "        question_str,\n",
    "        \"deepseek-r1-distill-llama-70b\", # model_name\n",
    "        \"\", # stop_words\n",
    "        \"src/generated\", # save_path\n",
    "        500, # max_new_tokens\n",
    "        False # use_inline_prompt?\n",
    "    ]\n",
    "    deepseek_problem_reduction = Groq_Reasoning_Graph_Baseline(*args)\n",
    "    deepseek_problem_reduction.reasoning_graph_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0\n"
     ]
    }
   ],
   "source": [
    "model_files = get_model_files(\"2025-02-07\", \"deepseek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% ProbLog Inference Result：\n",
      "detectEvent(sequence=0,150) = 1.0000\n",
      "detectEvent(sequence=1,150) = 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = \"\"\"\n",
    "coin1(ID1, T) :-\n",
    "    happensAt(X,Y,T), \n",
    "    event1(X, ID1).\n",
    "coin2(ID2, T) :-\n",
    "    happensAt(X,Y,T), \n",
    "    event2(Y, ID2).\n",
    "\n",
    "outcome(1, ID1, ID2) :- (abs(ID1 - ID2) =:= 2).\n",
    "outcome(0, ID1, ID2) :- (abs(ID1 - ID2) =\\= 2).\n",
    "\n",
    "detectEvent(sequence=EventID,T) :-\n",
    "    coin1(ID1, T),\n",
    "    coin2(ID2, T),\n",
    "    outcome(EventID, ID1, ID2).\n",
    "\n",
    "% =================%%  Following will be code generated by LLM  %%=================%\n",
    "% ================= %% ================= %% ================= %% ================= %\n",
    "\n",
    "detectEvent(sequence=0, T) :-\n",
    "    % When timestamp is between 50 and 250, and event1=1, event2=3\n",
    "    coin1(1, T),\n",
    "    coin2(3, T),\n",
    "    T >= 50,\n",
    "    T =< 250.\n",
    "\n",
    "detectEvent(sequence=1, T) :-\n",
    "    % When timestamp is between 100 and 300, and event1=0, event2=3\n",
    "    coin1(0, T),\n",
    "    coin2(3, T),\n",
    "    T >= 100,\n",
    "    T =< 300.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "facts = \"\"\" \n",
    "happensAt(a,b,150).\n",
    "event1(a,0).\n",
    "event2(b,3).\n",
    "\n",
    "query(detectEvent(X, 150)).\n",
    "\"\"\"\n",
    "\n",
    "prolog_reasoning(model+facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = 1\n",
    "t2 = \"a\"\n",
    "str(f\"{t1 and t2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wki-ws23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

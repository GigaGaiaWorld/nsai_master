{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Biased Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from state import BasicState, TaskStatus\n",
    "\n",
    "state = BasicState()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaskStatus.INIT\n"
     ]
    }
   ],
   "source": [
    "state['status'] = TaskStatus.INIT\n",
    "print(state['status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'rules/origin/BaCon_equO_Res.pl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m rules_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrules/origin/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresult_test_data.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                      \u001b[49m\u001b[38;5;66;43;03m# test_data: detect_test_data.txt  detectEvent\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# os.path.join(rules_path,\"coin_basic_modify_v3.pl\"),          # problog_files: ruleset,\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrules_path\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBaCon_equO_Res.pl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# problog_files: ruleset,\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# os.path.join(rules_path,\"DeE_ResDeEB2.pl\"),          # problog_files: ruleset,\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43min_test_data.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                       \u001b[49m\u001b[38;5;66;43;03m# problog_test_files: happensAt (put a list here)\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# os.path.join(model_path,'model_coin_basic_res.mdl'),             # load_model: \u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_coin_basic_res.mdl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# load_model: \u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# train_new_model? or just test with existing model?\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MASTERTHESIS/#Expert_System_Design/examples/MNIST/coins_with_llm_datagen/run.py:38\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(training_data, test_data, problog_files, problog_train_files, problog_test_files, load_model, train_new_model, train_epochs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train_new_model: train_queries \u001b[38;5;241m=\u001b[39m load(training_data)\n\u001b[1;32m     36\u001b[0m test_queries \u001b[38;5;241m=\u001b[39m load(test_data)\n\u001b[0;32m---> 38\u001b[0m problog_string \u001b[38;5;241m=\u001b[39m \u001b[43madd_files_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblog_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train_new_model: problog_train_string \u001b[38;5;241m=\u001b[39m add_files_to(problog_train_files, problog_string)\n\u001b[1;32m     40\u001b[0m problog_test_string \u001b[38;5;241m=\u001b[39m add_files_to(problog_test_files, problog_string)\n",
      "File \u001b[0;32m~/MASTERTHESIS/#Expert_System_Design/examples/MNIST/coins_with_llm_datagen/run.py:20\u001b[0m, in \u001b[0;36madd_files_to\u001b[0;34m(problog_files, problog_string)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_files_to\u001b[39m(problog_files, problog_string):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m problog_file \u001b[38;5;129;01min\u001b[39;00m problog_files:\n\u001b[0;32m---> 20\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mproblog_file\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     21\u001b[0m             problog_string \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     22\u001b[0m             problog_string \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'rules/origin/BaCon_equO_Res.pl'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from run import run\n",
    "#===========#===========# bias_test #===========#===========#\n",
    "bias_test = False\n",
    "test_now = True\n",
    "#===========#===========# orig test #===========#===========#\n",
    "if test_now:\n",
    "    if bias_test: data_path = \"data/bias\"\n",
    "    else: data_path = \"data/origin\"\n",
    "    rules_path = \"rules/origin/\"\n",
    "    model_path = \"models\"\n",
    "    run(\n",
    "        \"\", os.path.join(data_path,'result_test_data.txt'),                      # test_data: detect_test_data.txt  detectEvent\n",
    "        [\n",
    "            # os.path.join(rules_path,\"coin_basic_modify_v3.pl\"),          # problog_files: ruleset,\n",
    "            os.path.join(rules_path,\"BaCon_equO_Res.pl\"),          # problog_files: ruleset,\n",
    "            # os.path.join(rules_path,\"DeE_ResDeEB2.pl\"),          # problog_files: ruleset,\n",
    "        ], [],\n",
    "        [os.path.join(data_path,'in_test_data.txt')],                       # problog_test_files: happensAt (put a list here)\n",
    "\n",
    "        # os.path.join(model_path,'model_coin_basic_res.mdl'),             # load_model: \n",
    "        os.path.join(model_path,'model_coin_basic_res.mdl'),             # load_model: \n",
    "        False,              # train_new_model? or just test with existing model?\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from run import run\n",
    "#===========#===========# bias_test #===========#===========#\n",
    "bias_test = True\n",
    "all_test_now = False\n",
    "#===========#===========# orig test #===========#===========#\n",
    "# rule_list = [\"BaCon_equO_Res.pl\",\"BaCon_listO_Res.pl\",\"BaCon_listOB1_Res.pl\",\n",
    "#              \"DeE_ResDeE.pl\",\"DeE_ResDeEB1.pl\",\"DeE_ResDeEB2.pl\"]\n",
    "rule_list = [\"coin_llm_bia_v1.pl\",\"coin_llm_bia_v2.pl\",\"coin_llm_bia_v3.pl\",\n",
    "             \"coin_llm_bia_v4.pl\",\"coin_llm_bia_v5.pl\",\"coin_llm_ori_v1.pl\"]\n",
    "\n",
    "if all_test_now:\n",
    "    for rule_file in rule_list:\n",
    "        if bias_test: data_path = \"data/bias\"\n",
    "        else: data_path = \"data/origin\"\n",
    "        rules_path = \"rules/llm_gen\"\n",
    "        model_path = \"models\"\n",
    "        run(\n",
    "            \"\", os.path.join(data_path,'result_test_data.txt'),                      # test_data: detect_test_data.txt  detectEvent\n",
    "            [\n",
    "                # os.path.join(rules_path,\"coin_basic_modify_v3.pl\"),          # problog_files: ruleset,\n",
    "                # os.path.join(rules_path,\"coin_llm_generate_v1.pl\"),          # problog_files: ruleset,\n",
    "                os.path.join(rules_path,rule_file),          # problog_files: ruleset,\n",
    "            ], [],\n",
    "            [os.path.join(data_path,'in_test_data.txt')],                       # problog_test_files: happensAt (put a list here)\n",
    "\n",
    "            # os.path.join(model_path,'model_coin_basic_res.mdl'),             # load_model: \n",
    "            os.path.join(model_path,'model_iter_basic_detect.mdl'),             # load_model: \n",
    "            False,              # train_new_model? or just test with existing model?\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Generating Rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(data_path, file_name, read_samples=False):\n",
    "    file_path = os.path.join(data_path, file_name)\n",
    "    with open(file_path) as f:\n",
    "        if not read_samples:\n",
    "            file_str = f.read()\n",
    "        else:\n",
    "            file_lines = f.readlines()[:5]\n",
    "            file_str = \"\\n\".join(file_lines)\n",
    "    return file_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_test = False\n",
    "\n",
    "if bias_test: \n",
    "    data_path = \"data/bias\"\n",
    "else:\n",
    "    data_path = \"data/origin\"\n",
    "rules_path = \"rules/basic\"\n",
    "model_path = \"models\"\n",
    "context_str =\"\"\"\n",
    "This code combines the outputs of two different neural networks (corresponding to event1 and event2 respectively), \n",
    "extracts information from the simultaneous events through logical rules, and determines the final event outcome based on the difference between the two event labels.\n",
    "\"\"\"\n",
    "rules_str = read_file(rules_path, \"DeE_ResDeE.pl\")\n",
    "facts_str = read_file(data_path, \"in_test_data.txt\",read_samples=True)\n",
    "# queries_str = read_file(data_path, \"result_test_data.txt\",read_samples=True)\n",
    "queries_str = \"result(win=A,T)\"\n",
    "# question_str_basic = \"\"\"\n",
    "# # When the absolute value of the difference between the outputs of e1 and e2 is 2, the win output is 1, otherwise the game output is 0\n",
    "# \"\"\"\n",
    "question_str_basic = \"\"\n",
    "# question_str_additional = \"\"\n",
    "question_str_additional = \"\"\"\n",
    "Additional Rules:\n",
    "when the timestamp is between 50 and 250, if the event1 and event2 are classified as 1 and 3, the win output is 0\n",
    "when the timestamp is between 100 and 300, if the event1 and event2 are classified as 0 and 3, the win output is 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_context_examples: # Problem Context:\n",
      "\n",
      "[[CONTEXT]]\n",
      "\n",
      "# Facts:\n",
      "\n",
      "### There are two different types of facts write as predicates: \"happensAt\" and \"event\". Whenever you use facts inside a rule, you should follow the following form:\n",
      "\n",
      "1\\. happensAt are always given in following forms together with rules, you should not create this part:\n",
      "\n",
      " happensAt(Event1, Event2, ...,Event-n, Timestamp).\n",
      "\n",
      " from Event1, Event2 to Event-n are different events that happens at same time Timestamp,\n",
      "\n",
      " for example:\n",
      "\n",
      " happensAt(boy, alien, 12). means there's two events(boy and alien) happens at timestamp 12.\n",
      "\n",
      "2\\. events are always given in following forms together with rules, you should not create this part:\n",
      "\n",
      " event<Event_name>(Event, Label).\n",
      "\n",
      " event predicate could follow the above form, the <Event_name> could be replaced to distinguish different events, which also means they correspond to different mapping domains,\n",
      "\n",
      " for example:\n",
      "\n",
      " event1(14243, 2). could have one of the Label1 from [0,1,2,3], means event 14243 will be classified as class 2.\n",
      "\n",
      " event2(dog, black). could have one of the Label2 from [black,white], means event dog will be classified as class black.\n",
      "\n",
      "\\-----\n",
      "\n",
      "# Task:\n",
      "\n",
      "### Your task is to modify the following given DeepProblog rules based on the user's instructions. And generate the whole new code. Please first analyze the structure and logic of the existing code, and then create additional code according to the user's instructions so that it conforms to the DeepProblog syntax. Please add necessary comments in the code to explain the function of each part.\n",
      "\n",
      "### The existing DeepProblog code that you should refer to is below:\n",
      "\n",
      "[[RULE_SET]]\n",
      "\n",
      "### Here are some examples of facts, other facts also follows the same form: (you should not generate this part)\n",
      "\n",
      "[[FACTS]]\n",
      "\n",
      "### Here is the form of target predicate to express your results:\n",
      "\n",
      "[[QUERIES]]\n",
      "\n",
      "### Below is the demand of user that you need to fullfill with your generated new code:\n",
      "\n",
      "[[QUESTION]]\n",
      "\n",
      "\n",
      "# Note:\n",
      "\n",
      "1. Make sure you capture all the information from the context in the translation.\n",
      "    \n",
      "2. Make sure you follow the instruction and example to translate the information.\n",
      "    \n",
      "3. Please ensure your answer together with current code is directly executable.\n",
      "    \n",
      "4. Do not generate any descriptive content. Only generate the code.\n",
      "\n",
      "5. Let's think step by step.\n",
      "\n",
      "# Syntax Notes:\n",
      "1.DeepProbLog does not support if-then-else syntax of \"->\". You need to split the conditional judgment into multiple rules or use standard logical connections;\n",
      "2.When use Less than or equal to, use \"=<\".\n",
      "3.When comparing numbers, use \"=:=\" as equal and \"=\\=\" as unequal. \n",
      "\n",
      "# Not supported Syntax:\n",
      "• !/0\n",
      "• P -> Q\n",
      "• P *-> Q\n",
      "• repeat\n",
      "• incore/1 (use call/1)\n",
      "• call_with_args/N (use call/N)\n",
      "• if(A,B,C) (use (A,B);(\\+A,C))\n",
      "• ignore/1\n",
      "• abort/0\n",
      "• break/0\n",
      "• halt/0\n",
      "• halt/1\n",
      "• catch/3\n",
      "• throw/1\n",
      "• garbage_collect/0\n",
      "• garbage_collect_atoms/0\n",
      "• gc/0\n",
      "• nogc/0\n",
      "• grow_heap/1\n",
      "• grow_stack/1\n",
      "Translating...\n",
      "model_name:  deepseek-r1-distill-llama-70b\n",
      "save_directory_thinks: src/generated/thinks/2025-03-10\n",
      "save_directory_models: src/generated/models/2025-03-10\n"
     ]
    }
   ],
   "source": [
    "from src.functions import get_model_files, get_single_model_file_with_path, prolog_reasoning\n",
    "if not test_now:\n",
    "    from src.symbcot_groq import Groq_Reasoning_Graph_Baseline\n",
    "    args = [\n",
    "        context_str,\n",
    "        rules_str,\n",
    "        facts_str,\n",
    "        queries_str,\n",
    "        question_str_basic+\"\\n\"+question_str_additional,\n",
    "        \"deepseek-r1-distill-llama-70b\", # model_name\n",
    "        \"\", # stop_words\n",
    "        \"src/generated\", # save_path\n",
    "        500, # max_new_tokens\n",
    "        True # use_inline_prompt?\n",
    "    ]\n",
    "    deepseek_problem_reduction = Groq_Reasoning_Graph_Baseline(*args)\n",
    "    deepseek_problem_reduction.reasoning_graph_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0\n"
     ]
    }
   ],
   "source": [
    "model_files = get_model_files(\"2025-02-07\", \"deepseek\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wki-ws23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

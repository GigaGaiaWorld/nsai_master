{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input some data for generating \"constant events\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data\n",
    "weather_train_csv = '/Users/zhenzhili/MASTERTHESIS/datasets/#ASHRAE-energy-prediction-dataset/weather_train.csv'\n",
    "df_wt = pd.read_csv(weather_train_csv)\n",
    "weather_site_0 = df_wt[df_wt[\"site_id\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently, we have the following clusters and their respective equipments and sensors, KMS are sensors that integrated with following functions, like temperature, humidity, dew point, air quality.\n",
      "The relationship between equipements are as follows:\n",
      "Cluster: one\n",
      "  Equipment: server_1\n",
      "    Hot Aisle Sensors: KMS_1, KMS_2\n",
      "    Cold Aisle Sensors: KMS_3, KMS_4\n",
      "  Equipment: server_2\n",
      "    Hot Aisle Sensors: KMS_5, KMS_6\n",
      "    Cold Aisle Sensors: KMS_7, KMS_8\n",
      "\n",
      "Cluster: two\n",
      "  Equipment: server_3\n",
      "    Hot Aisle Sensors: KMS_9, KMS_10\n",
      "    Cold Aisle Sensors: KMS_11, KMS_12\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clusters = {\n",
    "    \"one\": {\n",
    "        \"equipments\": {\n",
    "            \"server_1\": {\n",
    "                \"hot_aisle\": [\"KMS_1\", \"KMS_2\"],\n",
    "                \"cold_aisle\": [\"KMS_3\", \"KMS_4\"]\n",
    "            },\n",
    "            \"server_2\": {\n",
    "                \"hot_aisle\": [\"KMS_5\", \"KMS_6\"],\n",
    "                \"cold_aisle\": [\"KMS_7\", \"KMS_8\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"two\": {\n",
    "        \"equipments\": {\n",
    "            \"server_3\": {\n",
    "                \"hot_aisle\": [\"KMS_9\", \"KMS_10\"],\n",
    "                \"cold_aisle\": [\"KMS_11\", \"KMS_12\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "item_form = \"\"\" \n",
    "Form:\"date\",\"Appliances\",\"lights\",\"T1\",\"RH_1\",\"T2\",\"RH_2\",\"T3\",\"RH_3\",\"T4\",\"RH_4\",\"T5\",\"RH_5\",\"T6\",\"RH_6\",\"T7\",\"RH_7\",\"T8\",\"RH_8\",\"T9\",\"RH_9\",\"T_out\",\"Press_mm_hg\",\"RH_out\",\"Windspeed\",\"Visibility\",\"Tdewpoint\",\"rv1\",\"rv2\"\n",
    "Details:\n",
    "date, time year-month-day hour:minute:second\n",
    "Appliances, energy use in Wh\n",
    "lights, energy use of light fixtures in the house in Wh\n",
    "T1, Temperature in kitchen area, in Celsius\n",
    "RH_1, Humidity in kitchen area, in %\n",
    "T2, Temperature in living room area, in Celsius\n",
    "RH_2, Humidity in living room area, in %\n",
    "T3, Temperature in laundry room area\n",
    "RH_3, Humidity in laundry room area, in %\n",
    "T4, Temperature in office room, in Celsius\n",
    "RH_4, Humidity in office room, in %\n",
    "T5, Temperature in bathroom, in Celsius\n",
    "RH_5, Humidity in bathroom, in %\n",
    "T6, Temperature outside the building (north side), in Celsius\n",
    "RH_6, Humidity outside the building (north side), in %\n",
    "T7, Temperature in ironing room , in Celsius\n",
    "RH_7, Humidity in ironing room, in %\n",
    "T8, Temperature in teenager room 2, in Celsius\n",
    "RH_8, Humidity in teenager room 2, in %\n",
    "T9, Temperature in parents room, in Celsius\n",
    "RH_9, Humidity in parents room, in %\n",
    "To, Temperature outside (from Chievres weather station), in Celsius\n",
    "Pressure (from Chievres weather station), in mm Hg\n",
    "RH_out, Humidity outside (from Chievres weather station), in %\n",
    "Wind speed (from Chievres weather station), in m/s\n",
    "Visibility (from Chievres weather station), in km\n",
    "Tdewpoint (from Chievres weather station), Â°C\n",
    "rv1, Random variable 1, nondimensional\n",
    "rv2, Random variable 2, nondimensional\n",
    "\"\"\"\n",
    "\n",
    "facts = \"\"\"Currently, we have the following clusters and their respective equipments and sensors, KMS are sensors that integrated with following functions, like temperature, humidity, dew point, air quality.\n",
    "The relationship between equipements are as follows:\n",
    "\"\"\"\n",
    "for cluster, data in clusters.items():\n",
    "    facts += f\"Cluster: {cluster}\\n\"\n",
    "    for equipment, details in data[\"equipments\"].items():\n",
    "        facts += f\"  Equipment: {equipment}\\n\"\n",
    "        facts += f\"    Hot Aisle Sensors: {', '.join(details['hot_aisle'])}\\n\"\n",
    "        facts += f\"    Cold Aisle Sensors: {', '.join(details['cold_aisle'])}\\n\"\n",
    "    facts += \"\\n\"\n",
    "print(facts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parsing prompts:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just record the prompt of following models:\n",
    "prompt = \"\"\"\n",
    "Problem Context: A data center monitors various environmental metrics using sensor data The goal is to detect anomalous events that may indicate failures, inefficiencies, or unexpected conditions in the facility.\n",
    "Task Description: You are given a serie of facts that description. Your task is to leverage a pre-trained Large Language Model (LLM) combined with symbolic reasoning to analyze natural language event descriptions and map them to formalized logic-based anomaly detection rules.\n",
    "\n",
    "### Facts are always given in following forms, you should not create this part, they include the sensor's measurements in the time window between \"Start_timestamp\" and \"End_timestamp\". Each \"Sensor_id\" can monitor multiple items, whenever you use facts inside a rule, you should follow the following form: \n",
    "Item: sensor_air_temperature, sensor_wind_speed\n",
    "Form:\n",
    "sensor_data(Sensor, Item, Start_timestamp, End_timestamp, Std_value, Mean_value, Median_value, Max_value, Min_value, Slope)\n",
    "Example:\n",
    "sensor_data(sensor_KMS1, temperature, '2023-08-01T12:00:00', '2023-08-01T12:05:00', 0.8, 25.4, 25.3, 26.1, 24.5, 0.1).\n",
    "sensor_data(sensor_weather, humidity, '2023-08-05T13:00:00', '2023-08-05T13:05:00', 0.82, 0.80, 0.83, 0.85, 0.78, 0.02).\n",
    "sensor_data(sensor_cpu, cpuload, '2024-02-01T12:30:00', '2024-02-01T12:35:00', 0.45, 0.42, 0.46, 0.50, 0.40, 0.03).\n",
    "\n",
    "-----\n",
    "Below are some examples of how you should construct the predicate according to the input of the user:\n",
    "\n",
    "### Basic rules thats the objects in datacenter should follow, the name could be directly defined according to it's meaning: \n",
    "event_<Event_name1>(Sensor1,Sensor2)\n",
    "\n",
    "Example:\n",
    "Discribtion: if both Sensor1 and Sensor2 exceed the threshold of the temperature(in this case 26), the Event_name is set to \"temperature_exceed\", and the predicate structure is setted as follow:\n",
    "event_temperature_exceed(Sensor1, Sensor2):-\n",
    "    sensor_data(Sensor1, temperature, _,_, _, Mean1, _, _, _, Slope1),\n",
    "    sensor_data(Sensor2, temperature, _, _, _, Mean2, _, _, _, Slope2),\n",
    "    Slope1 > 0, Slope2 > 0, Mean1 > 26, Mean2 > 26.\n",
    "\n",
    "Discribtion: if the cpu load is higher as 0.45, the Event_name is set to \"cpu_high_load\", and the predicate structure is setted as follow:\n",
    "event_cpu_high_load(Sensor) :- \n",
    "  sensor_data(Sensor, cpuload, _, _, _, MeanCPU, _, _, _, _), MeanCPU > 0.45.\n",
    "\n",
    "Discribtion: if the temperature difference between Sensor1 and Sensor2 is higher that 2.0, the Event_name is set to \"temperature_difference_large\", and the predicate structure is setted as follow:\n",
    "event_temperature_difference_large(Sensor1, Sensor2) :- \n",
    "  sensor_data(Sensor1, temperature, _, _, _, Mean1, _, _, _, _),\n",
    "  sensor_data(Sensor2, temperature, _, _, _, Mean2, _, _, _, _), \n",
    "  Diff is abs(Mean1 - Mean2), Diff > 2.0.\n",
    "\n",
    "### Eventually, based on the events that we defined, we should define the anormaly predicate for the anormaly detection:\n",
    "anormaly(<Anormaly_name>) :-\n",
    "\n",
    "Example:\n",
    "Description: When the CPU is highly loaded and the temperature rises, the Anormaly_name is set to high_load_phenomenon, and the predicate structure is setted as follow:\n",
    "anomaly(high_load_phenomenon) :-\n",
    "    event_cpu_high_load(sensor_cpu),\n",
    "    event_temperature_rise(sensor_KMS1).\n",
    "\n",
    "Description: When the CPU is highly loaded and the temperature drops, the Anormaly_name is set to temperature_sensor_failure, and the predicate structure is setted as follow:\n",
    "anomaly(temperature_sensor_failure) :-\n",
    "    event_cpu_high_load(sensor_cpu),\n",
    "    event_temperature_fall(sensor_KMS1).\n",
    "\n",
    "Description: When the temperature difference between sensor_KMS1 and sensor_KMS2 is too large, the Anormaly_name is set to cooling_system_failure, and the predicate structure is setted as follow:\n",
    "anomaly(cooling_system_failure) :-\n",
    "    event_temperature_difference_large(sensor_KMS1, sensor_KMS2).\n",
    "\n",
    "-----\n",
    "Below is the one you need to translate:\n",
    "\n",
    "1. When wind speed rises and temperature drops, there is a risk of catching a cold.\n",
    "2. When wind speed drops and temperature rises and the temperature is higher than 9, there is a risk of dryness.\n",
    "3. when wind speed is lower than 3.6, there's a risk of stillness\n",
    "\n",
    "###\n",
    "Make sure you capture all the information from the context in the translation.\n",
    "Make sure you follow the instruction and example to translate the information.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### so there're some generated models based on above prompt, they are classified by their LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gpto3mini = \"\"\"\n",
    "anomaly(catching_cold) :-\n",
    "    event_wind_speed_rise(Sensor1),\n",
    "    event_temperature_drop(Sensor2).\n",
    "\n",
    "event_wind_speed_rise(Sensor) :-\n",
    "    sensor_data(Sensor, wind_speed, _, _, _, _, _, MaxWS, _, SlopeWS),\n",
    "    SlopeWS > 0, MaxWS > 0.\n",
    "\n",
    "event_temperature_drop(Sensor) :-\n",
    "    sensor_data(Sensor, temperature, _, _, _, _, _, _, MinTemp, SlopeT),\n",
    "    SlopeT < 0, MinTemp < 0.\n",
    "\n",
    "anomaly(dryness_risk) :-\n",
    "    event_wind_speed_drop(Sensor1),\n",
    "    event_temperature_rise_higher_9(Sensor2).\n",
    "\n",
    "event_wind_speed_drop(Sensor) :-\n",
    "    sensor_data(Sensor, wind_speed, _, _, _, _, _, _, MinWS, SlopeWS),\n",
    "    SlopeWS < 0, MinWS < 0.\n",
    "\n",
    "event_temperature_rise_higher_9(Sensor) :-\n",
    "    sensor_data(Sensor, temperature, _, _, _, MeanT, _, MaxT, _, SlopeT),\n",
    "    SlopeT > 0, MeanT > 9, MaxT > 9.\n",
    "\n",
    "anomaly(stillness_risk) :-\n",
    "    event_low_wind_speed(Sensor).\n",
    "\n",
    "event_low_wind_speed(Sensor) :-\n",
    "    sensor_data(Sensor, wind_speed, _, _, _, MeanWS, _, _, _, _),\n",
    "    MeanWS < 3.6.\n",
    "\"\"\"\n",
    "\n",
    "model_gpt4o = \"\"\" \n",
    "% Rule 1: When wind speed rises and temperature drops, there is a risk of catching a cold.\n",
    "% Define the event predicates:\n",
    "event_wind_speed_rise(Sensor) :-\n",
    "    sensor_data(Sensor, sensor_wind_speed, _Start, _End, _Std, _MeanWS, _Median, _Max, _Min, SlopeWS),\n",
    "    SlopeWS > 0.\n",
    "\n",
    "event_temperature_fall(Sensor) :-\n",
    "    sensor_data(Sensor, sensor_air_temperature, _Start, _End, _Std, _MeanT, _Median, _Max, _Min, SlopeT),\n",
    "    SlopeT < 0.\n",
    "\n",
    "% Combine events into an anomaly predicate.\n",
    "anomaly(catching_cold) :-\n",
    "    event_wind_speed_rise(sensor_WS1),\n",
    "    event_temperature_fall(sensor_KMS1).\n",
    "\n",
    "% Rule 2: When wind speed drops and temperature rises and the temperature is higher than 9, there is a risk of dryness.\n",
    "% Define the event predicates:\n",
    "event_wind_speed_drop(Sensor) :-\n",
    "    sensor_data(Sensor, sensor_wind_speed, _Start, _End, _Std, _MeanWS, _Median, _Max, _Min, SlopeWS),\n",
    "    SlopeWS < 0.\n",
    "\n",
    "% Here we combine a rising temperature with an extra threshold on the mean temperature.\n",
    "event_temperature_rise_high(Sensor) :-\n",
    "    sensor_data(Sensor, sensor_air_temperature, _Start, _End, _Std, MeanT, _Median, _Max, _Min, SlopeT),\n",
    "    SlopeT > 0,\n",
    "    MeanT > 9.\n",
    "\n",
    "% Combine events into an anomaly predicate.\n",
    "anomaly(dryness) :-\n",
    "    event_wind_speed_drop(sensor_WS1),\n",
    "    event_temperature_rise_high(sensor_KMS1).\n",
    "\n",
    "% Rule 3: When wind speed is lower than 3.6, there's a risk of stillness.\n",
    "% Define an event predicate checking the mean wind speed value.\n",
    "event_wind_speed_low(Sensor) :-\n",
    "    sensor_data(Sensor, sensor_wind_speed, _Start, _End, _Std, MeanWS, _Median, _Max, _Min, _Slope),\n",
    "    MeanWS < 3.6.\n",
    "\n",
    "% Combine into an anomaly predicate.\n",
    "anomaly(stillness) :-\n",
    "    event_wind_speed_low(sensor_WS1).\n",
    "\"\"\"\n",
    "\n",
    "model_deepseek = \"\"\" \n",
    "event_wind_speed_rise(Sensor) :-\n",
    "sensor_data(Sensor, wind_speed, _, _, _, _, _, _, _, Slope),\n",
    "Slope > 0.\n",
    "\n",
    "event_temperature_drop(Sensor) :-\n",
    "sensor_data(Sensor, temperature, _, _, _, _, _, _, _, Slope),\n",
    "Slope < 0.\n",
    "\n",
    "anomaly(risk_of_cold) :-\n",
    "event_wind_speed_rise(WindSensor),\n",
    "event_temperature_drop(TempSensor).\n",
    "\n",
    "event_wind_speed_drop(Sensor) :-\n",
    "sensor_data(Sensor, wind_speed, _, _, _, _, _, _, _, Slope),\n",
    "Slope < 0.\n",
    "\n",
    "event_temperature_rise_high(Sensor) :-\n",
    "sensor_data(Sensor, temperature, _, _, _, Mean, _, _, _, Slope),\n",
    "Slope > 0,\n",
    "Mean > 9.\n",
    "\n",
    "anomaly(risk_of_dryness) :-\n",
    "event_wind_speed_drop(WindSensor),\n",
    "event_temperature_rise_high(TempSensor).\n",
    "\n",
    "event_wind_speed_low(Sensor) :-\n",
    "sensor_data(Sensor, wind_speed, _, _, _, Mean, _, _, _, _),\n",
    "Mean < 3.6.\n",
    "\n",
    "anomaly(risk_of_stillness) :-\n",
    "event_wind_speed_low(WindSensor).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==============================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Concept-Deepseek based:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==============================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os# define the arguments for the model:\n",
    "from src.functions import get_model_files, get_single_model_file_with_path, prolog_reasoning\n",
    "context_str =\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "rules_str = \"\"\"\n",
    "\"\"\"\n",
    "facts_str = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "question_str_1 = \"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating...\n",
      "model_name:  deepseek-r1-distill-llama-70b\n",
      "Response saved.\n"
     ]
    }
   ],
   "source": [
    "# Main function: (create new model files)\n",
    "\n",
    "from src.symbcot_groq import Groq_Reasoning_Graph_Baseline\n",
    "args = [\n",
    "    context_str,\n",
    "    rules_str,\n",
    "    facts_str,\n",
    "    question_str_1,\n",
    "    \"deepseek-r1-distill-llama-70b\", # model_name\n",
    "    \"\", # stop_words\n",
    "    \"src/generated\", # save_path\n",
    "    500 # max_new_tokens\n",
    "]\n",
    "deepseek_problem_reduction = Groq_Reasoning_Graph_Baseline(*args)\n",
    "deepseek_problem_reduction.reasoning_graph_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProbLog Inference Result：\n",
      "fact(a) = 0.8000\n",
      "fact(b) = 0.6000\n",
      "allfacts = 0.4800\n"
     ]
    }
   ],
   "source": [
    "model = \"\"\" \n",
    "0.8::fact(a).\n",
    "0.6::fact(b).\n",
    "allfacts :-\n",
    "    fact(a), fact(b).\n",
    "\n",
    "    \n",
    "query(fact(X)).\n",
    "query(allfacts).\n",
    "\"\"\"\n",
    "prolog_reasoning(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation and View Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2025-02-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10\n",
      "====================generated/models/2025-02-07/prolog_model_deepseek_2025-02-08 19:39:38.545957.txt====================\n",
      "------------facts_cold_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(X2) = 0.0000\n",
      "------------facts_dryness_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(dryness_risk) = 1.0000\n",
      "anomaly(stillness_risk) = 1.0000\n",
      "------------facts_stillness_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(stillness_risk) = 1.0000\n",
      "====================generated/models/2025-02-07/prolog_model_deepseek_2025-02-08 19:37:40.256262.txt====================\n",
      "------------facts_cold_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(X2) = 0.0000\n",
      "------------facts_dryness_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(X2) = 0.0000\n",
      "------------facts_stillness_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(X2) = 0.0000\n",
      "====================generated/models/2025-02-07/prolog_model_deepseek_2025-02-08 19:39:43.275474.txt====================\n",
      "------------facts_cold_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(X2) = 0.0000\n",
      "------------facts_dryness_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(stillness_risk) = 1.0000\n",
      "------------facts_stillness_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(stillness_risk) = 1.0000\n",
      "====================generated/models/2025-02-07/prolog_model_deepseek_2025-02-08 19:39:29.958497.txt====================\n",
      "------------facts_cold_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(X2) = 0.0000\n",
      "------------facts_dryness_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(dryness_risk) = 1.0000\n",
      "anomaly(stillness_risk) = 1.0000\n",
      "------------facts_stillness_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(stillness_risk) = 1.0000\n",
      "====================generated/models/2025-02-07/prolog_model_deepseek_2025-02-08 18:59:37.758261.txt====================\n",
      "------------facts_cold_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(X2) = 0.0000\n",
      "------------facts_dryness_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(dryness_risk) = 1.0000\n",
      "anomaly(stillness_risk) = 1.0000\n",
      "------------facts_stillness_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(stillness_risk) = 1.0000\n",
      "====================generated/models/2025-02-07/prolog_model_deepseek_2025-02-08 18:50:27.403608.txt====================\n",
      "------------facts_cold_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(X2) = 0.0000\n",
      "------------facts_dryness_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(dryness_risk) = 1.0000\n",
      "anomaly(stillness_risk) = 1.0000\n",
      "------------facts_stillness_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(stillness_risk) = 1.0000\n",
      "====================generated/models/2025-02-07/prolog_model_deepseek_2025-02-08 19:38:54.841523.txt====================\n",
      "------------facts_cold_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(X2) = 0.0000\n",
      "------------facts_dryness_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(dryness_risk) = 1.0000\n",
      "anomaly(stillness_risk) = 1.0000\n",
      "------------facts_stillness_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(stillness_risk) = 1.0000\n",
      "====================generated/models/2025-02-07/prolog_model_deepseek_2025-02-08 19:39:34.442966.txt====================\n",
      "------------facts_cold_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(X2) = 0.0000\n",
      "------------facts_dryness_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(dryness_risk) = 1.0000\n",
      "anomaly(stillness_risk) = 1.0000\n",
      "------------facts_stillness_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(stillness_risk) = 1.0000\n",
      "====================generated/models/2025-02-07/prolog_model_deepseek_2025-02-08 19:42:39.246113.txt====================\n",
      "------------facts_cold_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(X2) = 0.0000\n",
      "------------facts_dryness_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(dryness_risk) = 1.0000\n",
      "anomaly(stillness_risk) = 1.0000\n",
      "------------facts_stillness_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(stillness_risk) = 1.0000\n",
      "====================generated/models/2025-02-07/prolog_model_deepseek_2025-02-08 18:56:25.515842.txt====================\n",
      "------------facts_cold_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(X2) = 0.0000\n",
      "------------facts_dryness_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(dryness_risk) = 1.0000\n",
      "anomaly(stillness_risk) = 1.0000\n",
      "------------facts_stillness_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(stillness_risk) = 1.0000\n"
     ]
    }
   ],
   "source": [
    "facts_1st_risk = \"\"\" \n",
    "sensor_data(sensor_KMS1, temperature, _, _, _, 26.0, _, _, _, _). \n",
    "sensor_data(sensor_cpu, cpuload, _, _, _, 0.75, _, _, _, _).\n",
    "\"\"\"\n",
    "facts_2nd_risk = \"\"\" \n",
    "sensor_data(sensor_weather, windspeed, '2023-08-01T12:10:00', '2023-08-01T12:15:00', 0.8, 2, 4.5, 4.0, 3.5, -0.3).\n",
    "sensor_data(sensor_KMS1, temperature, '2023-08-01T12:10:00', '2023-08-01T12:15:00', 0.8, 10, 9.5, 10.2, 10.8, 0.3).\n",
    "\"\"\"\n",
    "facts_3rd_risk= \"\"\" \n",
    "sensor_data(sensor_weather, windspeed, '2023-08-01T12:20:00', '2023-08-01T12:25:00', 0.8, 3, 3.8, 3.5, 3.2, -0.1).\n",
    "\"\"\"\n",
    "query = \"\"\" \n",
    "query(anomaly(_)).\n",
    "\"\"\"\n",
    "facts ={\"facts_cold_risk\":facts_1st_risk, \n",
    "        \"facts_dryness_risk\":facts_2nd_risk, \n",
    "        \"facts_stillness_risk\":facts_3rd_risk\n",
    "}\n",
    "# read all model files that start with \"prolog_model_deepseek_\":\n",
    "model_files = get_model_files(\"2025-02-07\", \"deepseek\")\n",
    "for model_key in model_files:\n",
    "    print(f\"===================={model_key}====================\")\n",
    "    for fact_key in facts:\n",
    "        print(f\"------------{fact_key}------------\")\n",
    "        whole_model = facts[fact_key] + model_files[model_key] + query\n",
    "        result_single = prolog_reasoning(whole_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2025-02-09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3\n",
      "====================generated/models/2025-02-09/prolog_model_deepseek_22:29:35.txt====================\n",
      "------------facts_overheat_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(risk_of_overheating) = 1.0000\n",
      "------------facts_condensation_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(risk_of_condensation) = 1.0000\n",
      "------------facts_high_power_consumption_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(risk_of_high_power_consumption) = 1.0000\n",
      "====================generated/models/2025-02-09/prolog_model_deepseek_22-28-45.txt====================\n",
      "------------facts_overheat_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(overheat_risk) = 1.0000\n",
      "------------facts_condensation_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(condensation_risk) = 1.0000\n",
      "------------facts_high_power_consumption_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(high_power_consumption) = 1.0000\n",
      "====================generated/models/2025-02-09/prolog_model_deepseek_22-27-10.txt====================\n",
      "------------facts_overheat_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(risk_of_overheating) = 1.0000\n",
      "------------facts_condensation_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(risk_of_condensation) = 1.0000\n",
      "------------facts_high_power_consumption_risk------------\n",
      "ProbLog Inference Result：\n",
      "anomaly(risk_of_high_power_consumption) = 1.0000\n"
     ]
    }
   ],
   "source": [
    "facts_1st_risk = \"\"\" \n",
    "sensor_data(sensor_KMS1, temperature, '2023-08-15T14:00:00', '2023-08-15T14:05:00', 0.7, 27.5, 1.2, 27.3, 27.6, 0.1).\n",
    "sensor_data(sensor_cpu, cpuload, '2023-08-15T14:00:00', '2023-08-15T14:05:00', 0.9, 0.82, 0.05, 0.81, 0.83, 0.01).\n",
    "\"\"\"\n",
    "facts_2nd_risk = \"\"\" \n",
    "sensor_data(sensor_KMS1, temperature, '2023-08-15T03:00:00', '2023-08-15T03:05:00', 0.6, 23.2, 0.8, 23.0, 23.5, -0.3).\n",
    "sensor_data(sensor_weather, humidity, '2023-08-15T03:00:00', '2023-08-15T03:05:00', 0.7, 0.88, 0.02, 0.87, 0.89, 0.01).\n",
    "\"\"\"\n",
    "facts_3rd_risk= \"\"\" \n",
    "sensor_data(sensor_weather, temperature, '2023-08-15T12:00:00', '2023-08-15T12:05:00', 0.8, 25.5, 1.0, 25.3, 25.8, 0.2).\n",
    "sensor_data(sensor_KMS1, temperature, '2023-08-15T12:00:00', '2023-08-15T12:05:00', 0.9, 22.8, 1.5, 22.5, 23.0, -0.5).\n",
    "\"\"\"\n",
    "query = \"\"\" \n",
    "query(anomaly(_)).\n",
    "\"\"\"\n",
    "network_define = \"\"\" \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "facts ={\"facts_overheat_risk\":facts_1st_risk, \n",
    "        \"facts_condensation_risk\":facts_2nd_risk, \n",
    "        \"facts_high_power_consumption_risk\":facts_3rd_risk\n",
    "}\n",
    "# read all model files that start with \"prolog_model_deepseek_\":\n",
    "model_files = get_model_files(\"2025-02-09\", \"deepseek\")\n",
    "for model_key in model_files:\n",
    "    print(f\"===================={model_key}====================\")\n",
    "    for fact_key in facts:\n",
    "        print(f\"------------{fact_key}------------\")\n",
    "        whole_model = facts[fact_key] + model_files[model_key] + query\n",
    "        result_single = prolog_reasoning(whole_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2025-02-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0\n"
     ]
    }
   ],
   "source": [
    "facts_1st_risk = \"\"\" \n",
    "sensor_data(sensor_KMS1, temperature, '2023-08-15T14:00:00', '2023-08-15T14:05:00', 0.7, 27.5, 1.2, 27.3, 27.6, 0.1).\n",
    "sensor_data(sensor_cpu, cpuload, '2023-08-15T14:00:00', '2023-08-15T14:05:00', 0.9, 0.82, 0.05, 0.81, 0.83, 0.01).\n",
    "\"\"\"\n",
    "facts_2nd_risk = \"\"\" \n",
    "sensor_data(sensor_KMS1, temperature, '2023-08-15T03:00:00', '2023-08-15T03:05:00', 0.6, 23.2, 0.8, 23.0, 23.5, -0.3).\n",
    "sensor_data(sensor_weather, humidity, '2023-08-15T03:00:00', '2023-08-15T03:05:00', 0.7, 0.88, 0.02, 0.87, 0.89, 0.01).\n",
    "\"\"\"\n",
    "facts_3rd_risk= \"\"\" \n",
    "sensor_data(sensor_weather, temperature, '2023-08-15T12:00:00', '2023-08-15T12:05:00', 0.8, 25.5, 1.0, 25.3, 25.8, 0.2).\n",
    "sensor_data(sensor_KMS1, temperature, '2023-08-15T12:00:00', '2023-08-15T12:05:00', 0.9, 22.8, 1.5, 22.5, 23.0, -0.5).\n",
    "\"\"\"\n",
    "query = \"\"\" \n",
    "query(anomaly(_)).\n",
    "\"\"\"\n",
    "network_define = \"\"\" \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "facts ={\"facts_overheat_risk\":facts_1st_risk, \n",
    "        \"facts_condensation_risk\":facts_2nd_risk, \n",
    "        \"facts_high_power_consumption_risk\":facts_3rd_risk\n",
    "}\n",
    "# read all model files that start with \"prolog_model_deepseek_\":\n",
    "model_files = get_model_files(\"2025-02-11\", \"deepseek\")\n",
    "for model_key in model_files:\n",
    "    print(f\"===================={model_key}====================\")\n",
    "    for fact_key in facts:\n",
    "        print(f\"------------{fact_key}------------\")\n",
    "        whole_model = facts[fact_key] + model_files[model_key] + query\n",
    "        result_single = prolog_reasoning(whole_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# real Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this file could not be found\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'model_string' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 31\u001b[0m\n\u001b[1;32m     26\u001b[0m facts \u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacts_overheat_risk\u001b[39m\u001b[38;5;124m\"\u001b[39m:facts_1st_risk, \n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacts_condensation_risk\u001b[39m\u001b[38;5;124m\"\u001b[39m:facts_2nd_risk, \n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacts_high_power_consumption_risk\u001b[39m\u001b[38;5;124m\"\u001b[39m:facts_3rd_risk\n\u001b[1;32m     29\u001b[0m }\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# read all model files that start with \"prolog_model_deepseek_\":\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m model_files \u001b[38;5;241m=\u001b[39m \u001b[43mget_single_model_file_with_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_network_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fact_key \u001b[38;5;129;01min\u001b[39;00m facts:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m------------\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfact_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/MASTERTHESIS/#Expert_System_Design/functions.py:26\u001b[0m, in \u001b[0;36mget_single_model_file_with_path\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis file could not be found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_string\u001b[49m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'model_string' referenced before assignment"
     ]
    }
   ],
   "source": [
    "from functions import get_model_files, get_single_model_file_with_path, prolog_reasoning\n",
    "model_network_file = \"/Users/zhenzhili/MASTERTHESIS/#Expert_System_Design/generated/example_for_netowork/prolog_model_deepseek_2025-02-08.pl\"\n",
    "\n",
    "facts_1st_risk = \"\"\" \n",
    "sensor_data(sensor_KMS1, temperature, '2023-08-15T14:00:00', '2023-08-15T14:05:00', 0.7, 27.5, 1.2, 27.3, 27.6, 0.1).\n",
    "sensor_data(sensor_cpu, cpuload, '2023-08-15T14:00:00', '2023-08-15T14:05:00', 0.9, 0.82, 0.05, 0.81, 0.83, 0.01).\n",
    "\"\"\"\n",
    "\n",
    "facts_2nd_risk = \"\"\" \n",
    "sensor_data(sensor_KMS1, temperature, '2023-08-15T03:00:00', '2023-08-15T03:05:00', 0.6, 23.2, 0.8, 23.0, 23.5, -0.3).\n",
    "sensor_data(sensor_weather, humidity, '2023-08-15T03:00:00', '2023-08-15T03:05:00', 0.7, 0.88, 0.02, 0.87, 0.89, 0.01).\n",
    "\"\"\"\n",
    "\n",
    "facts_3rd_risk= \"\"\" \n",
    "sensor_data(sensor_weather, temperature, '2023-08-15T12:00:00', '2023-08-15T12:05:00', 0.8, 25.5, 1.0, 25.3, 25.8, 0.2).\n",
    "sensor_data(sensor_KMS1, temperature, '2023-08-15T12:00:00', '2023-08-15T12:05:00', 0.9, 22.8, 1.5, 22.5, 23.0, -0.5).\n",
    "\"\"\"\n",
    "\n",
    "query = \"\"\" \n",
    "query(anomaly(_)).\n",
    "\"\"\"\n",
    "\n",
    "network_define = \"\"\" \n",
    "\"\"\"\n",
    "\n",
    "facts ={\"facts_overheat_risk\":facts_1st_risk, \n",
    "        \"facts_condensation_risk\":facts_2nd_risk, \n",
    "        \"facts_high_power_consumption_risk\":facts_3rd_risk\n",
    "}\n",
    "# read all model files that start with \"prolog_model_deepseek_\":\n",
    "model_files = get_single_model_file_with_path(model_network_file)\n",
    "for fact_key in facts:\n",
    "    print(f\"------------{fact_key}------------\")\n",
    "    whole_model = facts[fact_key] + model_files + query\n",
    "    result_single = prolog_reasoning(whole_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write for csv to prolog, data flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "def csv_to_prolog(csv_file, output_file):\n",
    "    # 读取 CSV 文件\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # 确保 CSV 包含所有必要的列\n",
    "    required_columns = [\"Sensor\", \"Item\", \"Start_timestamp\", \"End_timestamp\", \"Std_value\", \"Mean_value\", \"Median_value\", \"Max_value\", \"Min_value\", \"Slope\"]\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Missing required column: {col}\")\n",
    "    \n",
    "    # 生成 Prolog 规则\n",
    "    with open(output_file, 'w') as f:\n",
    "        for _, row in df.iterrows():\n",
    "            prolog_fact = f\"sensor_data({row['Sensor']}, {row['Item']}, '{row['Start_timestamp']}', '{row['End_timestamp']}', {row['Std_value']}, {row['Mean_value']}, {row['Median_value']}, {row['Max_value']}, {row['Min_value']}, {row['Slope']}).\"\n",
    "            f.write(prolog_fact + '\\n')\n",
    "    \n",
    "    print(f\"Prolog facts saved to {output_file}\")\n",
    "\n",
    "if len(sys.argv) != 3:\n",
    "    print(\"Usage: python csv_to_prolog.py <input_csv> <output_pl>\")\n",
    "    sys.exit(1)\n",
    "\n",
    "csv_file = sys.argv[1]\n",
    "output_file = sys.argv[2]\n",
    "\n",
    "csv_to_prolog(csv_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NonGroundProbabilisticClause",
     "evalue": "Encountered a non-ground probabilistic clause at 11:4.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNonGroundProbabilisticClause\u001b[0m              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_model_files, get_single_model_file_with_path, prolog_reasoning\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m \u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124msensor_data(Sensor, temperature, _, _, _, 29, _, _, _, _).\u001b[39m\n\u001b[1;32m      5\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124mquery(event_temperature_exceed(_)).\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 21\u001b[0m \u001b[43mprolog_reasoning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MASTERTHESIS/#Expert_System_Design/functions.py:29\u001b[0m, in \u001b[0;36mprolog_reasoning\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprolog_reasoning\u001b[39m(model:\u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 29\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mget_evaluatable\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPrologString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProbLog Inference Result：\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m query_key, probability \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/miniforge3/envs/wki-ws23/lib/python3.9/site-packages/problog/core.py:156\u001b[0m, in \u001b[0;36mProbLogObject.create_from\u001b[0;34m(cls, obj, **kwdargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_from\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwdargs):\n\u001b[1;32m    150\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Transform the given object into an object of the current class using transformations.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03m    :param obj: obj to transform\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m    :param kwdargs: additional options\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m    :return: object of current class\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mProbLog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwdargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/wki-ws23/lib/python3.9/site-packages/problog/core.py:121\u001b[0m, in \u001b[0;36mProbLog.convert\u001b[0;34m(cls, src, target, **kwdargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m path:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m path[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m         next_obj \u001b[38;5;241m=\u001b[39m \u001b[43mpath\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwdargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwdargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m         next_obj \u001b[38;5;241m=\u001b[39m path[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcreate_from_default_action(\n\u001b[1;32m    124\u001b[0m             current_obj, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwdargs\n\u001b[1;32m    125\u001b[0m         )\n",
      "File \u001b[0;32m~/miniforge3/envs/wki-ws23/lib/python3.9/site-packages/problog/engine.py:51\u001b[0m, in \u001b[0;36mground\u001b[0;34m(model, target, grounder, **kwdargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ground_yap(model, target, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwdargs)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mground_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwdargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/wki-ws23/lib/python3.9/site-packages/problog/engine.py:78\u001b[0m, in \u001b[0;36mground_default\u001b[0;34m(model, target, queries, evidence, propagate_evidence, labels, engine, **kwdargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     engine \u001b[38;5;241m=\u001b[39m DefaultEngine(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwdargs)\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mground_all\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqueries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevidence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevidence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpropagate_evidence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpropagate_evidence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/wki-ws23/lib/python3.9/site-packages/problog/engine.py:587\u001b[0m, in \u001b[0;36mClauseDBEngine.ground_all\u001b[0;34m(self, db, target, queries, evidence, propagate_evidence, labels)\u001b[0m\n\u001b[1;32m    583\u001b[0m             logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    584\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPropagated evidence: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mlist\u001b[39m(target\u001b[38;5;241m.\u001b[39mlookup_evidence)\n\u001b[1;32m    585\u001b[0m             )\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 587\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mground_queries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mground_evidence(db, target, evidence)\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m target\n",
      "File \u001b[0;32m~/miniforge3/envs/wki-ws23/lib/python3.9/site-packages/problog/engine.py:531\u001b[0m, in \u001b[0;36mClauseDBEngine.ground_queries\u001b[0;34m(self, db, target, queries)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label, query \u001b[38;5;129;01min\u001b[39;00m queries:\n\u001b[1;32m    530\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrounding query \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, query)\n\u001b[0;32m--> 531\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mground\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    532\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGround program size: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(target))\n",
      "File \u001b[0;32m~/miniforge3/envs/wki-ws23/lib/python3.9/site-packages/problog/engine.py:336\u001b[0m, in \u001b[0;36mClauseDBEngine.ground\u001b[0;34m(self, db, term, target, label, **kwdargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    334\u001b[0m     negated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m target, results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ground\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent_fail\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwdargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m args_node \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m args, node_id \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "File \u001b[0;32m~/miniforge3/envs/wki-ws23/lib/python3.9/site-packages/problog/engine.py:451\u001b[0m, in \u001b[0;36mClauseDBEngine._ground\u001b[0;34m(self, db, term, gp, silent_fail, assume_prepared, **kwdargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m         location \u001b[38;5;241m=\u001b[39m db\u001b[38;5;241m.\u001b[39mlineno(term\u001b[38;5;241m.\u001b[39mlocation)\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebugger\u001b[38;5;241m.\u001b[39mcall_create(\n\u001b[1;32m    449\u001b[0m             clause_node, term\u001b[38;5;241m.\u001b[39mfunctor, context, \u001b[38;5;28;01mNone\u001b[39;00m, location\n\u001b[1;32m    450\u001b[0m         )\n\u001b[0;32m--> 451\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclause_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwdargs\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m UnknownClauseInternal:\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m silent_fail \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munknown \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mUNKNOWN_FAIL:\n",
      "File \u001b[0;32m~/miniforge3/envs/wki-ws23/lib/python3.9/site-packages/problog/engine_stack.py:441\u001b[0m, in \u001b[0;36mStackBasedEngine.execute\u001b[0;34m(self, node_id, target, database, subcall, is_root, name, **kwdargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;66;03m# We need to execute another node.\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;66;03m# if self.cycle_root is not None and context['parent'] < self.cycle_root.pointer:\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;66;03m#     print ('Cycle exhausted indeed:', len(actions) + 1)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m#         (act, obj, args, context)]\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;66;03m# Evaluate the next node.\u001b[39;00m\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;66;03m# if exclude is not None and obj in exclude:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;66;03m#     obj = self.pointer\u001b[39;00m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[0;32m--> 441\u001b[0m     next_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpointer\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m UnknownClauseInternal:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;66;03m# An unknown clause was encountered.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;66;03m# TODO why is this handled here?\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/wki-ws23/lib/python3.9/site-packages/problog/engine_stack.py:126\u001b[0m, in \u001b[0;36mStackBasedEngine.eval\u001b[0;34m(self, node_id, **kwdargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m UnknownClauseInternal()\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexec_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwdargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/wki-ws23/lib/python3.9/site-packages/problog/engine_stack.py:834\u001b[0m, in \u001b[0;36mStackBasedEngine.eval_call\u001b[0;34m(self, node_id, node, context, parent, transform, identifier, **kwdargs)\u001b[0m\n\u001b[1;32m    831\u001b[0m kwdargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m transform\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 834\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midentifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midentifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwdargs\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m UnknownClauseInternal:\n\u001b[1;32m    838\u001b[0m     loc \u001b[38;5;241m=\u001b[39m kwdargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatabase\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mlineno(node\u001b[38;5;241m.\u001b[39mlocation)\n",
      "File \u001b[0;32m~/miniforge3/envs/wki-ws23/lib/python3.9/site-packages/problog/engine_stack.py:126\u001b[0m, in \u001b[0;36mStackBasedEngine.eval\u001b[0;34m(self, node_id, **kwdargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m UnknownClauseInternal()\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexec_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwdargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/wki-ws23/lib/python3.9/site-packages/problog/engine_stack.py:914\u001b[0m, in \u001b[0;36mStackBasedEngine.eval_choice\u001b[0;34m(self, parent, node_id, node, context, target, database, identifier, **kwdargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(result):\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39mlocvars \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_ground(r):\n\u001b[0;32m--> 914\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_nonground\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnode_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[43midentifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midentifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwdargs\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    926\u001b[0m probability \u001b[38;5;241m=\u001b[39m instantiate(node\u001b[38;5;241m.\u001b[39mprobability, result)\n\u001b[1;32m    927\u001b[0m \u001b[38;5;66;03m# Create a new atom in ground program.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/wki-ws23/lib/python3.9/site-packages/problog/engine_stack.py:905\u001b[0m, in \u001b[0;36mStackBasedEngine.handle_nonground\u001b[0;34m(self, location, database, node, **kwdargs)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandle_nonground\u001b[39m(\u001b[38;5;28mself\u001b[39m, location\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, database\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, node\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwdargs):\n\u001b[0;32m--> 905\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NonGroundProbabilisticClause(location\u001b[38;5;241m=\u001b[39mdatabase\u001b[38;5;241m.\u001b[39mlineno(node\u001b[38;5;241m.\u001b[39mlocation))\n",
      "\u001b[0;31mNonGroundProbabilisticClause\u001b[0m: Encountered a non-ground probabilistic clause at 11:4."
     ]
    }
   ],
   "source": [
    "from functions import get_model_files, get_single_model_file_with_path, prolog_reasoning\n",
    "\n",
    "model = \"\"\" \n",
    "sensor_data(Sensor, temperature, _, _, _, 29, _, _, _, _).\n",
    "\n",
    "temp_exceed_net(Mean, P):-\n",
    "    Mean > 28, P is 0.8.\n",
    "    \n",
    "temp_exceed_net(Mean, P):-\n",
    "    Mean > 24, Mean =< 28, P is 0.5.\n",
    "\n",
    "\n",
    "P::event_temperature_exceed(Sensor) :- \n",
    "    sensor_data(Sensor, temperature, _, _, _, Mean, _, _, _, _),\n",
    "    Mean > 26,  % 保留条件（可选）\n",
    "    temp_exceed_net(Mean, P).  % 神经网络预测概率\n",
    "    \n",
    "query(event_temperature_exceed(_)).\n",
    "\"\"\"\n",
    "\n",
    "prolog_reasoning(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '/mnt/data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m df_humidity \u001b[38;5;241m=\u001b[39m df_anormales[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStart_timestamp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnd_timestamp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHumidity\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 保存文件\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mdf_temp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_temp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m df_cpu\u001b[38;5;241m.\u001b[39mto_csv(csv_cpu, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m df_humidity\u001b[38;5;241m.\u001b[39mto_csv(csv_humidity, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/wki-ws23/lib/python3.9/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/wki-ws23/lib/python3.9/site-packages/pandas/core/generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3965\u001b[0m )\n\u001b[0;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/wki-ws23/lib/python3.9/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/miniforge3/envs/wki-ws23/lib/python3.9/site-packages/pandas/io/formats/csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/miniforge3/envs/wki-ws23/lib/python3.9/site-packages/pandas/io/common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/wki-ws23/lib/python3.9/site-packages/pandas/io/common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '/mnt/data'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Data_Center_Anomalies_with_Nois_path = \"/Users/zhenzhili/MASTERTHESIS/datasets/Data_Center_Anomalies_with_Noise.csv\"\n",
    "df_anormales = pd.read_csv(Data_Center_Anomalies_with_Nois_path)\n",
    "\n",
    "# 创建单独的 CSV 文件\n",
    "csv_temp = \"/mnt/data/temperature_data.csv\"\n",
    "csv_cpu = \"/mnt/data/cpu_load_data.csv\"\n",
    "csv_humidity = \"/mnt/data/humidity_data.csv\"\n",
    "\n",
    "# 创建单独的 DataFrame\n",
    "df_temp = df_anormales[['Start_timestamp', 'End_timestamp', 'Temperature']]\n",
    "df_cpu = df_anormales[['Start_timestamp', 'End_timestamp', 'CPU_load']]\n",
    "df_humidity = df_anormales[['Start_timestamp', 'End_timestamp', 'Humidity']]\n",
    "\n",
    "# 保存文件\n",
    "df_temp.to_csv(csv_temp, index=False)\n",
    "df_cpu.to_csv(csv_cpu, index=False)\n",
    "df_humidity.to_csv(csv_humidity, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"\"\"\n",
    "t(0.5) :: col(1,red); t(0.5) :: col(1,blue).\n",
    "t(0.333) :: col(2,red); t(0.333) :: col(2,green); t(0.333) :: col(2,blue).\n",
    "t(0.5) :: coin_heads.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wki-ws23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
